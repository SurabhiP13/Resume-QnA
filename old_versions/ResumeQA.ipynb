{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !unzip Resume-markdown-docling-zip.zip"
      ],
      "metadata": {
        "id": "LuYOL6F0DeQt"
      },
      "id": "LuYOL6F0DeQt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docling\n",
        "!pip install -U sentence-transformers\n",
        "!pip install rank-bm25\n",
        "!pip install faiss-cpu\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "HD2BulRfI42S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bae995b-6c78-443a-d534-45a06d269352"
      },
      "id": "HD2BulRfI42S",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docling\n",
            "  Downloading docling-2.57.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (2.11.10)\n",
            "Collecting docling-core<3.0.0,>=2.48.2 (from docling-core[chunking]<3.0.0,>=2.48.2->docling)\n",
            "  Downloading docling_core-2.49.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting docling-parse<5.0.0,>=4.4.0 (from docling)\n",
            "  Downloading docling_parse-4.7.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting docling-ibm-models<4,>=3.9.1 (from docling)\n",
            "  Downloading docling_ibm_models-3.10.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from docling)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pypdfium2!=4.30.1,<5.0.0,>=4.30.0 (from docling)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic-settings<3.0.0,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from docling) (2.11.0)\n",
            "Requirement already satisfied: huggingface_hub<1,>=0.23 in /usr/local/lib/python3.12/dist-packages (from docling) (0.35.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from docling) (2.32.4)\n",
            "Collecting rapidocr<4.0.0,>=3.3 (from docling)\n",
            "  Downloading rapidocr-3.4.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from docling) (2025.10.5)\n",
            "Collecting rtree<2.0.0,>=1.3.0 (from docling)\n",
            "  Downloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: typer<0.20.0,>=0.12.5 in /usr/local/lib/python3.12/dist-packages (from docling) (0.19.2)\n",
            "Collecting python-docx<2.0.0,>=1.1.2 (from docling)\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-pptx<2.0.0,>=1.0.2 (from docling)\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from docling) (4.13.5)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /usr/local/lib/python3.12/dist-packages (from docling) (2.2.2)\n",
            "Collecting marko<3.0.0,>=2.1.2 (from docling)\n",
            "  Downloading marko-2.2.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.12/dist-packages (from docling) (3.1.5)\n",
            "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (5.4.0)\n",
            "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (11.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from docling) (4.67.1)\n",
            "Requirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (1.6.0)\n",
            "Collecting pylatexenc<3.0,>=2.10 (from docling)\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from docling) (1.16.2)\n",
            "Requirement already satisfied: accelerate<2,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (1.10.1)\n",
            "Collecting polyfactory>=2.22.2 (from docling)\n",
            "  Downloading polyfactory-2.22.3-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (2.8.0+cu126)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (0.6.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (4.15.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /usr/local/lib/python3.12/dist-packages (from docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling) (4.25.1)\n",
            "Collecting jsonref<2.0.0,>=1.1.0 (from docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling) (0.9.0)\n",
            "Collecting latex2mathml<4.0.0,>=3.77.0 (from docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling)\n",
            "  Downloading latex2mathml-3.78.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting semchunk<3.0.0,>=2.2.0 (from docling-core[chunking]<3.0.0,>=2.48.2->docling)\n",
            "  Downloading semchunk-2.2.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.12/dist-packages (from docling-core[chunking]<3.0.0,>=2.48.2->docling) (4.57.1)\n",
            "Requirement already satisfied: torchvision<1,>=0 in /usr/local/lib/python3.12/dist-packages (from docling-ibm-models<4,>=3.9.1->docling) (0.23.0+cu126)\n",
            "Collecting jsonlines<5.0.0,>=3.1.0 (from docling-ibm-models<4,>=3.9.1->docling)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1,>=0.23->docling) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1,>=0.23->docling) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1,>=0.23->docling) (1.1.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl<4.0.0,>=3.1.5->docling) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Collecting faker>=5.0.0 (from polyfactory>=2.22.2->docling)\n",
            "  Downloading faker-37.11.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.3.0->docling) (1.1.1)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling)\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pyclipper>=1.2.0 (from rapidocr<4.0.0,>=3.3->docling)\n",
            "  Downloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: opencv-python>=4.5.1.48 in /usr/local/lib/python3.12/dist-packages (from rapidocr<4.0.0,>=3.3->docling) (4.12.0.88)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from rapidocr<4.0.0,>=3.3->docling) (1.17.0)\n",
            "Requirement already satisfied: Shapely!=2.0.4,>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from rapidocr<4.0.0,>=3.3->docling) (2.1.2)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from rapidocr<4.0.0,>=3.3->docling) (2.3.0)\n",
            "Collecting colorlog (from rapidocr<4.0.0,>=3.3->docling)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.2->docling) (2.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.20.0,>=0.12.5->docling) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.20.0,>=0.12.5->docling) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.20.0,>=0.12.5->docling) (13.9.4)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines<5.0.0,>=3.1.0->docling-ibm-models<4,>=3.9.1->docling) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling) (0.27.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<0.20.0,>=0.12.5->docling) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<0.20.0,>=0.12.5->docling) (2.19.2)\n",
            "Collecting mpire[dill] (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.48.2->docling)\n",
            "  Downloading mpire-2.10.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.48.2->docling) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.48.2->docling) (0.22.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->rapidocr<4.0.0,>=3.3->docling) (4.9.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.20.0,>=0.12.5->docling) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.0.3)\n",
            "Requirement already satisfied: multiprocess>=0.70.15 in /usr/local/lib/python3.12/dist-packages (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.48.2->docling) (0.70.16)\n",
            "Requirement already satisfied: dill>=0.3.8 in /usr/local/lib/python3.12/dist-packages (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.48.2->docling) (0.3.8)\n",
            "Downloading docling-2.57.0-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_core-2.49.0-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.5/164.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_ibm_models-3.10.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_parse-4.7.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (15.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading marko-2.2.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading polyfactory-2.22.3-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidocr-3.4.2-py3-none-any.whl (15.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.6/507.6 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faker-37.11.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading latex2mathml-3.78.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.8/963.8 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semchunk-2.2.2-py3-none-any.whl (10 kB)\n",
            "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading mpire-2.10.2-py3-none-any.whl (272 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=68d139469e61e171425bcfb6cdb7d7c8a091465a6db0bb1f91b1110353d65ef1\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/3e/78/fa1588c1ae991bbfd814af2bcac6cef7a178beee1939180d46\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: pylatexenc, pyclipper, filetype, XlsxWriter, rtree, python-docx, pypdfium2, mpire, marko, latex2mathml, jsonref, jsonlines, faker, colorlog, rapidocr, python-pptx, polyfactory, semchunk, docling-core, docling-parse, docling-ibm-models, docling\n",
            "Successfully installed XlsxWriter-3.2.9 colorlog-6.10.1 docling-2.57.0 docling-core-2.49.0 docling-ibm-models-3.10.0 docling-parse-4.7.0 faker-37.11.0 filetype-1.2.0 jsonlines-4.0.0 jsonref-1.1.0 latex2mathml-3.78.1 marko-2.2.1 mpire-2.10.2 polyfactory-2.22.3 pyclipper-1.3.0.post6 pylatexenc-2.10 pypdfium2-4.30.0 python-docx-1.2.0 python-pptx-1.0.2 rapidocr-3.4.2 rtree-1.4.1 semchunk-2.2.2\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\n",
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank-bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank-bm25\n",
            "Successfully installed rank-bm25-0.2.2\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.35)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1d53d14f",
      "metadata": {
        "id": "1d53d14f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Any\n",
        "import hashlib\n",
        "import statistics\n",
        "\n",
        "from docling.document_converter import DocumentConverter\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pickle\n",
        "import re\n",
        "from typing import List, Dict, Any\n",
        "from rank_bm25 import BM25Okapi\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "\n",
        "# Constants\n",
        "RESUME_PDF_PATH = \"Submit your resume or CV (File responses)\"\n",
        "RESUME_MARKDOWN_PATH = \"Resume-markdown-docling\"\n",
        "MAX_RESUMES = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF to Markdown Conversion using docling and saving it"
      ],
      "metadata": {
        "id": "Yjkm8UV6OlGj"
      },
      "id": "Yjkm8UV6OlGj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f82e2a59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f82e2a59",
        "outputId": "2c363b24-1bf6-47b7-d241-e78264158304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 52 PDFs to convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[INFO] 2025-10-17 06:21:03,282 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:03,288 [RapidOCR] download_file.py:68: Initiating download: https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.4.0/torch/PP-OCRv4/det/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:04,564 [RapidOCR] download_file.py:82: Download size: 13.83MB\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:04,732 [RapidOCR] download_file.py:95: Successfully saved to: /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:04,734 [RapidOCR] torch.py:54: Using /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:04,975 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:04,977 [RapidOCR] download_file.py:68: Initiating download: https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.4.0/torch/PP-OCRv4/cls/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:06,332 [RapidOCR] download_file.py:82: Download size: 0.56MB\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:06,366 [RapidOCR] download_file.py:95: Successfully saved to: /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:06,376 [RapidOCR] torch.py:54: Using /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:06,580 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:06,583 [RapidOCR] download_file.py:68: Initiating download: https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.4.0/torch/PP-OCRv4/rec/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:07,946 [RapidOCR] download_file.py:82: Download size: 25.67MB\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:08,711 [RapidOCR] download_file.py:95: Successfully saved to: /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-17 06:21:08,719 [RapidOCR] torch.py:54: Using /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # Basic PDF to Markdown conversion\n",
        "# from pathlib import Path\n",
        "\n",
        "# # Setup paths\n",
        "# pdf_dir = Path(\"Submit your resume or CV (File responses)\")\n",
        "# output_dir = Path(\"Resume-markdown-docling\")\n",
        "# output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# # Get first 200 PDFs\n",
        "# pdf_files = list(pdf_dir.glob(\"*.pdf\"))[:200]\n",
        "# print(f\"Found {len(pdf_files)} PDFs to convert\")\n",
        "\n",
        "# # Convert PDFs\n",
        "# converter = DocumentConverter()\n",
        "# successful = 0\n",
        "\n",
        "# for pdf_file in pdf_files:\n",
        "#     try:\n",
        "#         result = converter.convert(str(pdf_file))\n",
        "#         markdown_content = result.document.export_to_markdown()\n",
        "\n",
        "#         output_file = output_dir / f\"{pdf_file.stem}.md\"\n",
        "#         output_file.write_text(markdown_content, encoding='utf-8')\n",
        "\n",
        "#         successful += 1\n",
        "#         if successful % 20 == 0:\n",
        "#             print(f\"Converted {successful} files\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Failed: {pdf_file.name}\")\n",
        "\n",
        "# print(f\"Conversion complete: {successful}/{len(pdf_files)} successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunking the markdowns based on custom rules\n",
        "=> 3+ separated capital letters to be joined => due to conversion between pdf and markdown\n",
        "\n",
        "=> splitting based on common headers in resume such as experience , summary etc using regex + it needs to be after ## => thats how docling does it\n"
      ],
      "metadata": {
        "id": "r2Cm85VyOvZt"
      },
      "id": "r2Cm85VyOvZt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94a49d8a",
      "metadata": {
        "id": "94a49d8a",
        "outputId": "2b4fabd9-356c-4ec9-bde1-3df144f852ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 250 chunks from 52 resumes\n",
            "Average chunks per resume: 4.8\n"
          ]
        }
      ],
      "source": [
        "# markdown_dir=Path(\"Resume-markdown-docling\")\n",
        "# def fix_spaced_caps(s: str) -> str:\n",
        "#     pattern = re.compile(r'(?<!\\w)(?:[A-Z]\\s+){2,}[A-Z](?!\\w)')  # 3+ capital letters separated by spaces\n",
        "#     def _join(m):\n",
        "#         return m.group(0).replace(' ', '')\n",
        "#     return pattern.sub(_join, s)\n",
        "\n",
        "# def container_chunking(content: str, resume_id: str) -> List[Document]:\n",
        "#     # Remove image tags\n",
        "#     content = re.sub(r'<!-- image -->', '', content)\n",
        "#     #Removing spacing S K I L L -> SKILL\n",
        "#     # Fix spaced out words like \"e x p e r i e n c e\" or \"E X P E R I E N C E\"\n",
        "#     # content = re.sub(r'\\b(\\w)\\s+(\\w)\\s+(\\w)(\\s+\\w)*\\b', lambda m: re.sub(r'\\s+', '', m.group()), content)\n",
        "#     content = fix_spaced_caps(content)\n",
        "\n",
        "#     containers = [\n",
        "#         r'about\\s*me', r'summary', r'profile', r'experience', r'work\\s+experience',\n",
        "#         r'education', r'skill[s]?', r'project[s]?', r'achievement[s]?', r'award[s]?',\n",
        "#         r'publication[s]?', r'competition[s]?', r'hackathon[s]?'\n",
        "#     ]\n",
        "#     container_alt = '|'.join(containers)\n",
        "\n",
        "#     # Anchor to line start, any H1–H6, match only the heading line\n",
        "#     pattern = rf'(?=^#{{1,6}}\\s*(?:.*\\b(?:{container_alt})\\b).*$)'\n",
        "#     chunks = re.split(pattern, content, flags=re.IGNORECASE | re.MULTILINE)\n",
        "\n",
        "#     # Filter empty chunks and create documents\n",
        "#     docs = []\n",
        "#     for i, chunk in enumerate(chunks):\n",
        "#         chunk = chunk.strip()\n",
        "#         if chunk and len(chunk) > 50:\n",
        "#             doc = Document(\n",
        "#                 page_content=chunk,\n",
        "#                 metadata={'resume_id': resume_id, 'chunk_id': i}\n",
        "#             )\n",
        "#             docs.append(doc)\n",
        "\n",
        "#     return docs\n",
        "\n",
        "# # Process all resumes\n",
        "# all_chunks = []\n",
        "# for md_file in markdown_dir.glob(\"*.md\"):\n",
        "#     content = md_file.read_text(encoding='utf-8')\n",
        "#     resume_id = md_file.stem\n",
        "#     chunks = container_chunking(content, resume_id)\n",
        "#     all_chunks.extend(chunks)\n",
        "\n",
        "# print(f\"Created {len(all_chunks)} chunks from {len(list(markdown_dir.glob('*.md')))} resumes\")\n",
        "# print(f\"Average chunks per resume: {len(all_chunks) / len(list(markdown_dir.glob('*.md'))):.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "757de011",
      "metadata": {
        "id": "757de011"
      },
      "source": [
        "Embedding Models\n",
        "\n",
        "Creating embeddings of each chunk in the document(resume) list and storing them in a pickle file (so don't have to keep running it again)\n",
        "PS only works on colab due to version differences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #CREATING OPEN AI EMBEDDINGS FOR ALL CHUNKS\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = (\n",
        "#     userdata.get(\"OPENAI_API_KEY\") or userdata.get(\"openai_api_key\")\n",
        "# )\n",
        "# client=OpenAI()\n",
        "# def get_openai_embeddings(texts: list[str], model: str = \"text-embedding-3-small\", batch_size: int = 100) -> np.ndarray:\n",
        "#     embeddings: list[np.ndarray] = []\n",
        "#     for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding batches\"):\n",
        "#         batch = texts[i : i + batch_size]\n",
        "#         resp = client.embeddings.create(model=model, input=batch)\n",
        "#         embeddings.extend([np.array(item.embedding, dtype=np.float32) for item in resp.data])\n",
        "#     return np.vstack(embeddings) if embeddings else np.zeros((0, 0), dtype=np.float32)\n",
        "\n",
        "# # prepare chunks (prefer in-memory all_chunks, else load saved chunks)\n",
        "# try:\n",
        "#     chunks = all_chunks  # type: ignore[name-defined]\n",
        "# except NameError:\n",
        "#     if os.path.exists(\"resume_chunks.pkl\"):\n",
        "#         with open(\"resume_chunks.pkl\", \"rb\") as f:\n",
        "#             chunks = pickle.load(f)\n",
        "#     else:\n",
        "#         raise RuntimeError(\"No in-memory chunks and resume_chunks.pkl not found.\")\n",
        "\n",
        "# chunk_texts = [doc.page_content for doc in chunks]\n",
        "# print(f\"Generating OpenAI embeddings for {len(chunk_texts)} chunks...\")\n",
        "\n",
        "# # choose \"text-embedding-3-small\" or \"text-embedding-3-large\"\n",
        "# embeddings = get_openai_embeddings(chunk_texts, model=\"text-embedding-3-small\", batch_size=100)\n",
        "\n",
        "# # ====================================================================================================================\n",
        "# # SAVING THE EMBEDDINGS OF CHUNKS AND STORING IN PICKLE FILE\n",
        "# with open(\"resume_chunks_openai.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(chunks, f)\n",
        "\n",
        "# with open(\"resume_embeddings_openai.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(embeddings, f)\n",
        "\n",
        "# print(f\"Saved {len(chunks)} chunks and embeddings -> resume_chunks_openai.pkl, resume_embeddings_openai.pkl\")\n",
        "# print(f\"Embeddings shape: {embeddings.shape}\")\n",
        "\n",
        "# # # ====================================================================================================================\n",
        "# # # SACHECKING PURELY BASED ON COSINE SIMILARITY\n",
        "\n",
        "# # # retrieval function using cosine similarity\n",
        "# # def retrieve_similar_chunks_openai(query: str, top_k: int = 5, model: str = \"text-embedding-3-large\"):\n",
        "# #     # ensure embeddings & chunks are loaded in scope\n",
        "# #     global embeddings, chunks\n",
        "# #     if 'embeddings' not in globals() or embeddings is None or embeddings.size == 0:\n",
        "# #         if os.path.exists(\"resume_embeddings_openai.pkl\"):\n",
        "# #             with open(\"resume_embeddings_openai.pkl\", \"rb\") as f:\n",
        "# #                 embeddings = pickle.load(f)\n",
        "# #         else:\n",
        "# #             raise RuntimeError(\"Embeddings not loaded. Run embedding generation first.\")\n",
        "# #     if 'chunks' not in globals() or chunks is None:\n",
        "# #         if os.path.exists(\"resume_chunks_openai.pkl\"):\n",
        "# #             with open(\"resume_chunks_openai.pkl\", \"rb\") as f:\n",
        "# #                 chunks = pickle.load(f)\n",
        "# #         else:\n",
        "# #             raise RuntimeError(\"Chunks not loaded. Run embedding generation first.\")\n",
        "\n",
        "\n",
        "# #     0# get query embedding\n",
        "# #     q_resp = client.embeddings.create(model=model, input=[query])\n",
        "# #     q_emb = np.array(q_resp.data[0].embedding, dtype=np.float32).reshape(1, -1)\n",
        "# #     sims = cosine_similarity(q_emb, embeddings)[0]\n",
        "# #     top_idx = np.argsort(sims)[-top_k:][::-1]\n",
        "# #     results = []\n",
        "# #     for i in top_idx:\n",
        "# #         results.append({\n",
        "# #             \"score\": float(sims[i]),\n",
        "# #             \"content\": chunks[i].page_content,\n",
        "# #             \"metadata\": chunks[i].metadata\n",
        "# #         })\n",
        "# #     return results\n",
        "\n"
      ],
      "metadata": {
        "id": "JhO5p1xxExQf"
      },
      "id": "JhO5p1xxExQf",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # example usage:\n",
        "# results = retrieve_similar_chunks_openai(\"student who has scored more than 95% in school\", top_k=3)\n",
        "# # for r in results: print(r[\"score\"], r[\"metadata\"][\"resume_id\"], r[\"content\"][:200])"
      ],
      "metadata": {
        "id": "PenSXAMQFsJp"
      },
      "id": "PenSXAMQFsJp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying Hybrid Retrieval\n",
        "\n",
        "\n",
        "For resume based querying, just semantic search doesn't cut it, a lot of the times, the recruiters are looking for some keywords, with semantic similarity it can't match exact keywords hence we need to combine approaches; keyword matching +semantic similarity"
      ],
      "metadata": {
        "id": "1IGxdgPczByd"
      },
      "id": "1IGxdgPczByd"
    },
    {
      "cell_type": "code",
      "source": [
        " # Load saved chunks and embeddings\n",
        "with open('resume_chunks_openai.pkl', 'rb') as f:\n",
        "    chunks = pickle.load(f)\n",
        "\n",
        "with open('resume_embeddings_openai.pkl', 'rb') as f:\n",
        "    embeddings = pickle.load(f)\n",
        "\n",
        "# --- tiny cleaner & tokenizer ---\n",
        "_CLEAN_RX = re.compile(r'[^\\w\\s]')\n",
        "_WS_RX = re.compile(r'\\s+')\n",
        "\n",
        "def clean_and_tokenize(text: str) -> List[str]:\n",
        "    text = text.lower()\n",
        "    text = _CLEAN_RX.sub(' ', text)     # remove punctuation\n",
        "    text = _WS_RX.sub(' ', text).strip()\n",
        "    return [t for t in text.split(' ') if t]\n",
        "\n",
        "class BM25Index:\n",
        "    def __init__(self):\n",
        "        self.bm25 = None\n",
        "        self.docs: List[Document] = []\n",
        "        self.doc_tokens: List[List[str]] = []\n",
        "\n",
        "    def fit(self, chunks: List[Document]):\n",
        "        self.docs = chunks\n",
        "        self.doc_tokens = [clean_and_tokenize(d.page_content) for d in chunks]\n",
        "        self.bm25 = BM25Okapi(self.doc_tokens)\n",
        "\n",
        "    def search(self, query: str, top_k: int = 10) -> List[Dict[str, Any]]:\n",
        "        if self.bm25 is None:\n",
        "            raise RuntimeError(\"Call fit(chunks) before search().\")\n",
        "        q_tokens = clean_and_tokenize(query)\n",
        "        scores = self.bm25.get_scores(q_tokens)\n",
        "        # top-k indices by score\n",
        "        top_idx = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
        "        out = []\n",
        "        for rank, i in enumerate(top_idx, 1):\n",
        "            d = self.docs[i]\n",
        "            out.append({\n",
        "                \"rank\": rank,\n",
        "                \"bm25_score\": float(scores[i]),\n",
        "                \"resume_id\": (d.metadata or {}).get(\"resume_id\"),\n",
        "                \"chunk_id\": (d.metadata or {}).get(\"chunk_id\"),\n",
        "                \"preview\": d.page_content[:400]\n",
        "            })\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "NRqlni71zP6m"
      },
      "id": "NRqlni71zP6m",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm25 = BM25Index()\n",
        "bm25.fit(chunks)  # chunks = your List[Document] from the chunker\n",
        "\n",
        "query = \"Urban Water Logging Detection for Timely Intervention and Mitigation\"\n",
        "hits = bm25.search(query, top_k=10)\n",
        "\n",
        "print(f\"BM25 hits: {len(hits)}\")\n",
        "for h in hits[:5]:\n",
        "    print(f\"[{h['rank']:>2}] {h['bm25_score']:.3f}  resume={h['resume_id']}  chunk={h['chunk_id']}\")\n",
        "    print(\"   \", (h[\"preview\"] or \"\").splitlines()[0][:540], \"...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-b1MycG1VyN",
        "outputId": "4953d700-4569-444d-8c6c-794d28cee6a5"
      },
      "id": "u-b1MycG1VyN",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BM25 hits: 10\n",
            "[ 1] 30.951  resume=Resume Mollika - Mollika Garg  chunk=4\n",
            "    ## SELECTED PROJECTS ...\n",
            "[ 2] 16.028  resume=Resume Mollika - Mollika Garg  chunk=5\n",
            "    ## ACHIEVEMENTS ...\n",
            "[ 3] 10.170  resume=Resume.PunithHM - Punith H M  chunk=2\n",
            "    ## Projects ...\n",
            "[ 4] 9.759  resume=Zulfikar_resume - Zulfikar Charoliya  chunk=2\n",
            "    ## PROJECTS ...\n",
            "[ 5] 5.784  resume=Aziz Bayu Pratama - Curriculum Vitae - 4IA04_Aziz Bayu Pratama  chunk=2\n",
            "    ## EXPERIENCES ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = (\n",
        "    userdata.get(\"OPENAI_API_KEY\") or userdata.get(\"openai_api_key\")\n",
        ")\n",
        "client=OpenAI()\n",
        "\n",
        "class DenseIndexSimple:\n",
        "    def __init__(self):\n",
        "        self.docs: List[Document] = []\n",
        "        self.Xn: np.ndarray | None = None  # L2-normalized embeddings (N, D)\n",
        "        self.dim: int | None = None\n",
        "        self.model_name: str | None = None\n",
        "\n",
        "    def fit(self, chunks: List[Document], embeddings: np.ndarray, model_name: str):\n",
        "        \"\"\"\n",
        "        chunks: your List[Document]\n",
        "        embeddings: np.ndarray of shape (N, D) aligned with chunks\n",
        "        model_name: the embedding model used (e.g., 'text-embedding-3-small')\n",
        "        \"\"\"\n",
        "        if embeddings.ndim != 2 or len(chunks) != embeddings.shape[0]:\n",
        "            raise ValueError(\"Embeddings must be 2D and aligned with chunks.\")\n",
        "        X = embeddings.astype(np.float32)\n",
        "        X = np.ascontiguousarray(X)\n",
        "        norms = np.linalg.norm(X, axis=1, keepdims=True) + 1e-12\n",
        "        self.Xn = X / norms\n",
        "        self.dim = self.Xn.shape[1]\n",
        "        self.docs = chunks\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def _embed_query(self, query: str) -> np.ndarray:\n",
        "        if not self.model_name:\n",
        "            raise RuntimeError(\"Index not initialized with a model_name. Call fit() first.\")\n",
        "        resp = client.embeddings.create(model=self.model_name, input=[query])\n",
        "        q = np.array(resp.data[0].embedding, dtype=np.float32)\n",
        "        if q.shape[0] != self.dim:\n",
        "            raise ValueError(f\"Query dim {q.shape[0]} != index dim {self.dim}. \"\n",
        "                             f\"Use the same embedding model as indexing.\")\n",
        "        q = q / (np.linalg.norm(q) + 1e-12)\n",
        "        return q  # (D,)\n",
        "\n",
        "    def search(self, query: str, top_k: int = 200) -> list[dict]:\n",
        "        if self.Xn is None:\n",
        "            raise RuntimeError(\"Index empty. Call fit() first.\")\n",
        "\n",
        "        # embed + normalize query\n",
        "        q = self._embed_query(query)                 # (D,)\n",
        "        sims = self.Xn @ q                           # (N,)\n",
        "        n = sims.shape[0]\n",
        "        k = max(1, min(top_k, n))                    # clamp to [1, N]\n",
        "\n",
        "        # For small N, argsort is fine and simpler\n",
        "        top_idx = np.argsort(sims)[::-1][:k]\n",
        "\n",
        "        results = []\n",
        "        for rank, i in enumerate(top_idx, 1):\n",
        "            d = self.docs[i]\n",
        "            results.append({\n",
        "                \"rank\": rank,\n",
        "                \"dense_score\": float(sims[i]),\n",
        "                \"resume_id\": (d.metadata or {}).get(\"resume_id\"),\n",
        "                \"chunk_id\": (d.metadata or {}).get(\"chunk_id\"),\n",
        "                \"preview\": d.page_content[:400],\n",
        "            })\n",
        "        return results\n",
        "\n"
      ],
      "metadata": {
        "id": "JSGtdfXj1W-U"
      },
      "id": "JSGtdfXj1W-U",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You already have:\n",
        "# - chunks: List[Document]\n",
        "# - embeddings: np.ndarray from your earlier OpenAI embedding step\n",
        "# - model_name: e.g., \"text-embedding-3-small\" (must match the one used for embeddings)\n",
        "\n",
        "dense = DenseIndexSimple()\n",
        "dense.fit(chunks, embeddings, model_name=\"text-embedding-3-small\")\n",
        "\n",
        "query = \"mumbai university\"\n",
        "dense_hits = dense.search(query, top_k=10)\n",
        "\n",
        "print(f\"Dense hits: {len(dense_hits)}\")\n",
        "for h in dense_hits[:5]:\n",
        "    print(f\"[{h['rank']:>2}] {h['dense_score']:.4f} resume={h['resume_id']} chunk={h['chunk_id']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKR_LxWJ6h7L",
        "outputId": "12f14902-9d44-4103-aca2-d38af4a4a121"
      },
      "id": "UKR_LxWJ6h7L",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense hits: 10\n",
            "[ 1] 0.4334 resume=VES_Ganesh_Deulkar_Resume - Ganesh Deulkar chunk=1\n",
            "[ 2] 0.3864 resume=SHAHNAWAZ_RESUME (4) - shahnawaz Shaikh chunk=2\n",
            "[ 3] 0.3802 resume=Saaquib Motiwala Resume-6 (1) - saaquib motiwala chunk=3\n",
            "[ 4] 0.3674 resume=Mohit_CV - Mohit Lohani chunk=1\n",
            "[ 5] 0.3660 resume=Resume Mollika - Mollika Garg chunk=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "def _make_key(hit: Dict[str, Any]) -> str:\n",
        "    \"\"\"Stable key to identify a chunk across lists.\"\"\"\n",
        "    rid = (hit.get(\"resume_id\") or \"\").strip()\n",
        "    cid = str(hit.get(\"chunk_id\") or \"\").strip()\n",
        "    if rid or cid:\n",
        "        return f\"{rid}::{cid}\"\n",
        "    # Fallback: hash preview if metadata missing\n",
        "    prev = (hit.get(\"preview\") or \"\")[:256]\n",
        "    return \"hash::\" + hashlib.md5(prev.encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "def rrf_fuse(\n",
        "    bm25_hits: Optional[List[Dict[str, Any]]],\n",
        "    dense_hits: Optional[List[Dict[str, Any]]],\n",
        "    k: int = 60,\n",
        "    top_k: int = 5,\n",
        "    weights: Dict[str, float] = None,\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Reciprocal Rank Fusion (RRF): score = sum_s w_s * 1/(k + rank_s)\n",
        "    - bm25_hits / dense_hits: lists with at least {'rank', 'resume_id', 'chunk_id'} (or 'preview').\n",
        "    - k: stabilization constant (common choices: 60, 100).\n",
        "    - top_k: number of fused results to return.\n",
        "    - weights: optional per-source weights, e.g., {'bm25': 1.0, 'dense': 1.0}\n",
        "    \"\"\"\n",
        "    weights = weights or {\"bm25\": 1.0, \"dense\": 1.0}\n",
        "    pool: Dict[str, Dict[str, Any]] = {}\n",
        "\n",
        "    def add_source(hits: Optional[List[Dict[str, Any]]], label: str):\n",
        "        if not hits:\n",
        "            return\n",
        "        for h in hits:\n",
        "            key = _make_key(h)\n",
        "            rec = pool.setdefault(key, {\n",
        "                \"resume_id\": h.get(\"resume_id\"),\n",
        "                \"chunk_id\": h.get(\"chunk_id\"),\n",
        "                \"preview\": h.get(\"preview\"),\n",
        "                # keep original per-source info if present\n",
        "                \"bm25_rank\": None, \"bm25_score\": None,\n",
        "                \"dense_rank\": None, \"dense_score\": None,\n",
        "                \"rrf_score\": 0.0,\n",
        "            })\n",
        "            r = h.get(\"rank\")\n",
        "            if isinstance(r, int) and r >= 1:\n",
        "                rec[\"rrf_score\"] += weights.get(label, 1.0) * (1.0 / (k + r))\n",
        "            # stash per-source details (first occurrence wins)\n",
        "            rank_key = f\"{label}_rank\"\n",
        "            score_key = f\"{label}_score\"\n",
        "            if rec[rank_key] is None:\n",
        "                rec[rank_key] = r\n",
        "            if rec[score_key] is None:\n",
        "                # hit may have 'bm25_score' or 'dense_score'\n",
        "                val = h.get(score_key) or h.get(\"bm25_score\") or h.get(\"dense_score\")\n",
        "                rec[score_key] = float(val) if val is not None else None\n",
        "\n",
        "    add_source(bm25_hits, \"bm25\")\n",
        "    add_source(dense_hits, \"dense\")\n",
        "\n",
        "    fused = sorted(pool.values(), key=lambda x: x[\"rrf_score\"], reverse=True)[:top_k]\n",
        "    # add final rank\n",
        "    for i, rec in enumerate(fused, 1):\n",
        "        rec[\"rank\"] = i\n",
        "    return fused\n"
      ],
      "metadata": {
        "id": "dsb8AnKfD5LH"
      },
      "id": "dsb8AnKfD5LH",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"Urban Water Logging Detection for Timely Intervention and Mitigation\"\n",
        "bm25_hits = bm25.search(query, top_k=10)\n",
        "dense_hits = dense.search(query, top_k=10)\n",
        "\n",
        "fused = rrf_fuse(bm25_hits, dense_hits, k=60, top_k=5, weights={\"bm25\": 2.0, \"dense\": 1.0})\n",
        "for r in fused[:10]:\n",
        "    print(f\"[{r['rank']:>2}] RRF={r['rrf_score']:.5f}  bm25_r={r['bm25_rank']}  dense_r={r['dense_rank']}\")\n",
        "    print(\"   \", (r[\"preview\"] or \"\").splitlines()[0][:120], \"...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxRZEFNMHvMp",
        "outputId": "f45bca7e-99fb-407f-a33c-aa4ceb984012"
      },
      "id": "VxRZEFNMHvMp",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1] RRF=0.04918  bm25_r=1  dense_r=1\n",
            "    ## SELECTED PROJECTS ...\n",
            "[ 2] RRF=0.04788  bm25_r=3  dense_r=2\n",
            "    ## Projects ...\n",
            "[ 3] RRF=0.04528  bm25_r=8  dense_r=3\n",
            "    ## (Google Earth Engine, EDA, LSTM, Project Management)                                                                  ...\n",
            "[ 4] RRF=0.04459  bm25_r=6  dense_r=10\n",
            "    ## PERSONAL PROJECTS ...\n",
            "[ 5] RRF=0.04456  bm25_r=7  dense_r=8\n",
            "    ## Professional Experience ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for r in fused[:5]:\n",
        "    print(r.get(\"resume_id\", \"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r5PeUQyH0k3",
        "outputId": "fdb00fa1-421e-4cd1-e22b-2227500cfd0b"
      },
      "id": "6r5PeUQyH0k3",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume Mollika - Mollika Garg\n",
            "Resume.PunithHM - Punith H M\n",
            "Md_Aamir - Md Aamir\n",
            "Basit_s AI Resume - Basit Ali\n",
            "Resume_Soham_Y - Soham Yedgaonkar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# gpu_memory_bytes=torch.cuda.get_device_properties(0).total_memory\n",
        "# gpu_memory_gb=round(gpu_memory_bytes/(2**30))\n",
        "# print(gpu_memory_gb) #15 gb available to us!!!"
      ],
      "metadata": {
        "id": "zat9NMq5Poh_"
      },
      "id": "zat9NMq5Poh_",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = (\n",
        "    userdata.get(\"OPENAI_API_KEY\") or userdata.get(\"openai_api_key\")\n",
        ")\n",
        "client=OpenAI()\n",
        "\n",
        "with open('resume_chunks_openai.pkl', 'rb') as f:\n",
        "    all_chunks = pickle.load(f)\n",
        "\n",
        "def gather_full_resumes(fused_results: List[Dict[str, Any]], all_chunks: List[Document]) -> Dict[str, str]:\n",
        "    \"\"\"Collect all chunks for each resume_id mentioned in fused results.\"\"\"\n",
        "    resume_ids = {r[\"resume_id\"] for r in fused_results if r.get(\"resume_id\")}\n",
        "\n",
        "    resume_content = {}\n",
        "    for rid in resume_ids:\n",
        "        # Get all chunks for this resume\n",
        "        resume_chunks = [c.page_content for c in all_chunks if c.metadata.get(\"resume_id\") == rid]\n",
        "        resume_content[rid] = \"\\n\\n\".join(resume_chunks)\n",
        "\n",
        "    return resume_content\n",
        "\n",
        "def summarize_resumes_with_llm(query: str, fused_results: List[Dict[str, Any]], all_chunks: List[Document], top_n: int = 5):\n",
        "    \"\"\"Generate summaries for top N resumes based on query.\"\"\"\n",
        "\n",
        "    # Get top N unique resume IDs\n",
        "    top_resume_ids = []\n",
        "    for r in fused_results:\n",
        "        rid = r.get(\"resume_id\")\n",
        "        if rid and rid not in top_resume_ids:\n",
        "            top_resume_ids.append(rid)\n",
        "        if len(top_resume_ids) >= top_n:\n",
        "            break\n",
        "\n",
        "    # Gather full resume content\n",
        "    resume_content = gather_full_resumes(fused_results, all_chunks)\n",
        "\n",
        "    summaries = []\n",
        "    for rid in top_resume_ids:\n",
        "        full_resume = resume_content.get(rid, \"\")\n",
        "\n",
        "        prompt = f\"\"\"You are a recruiter assistant. Analyze this resume and provide:\n",
        "1. A brief summary of the candidate's profile (2-3 sentences)\n",
        "2. How this candidate matches the query: \"{query}\"\n",
        "3. Key strengths relevant to the query\n",
        "\n",
        "Resume ID: {rid}\n",
        "\n",
        "Resume:\n",
        "{full_resume[:4000]}  # Limit to avoid token limits\n",
        "\n",
        "Provide a concise response.\"\"\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.3,\n",
        "            max_tokens=300\n",
        "        )\n",
        "\n",
        "        summary = response.choices[0].message.content\n",
        "        summaries.append({\n",
        "            \"resume_id\": rid,\n",
        "            \"summary\": summary,\n",
        "            \"rrf_score\": next((r[\"rrf_score\"] for r in fused_results if r.get(\"resume_id\") == rid), None)\n",
        "        })\n",
        "\n",
        "    return summaries\n"
      ],
      "metadata": {
        "id": "8SUWxZMlmb0Y"
      },
      "id": "8SUWxZMlmb0Y",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Usage\n",
        "query = \"A candidate with background in deep learning and machine learning and have a cgpa above 9.5\"\n",
        "summaries = summarize_resumes_with_llm(query, fused, all_chunks, top_n=5)\n",
        "\n",
        "for i, s in enumerate(summaries, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"RANK {i} | Resume ID: {s['resume_id']} | RRF Score: {s['rrf_score']:.5f}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(s['summary'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOh1Iybksjhl",
        "outputId": "46e42937-49ae-4a4f-db69-2edc18bf0064"
      },
      "id": "lOh1Iybksjhl",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "RANK 1 | Resume ID: Atharva Domale Resume - Atharva Domale | RRF Score: 0.03126\n",
            "============================================================\n",
            "1. The candidate is a Bachelor of Technology in Artificial Intelligence and Data Science with a GPA of 7/10. They have experience in developing and implementing machine learning models, data analysis projects, and certifications in AI and cloud platforms.\n",
            "\n",
            "2. This candidate does not meet the query of having a CGPA above 9.5, as their GPA is 7/10.\n",
            "\n",
            "3. Key strengths relevant to the query include a strong understanding of deep learning and machine learning technologies, proficiency in data analysis and model optimization, and certifications in AI and cloud platforms.\n",
            "\n",
            "============================================================\n",
            "RANK 2 | Resume ID: Resume - Nahid Kawsar | RRF Score: 0.03110\n",
            "============================================================\n",
            "1. Nahid Kawsar is an aspiring machine learning engineer with a strong foundation in applied mathematics, specializing in NLP, deep learning, and generative AI. They have experience in leveraging machine learning frameworks and data science tools to solve complex problems.\n",
            "\n",
            "2. Nahid Kawsar matches the query as they have a background in deep learning and machine learning, as evidenced by their projects such as \"Chest X-ray with VGG16 Transfer Learning\" and \"Movie Review Analysis - Sentiment Analysis.\" Additionally, they are currently pursuing a BSc in Applied Mathematics with a CGPA of 3.63, which can be converted to a scale above 9.5.\n",
            "\n",
            "3. Key strengths relevant to the query include expertise in deep learning techniques such as ANN, CNN, RNN, LSTM, Transformers, and Attention Mechanism. They also have experience with machine learning frameworks like scikit-learn and TensorFlow (Keras) and have completed certifications in machine learning, neural networks, and generative AI.\n",
            "\n",
            "============================================================\n",
            "RANK 3 | Resume ID: ATS_Resume_Dev - Dev Bhanushali | RRF Score: 0.02899\n",
            "============================================================\n",
            "1. Dev Bhanushali is an AI student with a passion for software development and applied AI research. He has experience in app development, predictive maintenance, and deep learning techniques, with a focus on achieving high accuracy in real-world applications.\n",
            "\n",
            "2. Dev Bhanushali matches the query as he has a background in deep learning and machine learning, as evidenced by his projects such as \"Bearing Prognosis using Gated Recurrent Unit Networks\" and \"Hindi Handwritten Text Synthesis using Generative Methods.\" Additionally, his academic achievements and research publications showcase his expertise in these areas.\n",
            "\n",
            "3. Key strengths relevant to the query include hands-on experience in developing fully functional software apps, applying advanced deep learning techniques, and achieving high accuracy in real-world applications. Dev's projects demonstrate his proficiency in deep learning and machine learning, making him a strong candidate for roles requiring expertise in these areas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('resume_chunks_openai.pkl', 'rb') as f:\n",
        "    all_chunks = pickle.load(f)"
      ],
      "metadata": {
        "id": "ubq2EpHCfSCe"
      },
      "id": "ubq2EpHCfSCe",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "import torch\n",
        "\n",
        "# Load cross-encoder reranker\n",
        "reranker = CrossEncoder(\n",
        "    \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "def rerank_with_cross_encoder(query: str, fused_results: List[Dict[str, Any]], all_chunks: List[Document], top_k: int = 10) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Rerank fused results using cross-encoder for better relevance\"\"\"\n",
        "\n",
        "    # Get full chunk content for each result\n",
        "    pairs = []\n",
        "    valid_results = []\n",
        "\n",
        "    for r in fused_results:\n",
        "        resume_id = r.get(\"resume_id\")\n",
        "        chunk_id = r.get(\"chunk_id\")\n",
        "\n",
        "        # Find matching chunk\n",
        "        matching_chunk = next(\n",
        "            (c for c in all_chunks if c.metadata.get(\"resume_id\") == resume_id and c.metadata.get(\"chunk_id\") == chunk_id),\n",
        "            None\n",
        "        )\n",
        "\n",
        "        if matching_chunk:\n",
        "            pairs.append((query, matching_chunk.page_content))\n",
        "            valid_results.append(r)\n",
        "\n",
        "    # Get cross-encoder scores\n",
        "    ce_scores = reranker.predict(pairs).tolist()\n",
        "\n",
        "    # Add cross-encoder scores to results\n",
        "    for result, score in zip(valid_results, ce_scores):\n",
        "        result[\"ce_score\"] = float(score)\n",
        "\n",
        "    # Sort by cross-encoder score\n",
        "    reranked = sorted(valid_results, key=lambda x: x[\"ce_score\"], reverse=True)[:top_k]\n",
        "\n",
        "    # Update ranks\n",
        "    for i, r in enumerate(reranked, 1):\n",
        "        r[\"rerank_position\"] = i\n",
        "\n",
        "    return reranked\n",
        "\n"
      ],
      "metadata": {
        "id": "qu8bhaP4k34T"
      },
      "id": "qu8bhaP4k34T",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage\n",
        "query = \"A candidate with a background in machine learning and deep learning and has a GPA above 8\"\n",
        "bm25_hits = bm25.search(query, top_k=10)\n",
        "dense_hits = dense.search(query, top_k=10)\n",
        "fused = rrf_fuse(bm25_hits, dense_hits, k=60, top_k=3)\n",
        "\n",
        "# Rerank top 50 results to get final top 10\n",
        "reranked = rerank_with_cross_encoder(query, fused, all_chunks, top_k=10)\n",
        "\n",
        "print(\"RERANKED RESULTS:\")\n",
        "for r in reranked:\n",
        "    print(f\"[{r['rerank_position']:>2}] CE={r['ce_score']:.4f} RRF={r['rrf_score']:.5f} resume={r['resume_id']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4kcGxpOfK-U",
        "outputId": "b5d3fcee-2ae6-4bcc-d0eb-c92a00ffb51c"
      },
      "id": "E4kcGxpOfK-U",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RERANKED RESULTS:\n",
            "[ 1] CE=-0.8739 RRF=0.03110 resume=Resume - Nahid Kawsar\n",
            "[ 2] CE=-2.1342 RRF=0.03126 resume=Atharva Domale Resume - Atharva Domale\n",
            "[ 3] CE=-6.8400 RRF=0.02899 resume=ATS_Resume_Dev - Dev Bhanushali\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage\n",
        "query = \"A candidate with background in deep learning and machine learning and have a cgpa above 9.5\"\n",
        "summaries = summarize_resumes_with_llm(query, reranked, all_chunks, top_n=5)\n",
        "\n",
        "for i, s in enumerate(summaries, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"RANK {i} | Resume ID: {s['resume_id']} | RRF Score: {s['rrf_score']:.5f}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(s['summary'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFRWAS1sfmXe",
        "outputId": "7fd81b1f-ffac-4777-849d-daba96a91e7d"
      },
      "id": "wFRWAS1sfmXe",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "RANK 1 | Resume ID: Resume - Nahid Kawsar | RRF Score: 0.03110\n",
            "============================================================\n",
            "1. The candidate, Nahid Kawsar, is an aspiring machine learning engineer with a strong foundation in applied mathematics, specializing in NLP, deep learning, and generative AI. They have experience in leveraging machine learning frameworks and data science tools to solve complex problems.\n",
            "\n",
            "2. Nahid Kawsar matches the query for a candidate with a background in deep learning and machine learning as they have experience in deep learning with various neural network architectures, transfer learning, and generative AI. However, their current CGPA of 3.63 does not meet the requirement of above 9.5.\n",
            "\n",
            "3. Key strengths relevant to the query include expertise in deep learning with various architectures such as ANN, CNN, RNN, LSTM, Transformers, and Attention Mechanism. They also have experience with transfer learning using models like VGG16, VGG19, AlexNet, ResNet, EfficientNet, and MobileNet. Additionally, their specialization in NLP and generative AI showcases their proficiency in advanced machine learning techniques.\n",
            "\n",
            "============================================================\n",
            "RANK 2 | Resume ID: Atharva Domale Resume - Atharva Domale | RRF Score: 0.03126\n",
            "============================================================\n",
            "1. The candidate is a Bachelor of Technology in Artificial Intelligence and Data Science with a GPA of 7/10. They have experience in developing and implementing machine learning models, data analysis projects, and certifications in AI-related fields.\n",
            "\n",
            "2. This candidate does not meet the query of having a CGPA above 9.5, as their GPA is 7/10.\n",
            "\n",
            "3. Key strengths relevant to the query include a strong understanding of deep learning and machine learning concepts, experience in developing machine learning models, and proficiency in AI/ML frameworks such as TensorFlow and PyTorch.\n",
            "\n",
            "============================================================\n",
            "RANK 3 | Resume ID: ATS_Resume_Dev - Dev Bhanushali | RRF Score: 0.02899\n",
            "============================================================\n",
            "1. Dev Bhanushali is an AI student with a passion for software development and applied AI research. He has experience in app development, predictive maintenance, and deep learning techniques, with a focus on achieving high accuracy in real-world applications.\n",
            "\n",
            "2. Dev Bhanushali matches the query as he has experience in deep learning techniques, machine learning projects, and a strong academic background with international exposure. His hands-on experience in developing software apps and applying advanced AI techniques align well with the requirements.\n",
            "\n",
            "3. Key strengths relevant to the query include hands-on experience in deep learning techniques, machine learning projects, and achieving high accuracy in real-world applications. Additionally, his academic exposure and participation in diverse AI projects showcase his strong background in AI and software development.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from typing import Optional, Dict, Any\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "def extract_gpa(text: str) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Extract GPA/CGPA from text with multiple pattern variations.\n",
        "    Returns dict with gpa_value and gpa_scale, or None if not found.\n",
        "    \"\"\"\n",
        "    # Common GPA patterns\n",
        "    patterns = [\n",
        "        # CGPA: 9.2/10, GPA: 3.8/4.0, CGPA 8.5 / 10\n",
        "        r'(?:cgpa|gpa|cpi|spi)\\s*[:\\-]?\\s*(\\d+\\.?\\d*)\\s*(?:/|out of)\\s*(\\d+\\.?\\d*)',\n",
        "\n",
        "        # 9.2 CGPA, 3.8 GPA\n",
        "        r'(\\d+\\.?\\d*)\\s+(?:cgpa|gpa|cpi|spi)',\n",
        "\n",
        "        # CGPA 9.2, GPA 3.8\n",
        "        r'(?:cgpa|gpa|cpi|spi)\\s+(\\d+\\.?\\d*)',\n",
        "\n",
        "        # Percentage: 85%, 92.5%\n",
        "        r'(\\d+\\.?\\d*)\\s*%',\n",
        "\n",
        "        # Grade: 9.2 (common in bullet points)\n",
        "        r'(?:grade|score|marks?)\\s*[:\\-]?\\s*(\\d+\\.?\\d*)\\s*(?:/|out of)\\s*(\\d+\\.?\\d*)',\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for pattern in patterns:\n",
        "        matches = re.finditer(pattern, text, re.IGNORECASE)\n",
        "        for match in matches:\n",
        "            if len(match.groups()) == 2:\n",
        "                # Has scale: 9.2/10\n",
        "                gpa_value = float(match.group(1))\n",
        "                gpa_scale = float(match.group(2))\n",
        "            else:\n",
        "                # No scale: just \"9.2 CGPA\"\n",
        "                gpa_value = float(match.group(1))\n",
        "                # Infer scale based on value\n",
        "                if gpa_value <= 4.5:\n",
        "                    gpa_scale = 4.0\n",
        "                elif gpa_value <= 10.5:\n",
        "                    gpa_scale = 10.0\n",
        "                elif gpa_value <= 100:\n",
        "                    gpa_scale = 100.0  # Percentage\n",
        "                else:\n",
        "                    continue  # Invalid value\n",
        "\n",
        "            # Validate ranges\n",
        "            if 0 <= gpa_value <= gpa_scale:\n",
        "                results.append({\n",
        "                    \"gpa_value\": gpa_value,\n",
        "                    \"gpa_scale\": gpa_scale,\n",
        "                    \"gpa_normalized\": round(gpa_value / gpa_scale * 10, 2),  # Normalize to /10\n",
        "                    \"match_text\": match.group(0)\n",
        "                })\n",
        "\n",
        "    # Return first valid match\n",
        "    return results[0] if results else None\n",
        "\n",
        "def add_gpa_to_chunks(chunks: List[Document]) -> List[Document]:\n",
        "    \"\"\"Add GPA metadata to each chunk\"\"\"\n",
        "    enriched_chunks = []\n",
        "\n",
        "    for chunk in chunks:\n",
        "        gpa_info = extract_gpa(chunk.page_content)\n",
        "\n",
        "        # Create new metadata dict with GPA info\n",
        "        new_metadata = chunk.metadata.copy()\n",
        "        if gpa_info:\n",
        "            new_metadata[\"gpa_value\"] = gpa_info[\"gpa_value\"]\n",
        "            new_metadata[\"gpa_scale\"] = gpa_info[\"gpa_scale\"]\n",
        "            new_metadata[\"gpa_normalized\"] = gpa_info[\"gpa_normalized\"]\n",
        "            new_metadata[\"gpa_found\"] = True\n",
        "        else:\n",
        "            new_metadata[\"gpa_value\"] = None\n",
        "            new_metadata[\"gpa_scale\"] = None\n",
        "            new_metadata[\"gpa_normalized\"] = None\n",
        "            new_metadata[\"gpa_found\"] = False\n",
        "\n",
        "        # Create new Document with updated metadata\n",
        "        enriched_chunk = Document(\n",
        "            page_content=chunk.page_content,\n",
        "            metadata=new_metadata\n",
        "        )\n",
        "        enriched_chunks.append(enriched_chunk)\n",
        "\n",
        "    return enriched_chunks\n",
        "\n",
        "def analyze_gpa_coverage(chunks: List[Document]) -> Dict[str, Any]:\n",
        "    \"\"\"Analyze GPA extraction coverage across resumes\"\"\"\n",
        "\n",
        "    # Group by resume_id\n",
        "    resumes_with_gpa = set()\n",
        "    resumes_without_gpa = set()\n",
        "    total_chunks_with_gpa = 0\n",
        "    gpa_values = []\n",
        "\n",
        "    for chunk in chunks:\n",
        "        resume_id = chunk.metadata.get(\"resume_id\")\n",
        "\n",
        "        if chunk.metadata.get(\"gpa_found\"):\n",
        "            resumes_with_gpa.add(resume_id)\n",
        "            total_chunks_with_gpa += 1\n",
        "            gpa_values.append(chunk.metadata.get(\"gpa_normalized\"))\n",
        "        else:\n",
        "            if resume_id not in resumes_with_gpa:\n",
        "                resumes_without_gpa.add(resume_id)\n",
        "\n",
        "    # Remove resumes from \"without\" set if they have GPA in any chunk\n",
        "    resumes_without_gpa -= resumes_with_gpa\n",
        "\n",
        "    total_resumes = len(resumes_with_gpa) + len(resumes_without_gpa)\n",
        "    coverage_pct = (len(resumes_with_gpa) / total_resumes * 100) if total_resumes > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"total_resumes\": total_resumes,\n",
        "        \"resumes_with_gpa\": len(resumes_with_gpa),\n",
        "        \"resumes_without_gpa\": len(resumes_without_gpa),\n",
        "        \"coverage_percentage\": round(coverage_pct, 2),\n",
        "        \"total_chunks_with_gpa\": total_chunks_with_gpa,\n",
        "        \"avg_gpa_normalized\": round(sum(gpa_values) / len(gpa_values), 2) if gpa_values else None,\n",
        "        \"min_gpa\": min(gpa_values) if gpa_values else None,\n",
        "        \"max_gpa\": max(gpa_values) if gpa_values else None,\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# USAGE\n",
        "# ============================================================\n",
        "\n",
        "# Load your chunks\n",
        "with open('resume_chunks_openai.pkl', 'rb') as f:\n",
        "    chunks = pickle.load(f)\n",
        "\n",
        "print(f\"Original chunks: {len(chunks)}\")\n",
        "\n",
        "# Add GPA metadata\n",
        "enriched_chunks = add_gpa_to_chunks(chunks)\n",
        "\n",
        "# Analyze coverage\n",
        "coverage = analyze_gpa_coverage(enriched_chunks)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GPA EXTRACTION COVERAGE REPORT\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total Resumes: {coverage['total_resumes']}\")\n",
        "print(f\"Resumes with GPA: {coverage['resumes_with_gpa']}\")\n",
        "print(f\"Resumes without GPA: {coverage['resumes_without_gpa']}\")\n",
        "print(f\"Coverage: {coverage['coverage_percentage']}%\")\n",
        "print(f\"\\nTotal chunks with GPA: {coverage['total_chunks_with_gpa']}\")\n",
        "print(f\"Average GPA (normalized /10): {coverage['avg_gpa_normalized']}\")\n",
        "print(f\"GPA Range: {coverage['min_gpa']} - {coverage['max_gpa']}\")\n",
        "\n",
        "# Show some examples\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAMPLE EXTRACTIONS (First 5 with GPA)\")\n",
        "print(\"=\"*60)\n",
        "count = 0\n",
        "for chunk in enriched_chunks:\n",
        "    if chunk.metadata.get(\"gpa_found\") and count < 5:\n",
        "        print(f\"\\nResume: {chunk.metadata['resume_id']}\")\n",
        "        print(f\"GPA: {chunk.metadata['gpa_value']}/{chunk.metadata['gpa_scale']} (Normalized: {chunk.metadata['gpa_normalized']}/10)\")\n",
        "        print(f\"Preview: {chunk.page_content[:200]}...\")\n",
        "        count += 1\n",
        "\n",
        "# Save enriched chunks\n",
        "with open('resume_chunks_with_gpa.pkl', 'wb') as f:\n",
        "    pickle.dump(enriched_chunks, f)\n",
        "\n",
        "print(f\"\\n✅ Saved enriched chunks to 'resume_chunks_with_gpa.pkl'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcjUi5b3geYi",
        "outputId": "003616b6-0c7d-4e55-fe16-39959b7e9ba3"
      },
      "id": "pcjUi5b3geYi",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original chunks: 249\n",
            "\n",
            "============================================================\n",
            "GPA EXTRACTION COVERAGE REPORT\n",
            "============================================================\n",
            "Total Resumes: 52\n",
            "Resumes with GPA: 33\n",
            "Resumes without GPA: 19\n",
            "Coverage: 63.46%\n",
            "\n",
            "Total chunks with GPA: 54\n",
            "Average GPA (normalized /10): 7.43\n",
            "GPA Range: 0.18 - 9.99\n",
            "\n",
            "============================================================\n",
            "SAMPLE EXTRACTIONS (First 5 with GPA)\n",
            "============================================================\n",
            "\n",
            "Resume: zaid_resume_data - Zaid Ahmed Khan\n",
            "GPA: 95.6/100.0 (Normalized: 9.56/10)\n",
            "Preview: ## EDUCATION\n",
            "\n",
            "|   Year | Degree/Exam                 | Institute                                  | CGPA/Marks   |\n",
            "|--------|-----------------------------|--------------------------------------------|...\n",
            "\n",
            "Resume: zaid_resume_data - Zaid Ahmed Khan\n",
            "GPA: 97.0/100.0 (Normalized: 9.7/10)\n",
            "Preview: ## COMPETITION/CONFERENCE\n",
            "\n",
            "## Automatic liquid detecting system | Computer Vision | ML | Empower IIT Madras| Prof. P K Dan (Gold) Link\n",
            "\n",
            "\n",
            "\n",
            "- Innovated a Computer-Vision based product for liquid volume ...\n",
            "\n",
            "Resume: zaid_resume_data - Zaid Ahmed Khan\n",
            "GPA: 56.2/100.0 (Normalized: 5.62/10)\n",
            "Preview: ## PROJECTS\n",
            "\n",
            "## Hangman Challenge | Reinforcement Learning | Natural Language Processing | TrexQuant\n",
            "\n",
            "\n",
            "\n",
            "- Build a Hangman Game using NLP and RL , utilized length of word to make initial guess &amp; 2-...\n",
            "\n",
            "Resume: zaid_resume_data - Zaid Ahmed Khan\n",
            "GPA: 2.0/4.0 (Normalized: 5.0/10)\n",
            "Preview: ## PATENT/PUBLICATIONS\n",
            "\n",
            "- Intelligent Three-Stage OCR System for Robust Document Optical Character Recognition , IPR(Intellectual property rights) Patent Shakti Kaushal, Sujeet Kumar, Zaid Ahmed Khan ...\n",
            "\n",
            "Resume: DIVYABHARATHI S 2024 resume pdf - Divyabharathi S\n",
            "GPA: 71.0/100.0 (Normalized: 7.1/10)\n",
            "Preview: ## EDUCATION\n",
            "\n",
            "D G VAISHNAV COLLEGE [2017-2020]\n",
            "\n",
            "Bachelor of Science in Physics with Computer Applications OOPS, Basics of C++, JAVA, Data structure Marks obtained - 71%\n",
            "\n",
            "ICF SILVER JUBILEE MATRICULATI...\n",
            "\n",
            "✅ Saved enriched chunks to 'resume_chunks_with_gpa.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('resume_chunks_with_gpa.pkl', 'rb') as f:\n",
        "    gpa_chunks = pickle.load(f)"
      ],
      "metadata": {
        "id": "x7Xj-b4WzqHz"
      },
      "id": "x7Xj-b4WzqHz",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpa_chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfMfCDbaz9q8",
        "outputId": "ffb3355c-29c6-4f50-953e-d11be6c79cb3"
      },
      "id": "FfMfCDbaz9q8",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'resume_id': 'zaid_resume_data - Zaid Ahmed Khan', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## ZAID AHMED KHAN | https://www.linkedin.com/in/zaid-ahmed-khan-/\\n\\nPhone No. +918770642550 | Email Idik241168@gmail.com\\n\\nChemical Engineering (B.Tech+M.Tech),Artificial Intelligence (Micro)'),\n",
              " Document(metadata={'resume_id': 'zaid_resume_data - Zaid Ahmed Khan', 'chunk_id': 1, 'gpa_value': 95.6, 'gpa_scale': 100.0, 'gpa_normalized': 9.56, 'gpa_found': True}, page_content='## EDUCATION\\n\\n|   Year | Degree/Exam                 | Institute                                  | CGPA/Marks   |\\n|--------|-----------------------------|--------------------------------------------|--------------|\\n|   2026 | Dual Degree (B.Tech+M.Tech) | IIT Kharagpur                              | 8.80/ 10     |\\n|   2021 | CLASS XII                   | Christ Church Boys Senior Secondary School | 95.60%       |\\n|   2019 | CLASS X                     | Christ Church Boys Senior Secondary School | 96.40%       |'),\n",
              " Document(metadata={'resume_id': 'zaid_resume_data - Zaid Ahmed Khan', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## AWARDS / ACHIEVEMENTS\\n\\n- Offered Summer Intern Role at ITC Limited and Amazon India through on campus hiring, successfully clearing upto 5 rounds\\n- Secured first prize in Empower, representing IIT KGP at IIT Madras and got a rank of 3569 in round-2 of Facebook Hackercup\\n- Achieved a rating of 1630 (Expert) on Codeforces, 1903 on CodeChef and got a rank of 91 out of 20,000+ in CodeChef Contest\\n- Participated in ICUAS 2023 Conference and among top 40 teams out of 2600+ contesting teams in E-Yantra IIT Bombay 2022\\n- Won gold in GC Hall Data Analytics, 2nd prize in Datahunt ML Hackathon &amp; ranked among top 5 teams in KDSH ML Hackathon'),\n",
              " Document(metadata={'resume_id': 'zaid_resume_data - Zaid Ahmed Khan', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## RESEARCH EXPERIENCE\\n\\n## Natural Language Processing Intern | Under Professor Anil Kumar Singh | IIT (BHU) Varanasi May'23 -July' 23\\n\\n- Aimed at building a Fast Machine Learning Translation model based on Transformer architecture for regional Indian Languages\\n- Used Stanford parser to convert sentences dataset to parse tree for extracting features and then applied some basic models\\n- Adapted Trankit , a python library and increased it's implementation speed by using CoNLL-U library to convert the CoNLL data\\n- Trained a Biaffine graph-based dependency parser for tasks such as POS tagging etc. and got a cross-validation loss of 0.42\"),\n",
              " Document(metadata={'resume_id': 'zaid_resume_data - Zaid Ahmed Khan', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## INDUSTRIAL EXPERIENCE\\n\\n## Generative AI Intern | Offered by LimitPush Technologies Private Limited | New Delhi, India Nov'23 -Apr'24\\n\\n- Constructed a RAG based LLM chatbot using Open AI API and utilized FAST API and Whisper Live for real-time implementation\\n- Used Langchain to improve the chat-bot made &amp; did a comparative analysis between Pinecone, MongoDB Atlas Vector Search etc\\n- Aimed at building a generative AI based model using Stable Diffusion XL &amp; Fine-tuning it using DreamBooth, Textual Inversion\"),\n",
              " Document(metadata={'resume_id': 'zaid_resume_data - Zaid Ahmed Khan', 'chunk_id': 5, 'gpa_value': 97.0, 'gpa_scale': 100.0, 'gpa_normalized': 9.7, 'gpa_found': True}, page_content='## COMPETITION/CONFERENCE\\n\\n## Automatic liquid detecting system | Computer Vision | ML | Empower IIT Madras| Prof. P K Dan (Gold) Link\\n\\n\\n\\n- Innovated a Computer-Vision based product for liquid volume detection, making higher education accessible to blind individuals\\n- Developed a Web App using Streamlit and deployed the whole code on it and made a dedicated hardware setup for the product\\n- Utilized Python library gTTS for converting voice input to text and achieved an accuracy of 93-97% with a negligible running time\\n\\n## Cracks Detection System | CNN | Deep Learning | ICUAS 2023 Conference\\n\\n\\n\\n- Build a CNN model using PyTorch for identifying if an image contains cracks or not from the images provided by drone camera\\n- Applied different Image Argumentation method like Rotating, Distorting, Flipping etc to make the dataset balanced to avoid bias\\n- Implemented Transfer Learning on YoloV7 &amp; trained it on 92,000 images dataset &amp; achieved a confidence level of 91% overall'),\n",
              " Document(metadata={'resume_id': 'zaid_resume_data - Zaid Ahmed Khan', 'chunk_id': 6, 'gpa_value': 56.2, 'gpa_scale': 100.0, 'gpa_normalized': 5.62, 'gpa_found': True}, page_content='## PROJECTS\\n\\n## Hangman Challenge | Reinforcement Learning | Natural Language Processing | TrexQuant\\n\\n\\n\\n- Build a Hangman Game using NLP and RL , utilized length of word to make initial guess &amp; 2-gram model to make later guesses\\n- Used LSTM model to introduce some randomness in later guesses and used Monte Carlo Simultation to make stable guesses\\n- Did Exploratory Data Analysis (EDA) &amp; found out a method to skip guess of some words to reduce the running time of the model\\n- Generated dataset for training using Word2Batch Class to convert the dictionary into embedding &amp; achieved a accuracy of 56.2%'),\n",
              " Document(metadata={'resume_id': 'zaid_resume_data - Zaid Ahmed Khan', 'chunk_id': 7, 'gpa_value': 2.0, 'gpa_scale': 4.0, 'gpa_normalized': 5.0, 'gpa_found': True}, page_content=\"## PATENT/PUBLICATIONS\\n\\n- Intelligent Three-Stage OCR System for Robust Document Optical Character Recognition , IPR(Intellectual property rights) Patent Shakti Kaushal, Sujeet Kumar, Zaid Ahmed Khan , Bhagyashree M Dhakulkar\\n- The Model comprises of a combination of CNN &amp; RNN based network for classification task and U-Net for Text Detection Task\\n\\n## POSITIONS OF RESPONSIBILITY\\n\\n## Amazon Web Service (AWS) Cloud Club Captain, IIT Kharagpur\\n\\nMar'24-Present\\n\\n- Selected as AWS Cloud Club Captain ( selection rate-2% ) to lead student-led user group, educating about cloud technologies\\n- One of 87 Global AWS Cloud Captains, responsible for organizing events and fostering cloud computing skills among students\"),\n",
              " Document(metadata={'resume_id': 'zaid_resume_data - Zaid Ahmed Khan', 'chunk_id': 8, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS AND EXPERTISE\\n\\nLanguages: Proficient:C++ Intermediate :Python Familiar : JavaScript | C | TypeScript | MATLAB | SolidWork Technologies : HTML5 | CSS | JavaScript | Pytorch | Tensorflow | Numpy | Pandas | Postman | OpenCV | SQL | Github | Seaborn'),\n",
              " Document(metadata={'resume_id': 'DIVYABHARATHI S 2024 resume pdf - Divyabharathi S', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## PROFILE\\n\\nI am a Computer Applications and Physics graduate. I have basic skills in a few programming languages, and I am always pursuing more knowledge to improve my skills. I am a dedicated learner, always striving to achieve greater success by working hard and pushing myself to learn and grow.\\n\\n## CONTACT\\n\\nPHONE: 6380408218\\n\\nWEBSITE:\\n\\nlinkedin.com/in/divyabharathi-s560787206\\n\\nEMAIL:\\n\\nrathidivya26@gmail.com'),\n",
              " Document(metadata={'resume_id': 'DIVYABHARATHI S 2024 resume pdf - Divyabharathi S', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## PROJECTS\\n\\n1. OCR Project for documents reading - 6 months\\n3. Face detection using OpenCV\\n2. Heart disease prediction using Naive Bayes\\n4. Chatbot development\\n5. Tag identification using NLP\\n\\n## DIVYABHARATHI S\\n\\nAssociate'),\n",
              " Document(metadata={'resume_id': 'DIVYABHARATHI S 2024 resume pdf - Divyabharathi S', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## WORK EXPERIENCE\\n\\nProcess Associate - Mr. Cooper NSM\\n\\nExperience in US Mortgage, Reverse mortgage, Loan documents, MS Excel Operations.\\n\\n[Mar 2021] - [Jun 2022]\\n\\n## Data Associate - Fourkites\\n\\nExperience in Salesforce queue, Shipping documents verification, Shipment Track, and trace - Operations.\\n\\n[Sep 2022] - [Jul 2024]\\n\\nInternship - AI developer [Jul - Aug 2024]\\n\\nAI, Deep learning, Machine learning, NLP, Python and Computer vision.'),\n",
              " Document(metadata={'resume_id': 'DIVYABHARATHI S 2024 resume pdf - Divyabharathi S', 'chunk_id': 3, 'gpa_value': 71.0, 'gpa_scale': 100.0, 'gpa_normalized': 7.1, 'gpa_found': True}, page_content='## EDUCATION\\n\\nD G VAISHNAV COLLEGE [2017-2020]\\n\\nBachelor of Science in Physics with Computer Applications OOPS, Basics of C++, JAVA, Data structure Marks obtained - 71%\\n\\nICF SILVER JUBILEE MATRICULATION HIGHER SECONDARY SCHOOL HSC - STATE BOARD [2016-2017] BIOLOGY / MATHS Marks obtained - 84%\\n\\nICF SILVER JUBILEE MATRICULATION HIGHER SECONDARY SCHOOL SSLC - STATE BOARD [2014-2015] MARKS OBTAINED - 92%'),\n",
              " Document(metadata={'resume_id': 'DIVYABHARATHI S 2024 resume pdf - Divyabharathi S', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## KEY SKILLS &amp; CHARACTERISTICS\\n\\n- Ocean shipment tracking.\\n- Basic C++, JAVA, OOPS concept, python and SQL concepts.\\n- Reverse Mortgage and loan processing.\\n- Libraries like Tensorflow, Sci-kit, Keras and pytorch.\\n\\n.'),\n",
              " Document(metadata={'resume_id': 'Dev Vrat Sharma - Resume - Dev Vrat Sharma', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## EXPERIENCE\\n\\nML Engineering Intern @ ISRO Research Laboratory (PRL):Developed and deployed various ML models to clean and pre-process the huge datasets consisting in netCDF format, achieving 0.92 accuracy. Used the dataset to plot the emission and concentration of pollutants using OpenCV.\\n\\nAI/ML Research Intern @ NIT Delhi:Applied machine learning algorithms on large datasets to solve complex classification problems. Collaborated with teams to integrate results into cloud-based systems.\\n\\nUtilized version control tools like Git for effective team collaboration and code management.\\n\\nContent Correspondent Intern @ Aashman Foundation:Conducted statistical research on slums in developed nations, providing valuable insights for the foundation's initiatives that improved outreach efforts by 5 percent\"),\n",
              " Document(metadata={'resume_id': 'Dev Vrat Sharma - Resume - Dev Vrat Sharma', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## PROJECTS\\n\\nGenerative AI: Text-to-Image-Generator (07/2024 - 09/2024 ):Developed a web application over Streamlit that generates images from text inputs using Amazon's Titan LLM model. Users can create diverse images simply by typing in names or descriptions, showcasing the power of advanced language models for creative visual content generation.\\n\\nNLP Project: Sentiment Analysis and Labelling of Tweets (05/2024 - 07/2024 ):Developed an NLP pipeline for tweet sentiment analysis using GloVe, LSTM, Decision Tree, Random Forest, Logistic Regression, KNN, and SVM achieving 0.92 accuracy in analyzing sentiments.\\n\\nBERT: Topic Segmentation Model (03/2024 - 04/2024):Developed an advanced ML model using BERTopic for precise query segmentation by topic from a large dataset with 0.93 precision. Leveraged state-of-the-art techniques and outputted comprehensive results in a detailed Excel report.\"),\n",
              " Document(metadata={'resume_id': 'Dev Vrat Sharma - Resume - Dev Vrat Sharma', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS\\n\\nProgramming Languages:\\n\\nPython, Java, C, C++\\n\\nLarge Language Models:\\n\\nClaude, Llama, Titan, BERT\\n\\nML Algorithms:\\n\\nSVM, Naive Bayes, KNN, RBM, Decision Tree, Random Forest\\n\\nAI Algorithms:\\n\\nAnt Colony Optimization, Particle Swarm Optimization,\\n\\nButterfly Optimization Algorithm\\n\\nDeep Neural Networks:\\n\\nLSTM, RNN, CNN\\n\\nNLP Models:\\n\\nBERT, Glove, FastText\\n\\nML Frameworks:\\n\\nTensorFlow, PyTorch, Keras, NLTK, Gensim\\n\\nTools:\\n\\nSQL, Google Colab, Kaggle, Jupyter Notebooks, VS Code, AWS Cloud, NetBeans'),\n",
              " Document(metadata={'resume_id': 'Dev Vrat Sharma - Resume - Dev Vrat Sharma', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## EDUCATION\\n\\nB.Tech in Computer Science , Shri Mata Vaishno Devi University\\n\\nExpected 2025\\n\\nCGPA: 8.58\\n\\n12th Boards(Non-Medical) , SP Smart Hr. Sec. School\\n\\n2020 - 2021\\n\\nPercentage: 98\\n\\n## CERTIFICATIONS\\n\\n- Supervised Machine Learning\\n- Introduction to Artificial Intelligence (AI)\\n- Introduction to Cybersecurity\\n\\n## DEV VRAT SHARMA\\n\\n+91 9906130621\\n\\nsdevvrat088@gmail.com ⋄ Linkedin ⋄ Kaggle ⋄ GitHub ⋄ X ⋄'),\n",
              " Document(metadata={'resume_id': 'ShrutiGuptaResume - SHRUTI GUPTA', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Shruti Gupta\\n\\n\\n\\n\\n\\n/star\\n\\nPortfolio\\n\\n/github\\n\\nGithub\\n\\n/code\\n\\nLeetcode\\n\\n/dribbble Dribbble\\n\\n/linkedin\\n\\nLinkedIn\\n\\n/envelope\\n\\nshrutigupta.kin@gmail.com\\n\\n/phone\\n\\n8279819423'),\n",
              " Document(metadata={'resume_id': 'ShrutiGuptaResume - SHRUTI GUPTA', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education\\n\\n## Indian Institute of Information Technology Vadodara\\n\\nBachelor of Technology in Computer Science'),\n",
              " Document(metadata={'resume_id': 'ShrutiGuptaResume - SHRUTI GUPTA', 'chunk_id': 2, 'gpa_value': 75.0, 'gpa_scale': 100.0, 'gpa_normalized': 7.5, 'gpa_found': True}, page_content=\"## Experience\\n\\n## ServiceNow | Associate Software Engineer Intern\\n\\n2021-2025\\n\\nMay 2024- Jul 2024\\n\\n- Collaborated with a 5-member Digital Technology team to enhance partner portal, impacting 120+ employees\\n- Engineered a custom application using Generative AI, UI Builder, Flow Designer, IntegrationHub, Script Includes, and ACLs, increasing efficiency by 75% and minimizing human error\\n- Engaged in agile development methodology to understand development style in growth companies\\n\\n## Zeitgeist- IIT Ropar | UI/UX Designer\\n\\nAug 2023 - Oct 2023\\n\\n- Designed an engaging website for Zeitgeist, the cultural festival of IIT Ropar, attracting 20,000 visitors\\n- Optimized user experience, contributing to enhanced digital presence for the festival\\n- Boosted visitor traffic by 33% despite challenges from the 'Vintage Voyage' retro theme\"),\n",
              " Document(metadata={'resume_id': 'ShrutiGuptaResume - SHRUTI GUPTA', 'chunk_id': 3, 'gpa_value': 89.0, 'gpa_scale': 100.0, 'gpa_normalized': 8.9, 'gpa_found': True}, page_content='## Projects\\n\\n## YouText- Youtube Summarizer /link | Python, ML (Whisper, Pegasus, Bart Models)\\n\\n- Developed a video content summarizer using advanced ML models, achieving up to 89% accuracy\\n- Integrated manual, API-driven and AI powered methods, 4+ advanced models for transcription and summarization\\n- Evaluated performance using BertScore, ROUGE, &amp; METEOR metrics, achieving 46% baseline accuracy\\n\\n## Portfolio Website /link | Next, 3JS, GSAP\\n\\n- Showcased proficiency in modern web technologies and frameworks like NextJS, 3JS, GSAP etc\\n- Built a responsive, visually appealing interface with smooth animations\\n\\n## Recipify /link | React, Gemini API, Selenium Web Scraping, Flask\\n\\n- Created an full-stack AI-powered web app suggesting 5 dishes from user-input ingredients\\n- Implemented selenium web scraping to extract recipes from existing recipe websites\\n- Crafted a visually engaging interface for personalized dish suggestions and recipes, improving user engagement.\\n\\n## Library Management System /link | Java, NetBeans, MySQL, Git\\n\\n- Built a Library Management System using NetBeans IDE integrated with MySQL database\\n- Architected a MySQL database schema with CRUD functionality for book records, including title, author, and more\\n- Innovated an efficient search feature improving efficiency by 40% to find books by title, author, or genre'),\n",
              " Document(metadata={'resume_id': 'ShrutiGuptaResume - SHRUTI GUPTA', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Technical Skills\\n\\nLanguages\\n\\n: C, Java, JavaScript, Python, HTML, CSS\\n\\nLibraries/Tools\\n\\n: ReactJS, Git/GitHub, Figma, Adobe Illustrator, MySQL\\n\\nCoursework\\n\\n: Intro to Programming, OOPs, Data Structures, Algorithms, DBMS, OS'),\n",
              " Document(metadata={'resume_id': 'ShrutiGuptaResume - SHRUTI GUPTA', 'chunk_id': 6, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Achievements\\n\\nWinner of Tech Hunt (Capture the Flag) Competition, outperforming 25+ teams, IIITV, 2024\\n\\nHacktober Fest open source contributor, 2023\\n\\n1st Runner Up of Design Week, IIITV, 2023\\n\\n## Position Of Responsibility\\n\\n## Google Developer Student Club | Design Volunteer\\n\\n- Led workshops on UX Principles with 75+ participants Behance\\n- Coordinated multiple high-attendance events\\n\\n|\\n\\nFigma, Illustrator\\n\\n\\n\\n\\n\\nAug. 2022 - Aug. 2023'),\n",
              " Document(metadata={'resume_id': 'Tanishka_Resume - tanishka kasal', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education\\n\\n## JK Lakshmipat University\\n\\nB.Tech in Computer Science, Specialization in Artificial Intelligence GPA: 8.3'),\n",
              " Document(metadata={'resume_id': 'Tanishka_Resume - tanishka kasal', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Research Experience\\n\\n## Research Intern\\n\\nIIT Jodhpur (Prof. Richa Singh)\\n\\nJaipur,India\\n\\nSept.2021 - November 2025\\n\\nJune 2024 - Present\\n\\nJodhpur, Rajasthan\\n\\n- Developed a PyTorch-based deep learning model utilizing multilevel hierarchical attention mechanisms for the classification of Optical Coherence Tomography images using computer vision.\\n- Implemented advanced analytical algorithms that incorporate fuzzy logic for the selection of K-channels, enhancing the model's precision in classifying retinal images.\\n- Improved diagnostic accuracy and efficiency in ophthalmology through advanced image processing techniques\"),\n",
              " Document(metadata={'resume_id': 'Tanishka_Resume - tanishka kasal', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Projects\\n\\n## VocalBridge | Python, Gen-AI, Hugging Face, Speech Recognition, NLP\\n\\nOctober 2024 - Present\\n\\n- Designed and implemented a generative AI-based language translation pipeline that converts English audio to Hindi speech in real-time.\\n- Integrated Whisper for audio transcription, Helsinki NLP for text translation, and Suno Bark for text-to-speech conversion, using all models from Hugging Face to ensure high-quality outputs at each stage\\n- Optimized the system for seamless performance and accuracy in natural language processing tasks, enabling smooth and effective translations.\\n\\n## ProtoVision | Python,Diffusion Models, Gen-AI, Hugging Face, NLP\\n\\n- Efficient Text-to-Image Generation for Product Prototyping\\n- Developing a diffusion model to generate high-resolution product prototypes based on textual descriptions, aiming for a 30 percent reduction in computational costs.\\n- Implementing a compact diffusion network utilizing noise scheduling and multi-scale U-Net, alongside efficient transformers for text encoding.\\n- Enhancing product design iterations in e-commerce and manufacturing by enabling rapid visualization of concepts through high-fidelity generated images.\\n\\n## GPT Tokenizer | Python, NLP, LLM\\n\\nJan 2024 - March 2024\\n\\n- Developed comprehensive lexicons and implemented advanced text tokenization techniques, including Byte Pair Encoding (BPE) and Sentence Piece methodologies.\\n- Addressed tokenization issues to ensure optimal model performance, including handling trailing white spaces,managing non-English text, and optimizing maximum context length.'),\n",
              " Document(metadata={'resume_id': 'Tanishka_Resume - tanishka kasal', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Technical Skills\\n\\nLanguages\\n\\n: Python, Java, JavaScript, HTML/CSS\\n\\nFrameworks\\n\\n: PyTorch, Open-CV, TensorFlow, Keras, Git\\n\\nDeveloper Tools\\n\\n: VS Code, PyCharm, Eclipse\\n\\nLibraries\\n\\n: Pandas, NumPy, Matplotlib, Scikit-learn\\n\\n## Key Courses Undertaken\\n\\nComputer Science : Data Structures &amp; Algorithms, Computer Networks, Operating Systems, Object Oriented Programming, Design &amp; Analysis of Algorithms, Theoretical Foundation of Computer Network, Database Systems, Computer Architecture and Organization\\n\\nMachine Learning : Large Language Model, Machine Learning ver-1, Artificial Intelligence, Machine Learning and AI Specialization (Coursera), Deep Learning.\\n\\nMaths and Statistics : Calculus and Applied Mechanics, Computational Engineering Analysis, Linear Algebra, Differential Equations (ODE; Partial), Matrix Computation.\\n\\nSept. 2024 - Present\\n\\n## Tanishka Kasal\\n\\n+91 9770301238 | tanishkakasal@jklu.edu.in | LinkedIn | Github'),\n",
              " Document(metadata={'resume_id': 'Senior Frontend ILO - Aminat Shotade', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## PROFESSIONAL SUMMARY\\n\\nI  am  a  Senior  Frontend  Engineer  with  over  6  years  of  experience  in  building  scalable  and  user-focused  web  and  mobile applications. I specialize in React.js, React Native, and Next.js , with advanced expertise in performance optimization, state management, and responsive design. Proficient in end-to-end testing and accessibility compliance, I  ensure  applications meet the highest standards of quality and usability. I recently expanded my skill set into Artificial Intelligence and Machine Learning, with certifications in Advanced Regression and Classification .  A notable achievement includes resolving critical app  ringing  issues  in  a  Patient  Care  App  through  PushKit  and  Foreground  Services,  ensuring  seamless  cross-platform functionality.'),\n",
              " Document(metadata={'resume_id': 'Senior Frontend ILO - Aminat Shotade', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS\\n\\n- Frontend  Technologies : TypeScript, React.js, Nextjs, React Native, Vue.js, Angular,  Tailwind CSS\\n- State Management : Zustand, Redux, Redux Toolkit, Context API\\n- Design &amp;Documentation : Storybook, Figma, Styled Components, CSS/Sass Modules, Ant Design\\n- Testing: Cypress, Jest, React Testing Library, End-to-End Testing (E2E)\\n- Cloud  &amp;  Backend:  AWS  (Lambda,  S3,  API  Gateway),  GraphQL, Node.js, MySQL, PostgreSQL, MongoDB, RealmDb,\\n- Machine Learning &amp; AI: Python, Pandas, Matplotlib, TensorFlow, Regression &amp; Classification Models\\n- Others : GraphQL, Zustand, SEO, WCAG, Microfrontend Architecture, Responsive Design, System Design'),\n",
              " Document(metadata={'resume_id': 'Senior Frontend ILO - Aminat Shotade', 'chunk_id': 3, 'gpa_value': 40.0, 'gpa_scale': 100.0, 'gpa_normalized': 4.0, 'gpa_found': True}, page_content='## PROFESSIONAL EXPERIENCE\\n\\nLead Frontend Engineer | Avitech | Lagos, Nigeria 2022 - Present\\n\\n- Spearheaded the creation of a design system for AVICASH, ensuring consistent user experience across the React Native-based POS system.\\n- Designed  and  implemented  a  design  system  for  the  NSIB  Business  Intelligence  Dashboard,  streamlining component reuse and enhancing UI consistency across platforms.\\n- Led the development of end-to-end tests for all major features in AVICASH and NSIB, ensuring system reliability and reducing regressions by 40%.\\n- Utilized Figma for design handoff and implemented components with Styled Components and Storybook, enabling seamless documentation and collaboration.\\n- Spearheaded the integration of micro frontend architecture, boosting project efficiency and user experience.\\n- Mentored  a  team  of  junior  developers  and  championed  the  adoption  of  WCAG-compliant  standards  to  ensure inclusivity.\\n\\nTech Stack :  ReactJS ReactNative,  Redux Toolkit,  NextJS, TypeScript,  Jest, Zustand, React Query, Docker, Azure, Antd'),\n",
              " Document(metadata={'resume_id': 'Senior Frontend ILO - Aminat Shotade', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## EDUCATION\\n\\n2017- 2018 | Decagon Digital Learning\\n\\nSoftware Engineering Diploma LAGOS, NIGERIA\\n\\n2012-2016| ILORIN\\n\\nBachelor of Science(Comptuter sc.)\\n\\n## AMINAT SHOTADE\\n\\nSenior Software Engineer shotade-aminat/\\n\\n- shotadeaminat@gmail.com'),\n",
              " Document(metadata={'resume_id': 'Senior Frontend ILO - Aminat Shotade', 'chunk_id': 5, 'gpa_value': 30.0, 'gpa_scale': 100.0, 'gpa_normalized': 3.0, 'gpa_found': True}, page_content='## Key Achievements:\\n\\n- Reduced development time by 30% with a reusable component library.\\n- Enhanced cross-platform consistency in AVICASH and NSIB, supporting 200+ users daily.\\n\\n## Senior Software Engineer | Ileero Remit | London, UK\\n\\n## 2020 - 2022\\n\\n- https://github.com/mindelias shotadeaminat@gmail.com Developed a customizable agent portal using Vue 3, Tailwind CSS, and Figma, enhancing user onboarding and ID verification processes.\\n- Led the creation of a modular frontend system for the remittance platform, enabling scalable international money transfers via React and GraphQL.\\n- Implemented end-to-end tests for critical workflows, reducing bug reports by 25% post-release.\\n- Introduced  Cypress  E2E  tests,  ensuring  seamless  integration  of new features and reducing QA cycles.\\n- Led  a  team  of  four  developers  in  building  a  powerful  admin dashboard, increasing operational efficiency across various departments.'),\n",
              " Document(metadata={'resume_id': 'Senior Frontend ILO - Aminat Shotade', 'chunk_id': 6, 'gpa_value': 99.9, 'gpa_scale': 100.0, 'gpa_normalized': 9.99, 'gpa_found': True}, page_content='## Key Achievements:\\n\\n- Delivered a scalable platform handling 5,000+ daily transactions with 99.9% uptime.\\n- I  spearheaded  the  successful  development  of  an  innovative  identity  card  verification  service.  This sophisticated system meticulously examines user identity cards for expiration. In the event of an expired card, the service promptly triggers notifications to both the user and our dedicated customer service team.\\n\\n## Frontend Engineer | Indeed through Decagon | Lagos, Nigeria 2019 - 2020\\n\\n- Optimized frontend SDK load speed by 80%, reducing the main bundle size from 7MB to 400KB.\\n- Developed interactive,  mobile-friendly  websites,  transitioning  legacy  presentations  to  modern,  easy-to-use versions.\\n- Migrated legacy systems to interactive, mobile-friendly interfaces, improving accessibility and usability.\\n- Establish coding standards and best practices for the team\\n- Collaborated  successfully  with  stakeholders  across  departments,  ensuring  project  milestones  were  met  on time and within budget\\n- Designed  and  implemented  UI  dashboards  and  CMS  templates  tailored  to  various  business  sectors  to optimize business onboarding and increase retention rate by 70%'),\n",
              " Document(metadata={'resume_id': 'Senior Frontend ILO - Aminat Shotade', 'chunk_id': 7, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Key Achievements:\\n\\n- Successfully conducted end-to-end testing, reducing build failures and ensuring high-quality deployments.'),\n",
              " Document(metadata={'resume_id': 'Senior Frontend ILO - Aminat Shotade', 'chunk_id': 8, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## PROJECT HIGHLIGHT\\n\\n## Patient Care Customer and Doctor App\\n\\nTechnologies: React Native, Firebase Realtime Database, PushKit, Foreground Services, Agora Vidoe\\n\\n- Role: Project Lead\\n- Designed and implemented a two-way communication system between a CustomerApp and DoctorApp, enabling real-time video consultations.\\n- Utilized Firebase Realtime Database to track call\\\\_status, ensuring immediate call triggers across devices.\\n\\n## CERTIFICATIONS\\n\\n- Advanced Regression and Classification (Stanford University, Coursera)\\n- Udemy AWS Certified Cloud Practioner\\n- Database SQL QUERIES(ADVANCED)\\n- OWASP top 10 risks! Jumpstart your cyber security career\\n\\n## REFERENCES\\n\\nReferences available upon request\\n\\n- Resolved critical cross-platform ringing issues:\\n- Integrated PushKit for iOS, ensuring call notifications functioned even when inactive.\\n- Configured Foreground Services for Android, allowing consistent call alerts.\\n- Added end-to-end tests to validate call workflows, enhancing reliability and reducing bugs.\\n\\nI mpact : Delivered a seamless telemedicine experience, supporting thousands of consultations monthly.\\n\\nhttps://github.com/mindelias\\n\\n## AVICASH - Point-of-Sale System\\n\\nDescription: Developed  a  sophisticated  POS  system  enabling  offline  sales  management  with  seamless synchronization  when  online.  Implemented  advanced  cart  management,  allowing  users  to  handle  multiple customers simultaneously. Ensured mobile responsiveness across different devices using useWindowDimensions.\\n\\nRole:\\n\\nProject Lead\\n\\nTechnologies:\\n\\nReact Native, Realm DB, Zustand\\n\\n## NSIB - Business Intelligence Dashboard and Payout System\\n\\nTechnologies:\\n\\nReact, GraphQL, Azure, Redux, Tailwind\\n\\nRole:\\n\\nProject Lead\\n\\nDescription: Led  the  creation  of  a  business  intelligence  dashboard  with  a  four-step  approval  workflow, facilitating  efficient  payment  processing  and  access  to  revenue  data.  Ensured  compliance  and  strategic alignment across departments.\\n\\n## TRIPS - Customizable Flight Booking Widget\\n\\nTechnologies:\\n\\nReact,  React Native, Azure, Ant Design, Less, Zustand, Tailwind\\n\\nRole:\\n\\nProject Lead\\n\\nDescription: Oversaw the development and implementation of a customizable flight booking widget used by merchants  across  multiple  countries.  Provided  comprehensive  documentation  and  support  to  ensure seamless integration.\\n\\nshotadeaminat@gmail.com'),\n",
              " Document(metadata={'resume_id': 'Asmita  Bele resume - Asmita Bele', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Asmita Bhagwan Bele 9028148070\\n\\n## BELEASMITA871@GMAIL.COM\\n\\nLINKEDIN: ASMITA BELE\\n\\nGITHUB: ASMITA BELE\\n\\n## Carrer Objective:\\n\\nHighly organized and detail-oriented worker, with a drive to exceed expectations. Ability to analyses data, develop strategies, and provide solutions to complex problems. Seeking to leverage skills and knowledge to contribute to team success.'),\n",
              " Document(metadata={'resume_id': 'Asmita  Bele resume - Asmita Bele', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education:\\n\\n| • PG Data Science and AI Department of Technology, Savitribai Phule Pune University, Pune     | 2023-2024   |\\n|-----------------------------------------------------------------------------------------------|-------------|\\n| • M.Sc. Botany Prof. Ramkrishna More ASC College, Prabhakaran, Akurdi, Pune                   | 2021-2023   |\\n| • B.Sc.Botany Annasaheb Aawte Art, Commerce &Hutatma Babu Ganu Science College, Manchar, Pune | 2019-2021   |\\n| • HSC Shree Shiv Chhatrapati College Junnar, Pune                                             | 2018-2019   |\\n| • SSC Shankarraw Butte Patil Vidyalaya junnar                                                 | 2015-2016   |'),\n",
              " Document(metadata={'resume_id': 'Asmita  Bele resume - Asmita Bele', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Skills:\\n\\n- SQL\\n- Python\\n- Data Visualization\\n- Machine Learning\\n- Deep Learning'),\n",
              " Document(metadata={'resume_id': 'Asmita  Bele resume - Asmita Bele', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Projects:\\n\\n- Diabetics Prediction by using Machine Learning.\\n- Video Game Sales Analysis Dashboard\\n- Meri Mati Mera Dash\\n\\n## Personal Information:\\n\\nName:\\n\\nAsmita Bhagwan Bele\\n\\nDate of Birth\\n\\n:                1\\n\\nst  may 2000\\n\\nGender:\\n\\nFemale\\n\\nMarital Status:\\n\\nSingle\\n\\nNationality:\\n\\nIndian\\n\\nAddress:\\n\\nMadhuban Society, Len no.2, Old Sangvi, Pune- 411027\\n\\nLanguage Known:\\n\\nMarathi, Hindi, English\\n\\nI hereby declare that facts given above are genuine, information mentioned above is correct to the best of my knowledge  and belief.\\n\\nPlace: Pune                                                                                                                                      Yours Faithfully\\n\\nDate:                                                                                                                                           Asmita Bhagwan Bele'),\n",
              " Document(metadata={'resume_id': 'Resume_Zinadine_Zidan - Zinadine Zidan Alsyahana', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Zinadine Zidan Alsyahana\\n\\n+6282250810169 · z.zidan9123@gmail.com · https://www.linkedin.com/in/zinadine-zidan-alsyahana/ · https://github.com/aimldlnlp'),\n",
              " Document(metadata={'resume_id': 'Resume_Zinadine_Zidan - Zinadine Zidan Alsyahana', 'chunk_id': 1, 'gpa_value': 3.67, 'gpa_scale': 4.0, 'gpa_normalized': 9.18, 'gpa_found': True}, page_content='## Education\\n\\n## Universitas Airlangga\\n\\nB.E. in Robotics and AI\\n\\nGPA: 3.67/4.00\\n\\nSurabaya, Indonesia\\n\\nAug. 2022 - Jun. 2026\\n\\n- Relevant Courses: Data Structures &amp; Algorithms, OOP, Artificial Intelligence, Machine Learning, Deep Learning, Computer Vision.'),\n",
              " Document(metadata={'resume_id': 'Resume_Zinadine_Zidan - Zinadine Zidan Alsyahana', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Skills\\n\\n- Languages: Python, C, C++\\n- Tools/Frameworks: Tensorflow, PyTorch, OpenCV, Keras, Numpy, Tableau, Git\\n- ML/Robotics: Supervised Learning, Convolutional Neural Network (CNN), Computer Vision, LLMs, Mobile Robot, Robotics Manipulation, Control Systems'),\n",
              " Document(metadata={'resume_id': 'Resume_Zinadine_Zidan - Zinadine Zidan Alsyahana', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Work Experience\\n\\n## Machine Learning Intern\\n\\nLRNOVA\\n\\nLondon, United Kingdom\\n\\nOct 24 - Present Remote\\n\\n- Developing and fine-tuning Large Language Models (LLMs) to improve personalized learning experiences, including content recommendations and adaptive feedback for users.\\n- Collaborating with cross-functional teams to integrate LLMbased solutions into the platform, enhancing user engagement and driving better educational outcomes.\\n\\n## Machine Learning Cohort\\n\\nBangkit Academy\\n\\nIndonesia\\n\\nSep 24 - Present Remote\\n\\n- Engaged in an intensive program specializing in machine learning, covering foundational and advanced concepts in the field and their implementation.\\n- Collaboratively developing a project aimed at mitigating user addiction to sugar by leveraging machine learning models integrated with an LLM-based chatbot to provide personalized recommendations and support.\\n- Pursuing advanced certifications in areas such as Generative AI and Machine Learning, strengthening expertise in modern AI technologies and frameworks.\\n\\n## Data Analyst Intern\\n\\nBerau Coal\\n\\nBerau, East Borneo\\n\\nJun 24 - Oct 24 Hybrid\\n\\n- Designed and developed interactive dashboards using Tableau to visualize key business metrics, enabling datadriven decision-making across various departments.\\n- Performed advanced data analysis on large datasets, leveraging statistical techniques and visualization tools to uncover actionable insights and trends.\\n- Streamlined reporting processes by integrating Tableau dashboards with existing data pipelines, optimizing real-time data utilization and cross-functional collaboration.\\n\\n## Robotics Software Engineer\\n\\nRobotics Community UNAIR\\n\\nFeb 23 - Present Onsite\\n\\nSurabaya, East Java\\n\\n- Designed and programmed robot systems utilizing PID control for precise motion control and inverse kinematics to enable complex manipulator tasks with high accuracy.\\n- Collaborated with a multidisciplinary team to compete in the National Thematic Robotics Contest (KRTMI 2024), achieving 3rd place.\\n- Successfully integrated YOLOv8-based real-time object detection for automated waste classification, significantly enhancing the efficiency of robotic waste management systems.'),\n",
              " Document(metadata={'resume_id': 'Resume_Zinadine_Zidan - Zinadine Zidan Alsyahana', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Honors and Awards\\n\\n3rd National Winner Thematics Robot Contest (KRTMI) 2024\\n\\nKemendikbudristek'),\n",
              " Document(metadata={'resume_id': 'Resume_Zinadine_Zidan - Zinadine Zidan Alsyahana', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Projects\\n\\n## UnChain: AI-Based Application for Tackling Sugar Addiction with Integrated Chatbot\\n\\nLarge Language Models, Machine Learning, HealthTech\\n\\n- Developed UnChain, an AI-powered application aimed at tackling sugar addiction, featuring a Large Language Model (LLM)-integrated chatbot to deliver personalized dietary advice and motivational support.\\n- Included tools for tracking sugar intake, setting goals, and engaging in interactive challenges, while leveraging machine learning to provide data-driven insights and promote healthier lifestyle choices.\\n\\n## Automated Waste Sorting and Omnidirectional Transporter Robot\\n\\nMotion Planning, PID Control, YOLO\\n\\n- Developed two robots: an autonomous waste sorting robot utilizing inverse kinematics for precise manipulator movement, and a remote-controlled robot for transporting waste to the conveyor.\\n- Designed and implemented a vision system using YOLOv8 for accurate waste detection and classification, while integrating PID control to ensure smooth, responsive movement and stability in both robots.\\n\\n## Colorizing Indonesia's Historical Images with GANs\\n\\nGenerative Adversarial Networks, Computer Vision\\n\\n- Develop a machine learning model using Generative Adversarial Networks (GANs) to automatically colorize historical black-and-white images of Indonesian historical images.\\n- Utilize deep learning techniques for image processing, leveraging the power of GANs to generate realistic, context-aware colorizations while preserving historical accuracy.\\n- Enhance the model's performance by fine-tuning hyperparameters and training on a diverse dataset of historical imagery, improving the visual quality and authenticity of the generated colors.\\n\\nNote: For more details on my other projects, please visit my LinkedIn and GitHub profile.\\n\\n## Licenses and Certifications\\n\\n| Generative AI for Everyone      | (DeepLearning.AI)   |\\n|---------------------------------|---------------------|\\n| AI for Everyone                 | (DeepLearning.AI)   |\\n| Machine Learning Specialization | (DeepLearning.AI)   |\\n| TensorFlow Dev. Specialization  | (DeepLearning.AI)   |\\n\\nNote: For more details on my other licenses and certifications, please visit my LinkedIn profile.\"),\n",
              " Document(metadata={'resume_id': 'Md_Aamir - Md Aamir', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Md Aamir\\n\\nDATA SCIENCE PROFESSIONAL\\n\\nDOB:  07/04/1999\\n\\n\\n\\n\\n\\n\\n\\nmdaamir2712@gmail.com\\n\\n\\n\\nGitHub\\n\\nLinkedIn\\n\\n\\n\\nPassionate about data science and skilled in mathematics, I'm actively seeking a role that offers learning opportunities and professional growth. Dedicated to continuous learning, I'm well-prepared to apply my skills for making informed decisions in dynamic work environments, contributing to organizational success.\\n\\n| ACADEMIC PROFILE   | ACADEMIC PROFILE                                     | ACADEMIC PROFILE   |\\n|--------------------|------------------------------------------------------|--------------------|\\n| MSc. Data Science  | Christ (Deemed to be University), Pune Lavasa Campus | 2022-2024          |\\n| BSc. Mathematics   | Lalit Narayan Mithila University, Bihar              | 2017-2020          |\\n| Class XII(Science) | Islamia College - Darbhanga, Bihar                   | 2015-2017          |\\n| Class X            | Pindaruch High School - Darbhanga, Bihar             | 2014-2015          |\"),\n",
              " Document(metadata={'resume_id': 'Md_Aamir - Md Aamir', 'chunk_id': 2, 'gpa_value': 80.0, 'gpa_scale': 100.0, 'gpa_normalized': 8.0, 'gpa_found': True}, page_content='## Sales Chat Bot Project (Business Intern @ Detect Technologies, Chennai) Internship Project (Generative AI, RAG, Python, LLM, API, Project Management)                                                              Duration: 3 Months\\n\\n- Developed an AI chatbot to handle customer inquiries, improving engagement and support efficiency.\\n- Collaborated with sales and technical teams to enhance and expand FAQs for comprehensive responses.\\n- Employed advanced machine learning techniques, including Retrieval-Augmented Generation (RAG) models.\\n- Optimized model performance using Google Colab with BitsandBytes and 4-bit quantization.\\n- Achieved an 80% accuracy rate in responding to user queries.\\n- Gained experience in Python, data preprocessing, model training, and performance evaluation.'),\n",
              " Document(metadata={'resume_id': 'Md_Aamir - Md Aamir', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## GPM Data Project (AI Development Intern @ TISS)                                                                                   Internship Project'),\n",
              " Document(metadata={'resume_id': 'Md_Aamir - Md Aamir', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## (Google Earth Engine, EDA, LSTM, Project Management)                                                                       Duration: 4 Months\\n\\n- Played a key role in the Urban Rainfall Analysis and Prediction System project. Developed a detailed project plan, defined tasks, and established timelines.\\n- Utilized GEE for data collection and analysis. Extracted and analyzed rainfall data for Hyderabad.\\n- Implemented  grid-level  data  scraping  for  more  localized  insights.  Contributed  to  refining  data  analysis methodologies and addressing challenges.\\n- Enhanced skills in project management, data analysis, and problem-solving.\\n\\n## A Comparative Study of ML and DL Approaches for Twitter Sentiment Classification.        Research Paper\\n\\n- Utilized Natural Language Processing (NLP), ML, and Deep Learning techniques for sentiment analysis.\\n- Explored  various  models,  including  Logistic  Regression,  Naive  Bayes,  Random  Forest,  Support  Vector Machines (SVM), XGBoost, Feedforward Neural Networks (FNNs), and Convolutional Neural Networks (CNNs) for classifying sentiments in the context of Ola and Uber tweets.\\n- Provided a basis for future research in the field of sentiment analysis and user feedback in the ride-hailing industry. Engaged in model comparison and feature engineering using TensorFlow and Scikit-learn.'),\n",
              " Document(metadata={'resume_id': 'Md_Aamir - Md Aamir', 'chunk_id': 5, 'gpa_value': 95.0, 'gpa_scale': 100.0, 'gpa_normalized': 9.5, 'gpa_found': True}, page_content=\"## ROLES &amp; SKILLS\\n\\n| Technical Proficiency        | Python, Machine Learning, Deep Learning, Natural Language Processing, Statistics Timeseries Analysis, Database Management, MySQL                |\\n|------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------|\\n| Tools and Technologies       | Microsoft PowerBI, Microsoft Excel, R Programming                                                                                               |\\n| Intermediate-level Expertise | Generative AI, LLM, Sklearn, TensorFlow, PyTorch                                                                                                |\\n| Certifications               | Foundations of Data Science, Get Started with Python - by Google from Coursera SQL for Data Science - by University of California from Coursera |\\n| Soft Skills                  | Adaptability, Teamwork, Punctuality , Time Management, Creativity                                                                               |\\n\\n## ACHIVEMENT AND EXTRA CURRICULAR ACTIVITIES\\n\\n- IIT JAM Exam for Statistic : I got AIR 1700.\\n- Hackerverse 24 Hour Hackathon : Our team was under the top 10, first round based on visualization.\\n- Invested 750+ hours in intensive library study with a 95%+ attendance record during master's degrees.\\n- Math's Club: Helping non mathematics and Backlog Students in mathematics.\\n- Attended workshop: R and PowerBi, organized by Data Science Department and Skill Nation.\\n- College Event Management : Management team for various college-level events, including aptitude training, a Power BI workshop, and a conference within my college.\"),\n",
              " Document(metadata={'resume_id': 'Raj_Aryan_Resume (1) (1) - RAJ ARYAN', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Professional Summary\\n\\nAspiring Software Engineer with a solid foundation in computer science and programming. Currently pursuing a Bachelor's degree in Computer Science Engineering (AI) with hands-on experience in object-oriented programming and open-source contributions. Eager to apply creative problem-solving skills and quick learning ability to contribute to innovative projects at Microsoft.\"),\n",
              " Document(metadata={'resume_id': 'Raj_Aryan_Resume (1) (1) - RAJ ARYAN', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Skills\\n\\n- Object-Oriented Programming (Python, C++, Java)\\n- Software Development Life Cycle (SDLC)\\n- Problem Solving and Debugging\\n- Version Control (Git &amp; GitHub)\\n- Data Analysis (NumPy, Pandas)\\n- Tools: Blender, Power BI, MS Office, Tableau\\n- Quick Learner and Adaptable'),\n",
              " Document(metadata={'resume_id': 'Raj_Aryan_Resume (1) (1) - RAJ ARYAN', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education\\n\\n- Bachelor of Technology in Computer Science Engineering (AI) Chhattisgarh Swami Vivekananda Technical University, 2022 - 2026 GPA: 8.6\\n- Science Intermediate\\n- Railway Perweshika +2 School, Narkatiaganj West Champaran, 2019 - 2021 Percentage: 77.6\\n- High School\\n- Sr Sec Delhi Public School, Fatehpur Sheohar Br, 2018 - 2019 Percentage: 89'),\n",
              " Document(metadata={'resume_id': 'Raj_Aryan_Resume (1) (1) - RAJ ARYAN', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Professional Experience\\n\\n- Software Engineering Intern\\n\\nGSSOC, May 2024 - Present\\n\\n- Contributed to open-source software development, improving system efficiency and code quality.\\n- Quickly learned new programming techniques and integrated them into existing workflows, enhancing team productivity.\\n- Software Engineering Intern\\n- SSOC'3, May 2024 - Present\\n\\nFostered the spirit of open-source development among students and budding developers through contributions to various projects.\\n\\n- Recruitment Team Representative (TPO)\\n- UTD CSVTU, June 2023 - Present\\n- Represented the Training and Placement Cell for the upcoming campus drive in 2025.\"),\n",
              " Document(metadata={'resume_id': 'Raj_Aryan_Resume (1) (1) - RAJ ARYAN', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Projects\\n\\nHouse Prediction Model |  Link\\n\\n- Developed a machine learning model to predict house prices using Jupyter Notebook, HTML, and Python.\\n- Demonstrated ability to learn new engineering methods and incorporate them into the project.\\n- Successfully managed time to complete the project within deadlines, contributing to a collaborative team effort.\\n\\n## Certifications\\n\\n- Supervised Machine Learning: Regression and Classification - Coursera\\n- Advanced Learning Algorithms - Coursera\\n- Unsupervised Learning, Recommenders, Reinforcement Learning - Coursera\\n- Machine Learning Specialization - Coursera\\n- DSA with Java - Apna College\\n- Python (Basic) - HackerRank\\n\\n•\\n\\nSQL (Basic) - HackerRank\\n\\n- MATLAB Onramp - MATLAB\\n- Machine Learning Onramp -MATLAB'),\n",
              " Document(metadata={'resume_id': 'Raj_Aryan_Resume (1) (1) - RAJ ARYAN', 'chunk_id': 6, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Honors &amp; Awards\\n\\n- NTSE Scholar Stage 1\\n- Cleared IMO (International Mathematics Olympiad) Level 1\\n- Cleared JEE Mains and JEE Advance\\n- BCECE AIR (91)\\n- NDA (Written)\\n\\n## Activities\\n\\n- Member of University's Computer Science Club, participating in coding challenges and hackathons.\\n- Volunteer at local organizations, contributing technical skills to community projects.\\n\\n.\\n\\n## Languages\\n\\n- English (Fluent)\\n- Hindi (Fluent)\\n\\n## RAJ ARYAN\\n\\n## Narkatiaganj West Champaran, Bihar rrajariann@gmail.com | 6287278385\\n\\nLinkedIn | GitHub | HackerRank | LeetCode aryan-62172a260/\"),\n",
              " Document(metadata={'resume_id': 'VES_Ganesh_Deulkar_Resume - Ganesh Deulkar', 'chunk_id': 1, 'gpa_value': 77.73, 'gpa_scale': 100.0, 'gpa_normalized': 7.77, 'gpa_found': True}, page_content=\"## Education\\n\\nVivekananda Education Society's Institute of Technology, Mumbai\\n\\nAug 2023 - Expt Jun 2025\\n\\nMaster of Computer Applications | CGPI: 8.13\\n\\nMaharashtra, India\\n\\nDeogiri College, Aurangabad\\n\\nJun 2020 - May 2023\\n\\nBachelor of Computer Applications | Percentage: 77.73%\\n\\nMaharashtra, India\"),\n",
              " Document(metadata={'resume_id': 'VES_Ganesh_Deulkar_Resume - Ganesh Deulkar', 'chunk_id': 2, 'gpa_value': 40.0, 'gpa_scale': 100.0, 'gpa_normalized': 4.0, 'gpa_found': True}, page_content='## Experience\\n\\n## AI/ML Developer Intern\\n\\n## JDB Infotech\\n\\n- Developed and deployed advanced machine learning models, optimizing cyber threat detection by 40% and enhancing the robustness of two cybersecurity projects while innovating new, cutting-edge solutions.\\n- Collaborated with senior developers to troubleshoot issues and optimize code efficiency, gaining insight into best practices and industry standards. 3 Libraries\\n\\n## Applicative AI/ML Intern\\n\\n## Koviki Tech Solutions\\n\\n- Coordinated 3 high-impact projects aimed at enhancing model accuracy and performance, resulting in improved prediction reliability by 20% and processing speed by 15%. 55 commits\\n- Generated advanced machine learning models using OpenCV and TensorFlow , reducing downtime by 45% through accurate real-time anomaly detection in object identification and analysis processes.'),\n",
              " Document(metadata={'resume_id': 'VES_Ganesh_Deulkar_Resume - Ganesh Deulkar', 'chunk_id': 3, 'gpa_value': 20.0, 'gpa_scale': 100.0, 'gpa_normalized': 2.0, 'gpa_found': True}, page_content='## Projects\\n\\n## EnSync - An energy Monitoring System(Mobile Application) | Python, Machine Learning, Flutter, Google Firebase\\n\\n- Executed the creation of an innovative mobile app designed to help users manage and optimize energy consumption, resulting in a 20% reduction in overall energy usage and increased user engagement by 40%.\\n- Conceptualized a real-time push notification feature to notify users of unusual energy usage patterns, reducing customer energy costs by an average of 20% and increasing app retention rates by 18%.\\n\\n## ML based Food Delivery Time Prediction Model | Python, Machine Learning\\n\\nColab Link\\n\\n- Launched a regression model to predict food delivery time based on three key factors , incorporating advanced feature engineering techniques such as encoding categorical variables and scaling numerical features for improved accuracy.\\n- Enhanced model robustness by implementing cross-validation and ensemble learning techniques, leading to a 20% improvement in overall accuracy and consistency across diverse datasets.\\n\\n## ML based Imagery Analysis using K-means Clustering | Python, Machine Learning\\n\\nColab Link\\n\\n- Prepossessed image data by extracting 6 relevant features and reducing dimensionality to enhance clustering performance.\\n- Evaluated 4 clustering results using metrics like silhouette score and visual inspection of clustered images.\\n\\n## Pet Services | E-Commerce Application\\n\\n- Created a robust and user-friendly E-Commerce website utilizing HTML, CSS,JavaScript and PHP12 dfd\\n- Leveraged MySQL and PHP to manage server logic and database operations , ensuring efficient back-end functionality.'),\n",
              " Document(metadata={'resume_id': 'VES_Ganesh_Deulkar_Resume - Ganesh Deulkar', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Technical Skills\\n\\nLanguages\\n\\n: Python, Java, PHP\\n\\nFrameworks and Libraries\\n\\n: Numpy, Pandas, OpenCV, SciKit, Matplotlib, Seaborn, PyTorch, TensorFlow, Selenium.\\n\\nDatabases\\n\\n: MySQL, SQL.\\n\\nOther Technologies\\n\\n: GitHub, AWS.\\n\\n## Position of Responsibility\\n\\n## Music Representative\\n\\nMCA Department - Vivekanand Education Society's Institute of Technology, Mumbai.\\n\\n## Placement Co-ordinator\\n\\nDevgiri College, Aurangabad.\\n\\nApril 2024 - June 2024\\n\\n\\n\\nJuly 2024 - Present\"),\n",
              " Document(metadata={'resume_id': 'Deekshith_Kuchana (1) - Deekshith kuchana', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='7337042003 Warangal, Telangana kuchanadeekshith@gmail.com\\n\\n## Kuchana Deekshith Data Scientist / Junior Developer\\n\\nPortfolio: MathtoData.com github.com/kuchanadeekshith linkedin.com/in/deekshithkuchana\\n\\nEnthusiastic B.Tech student in Computer Science, specializing in AI ML, seeking an entry-level position as a Machine Learning Engineer, Data Scientist, or Junior Developer. Proficient in machine learning algorithms, data analysis, and software development with experience in designing data-driven solutions. Currently completing the final year of a degree with practical exposure to innovative machine learning projects, accessibility features, and cloud-based deployments. Possess a strong foundation in deep learning, security considerations, and a readiness to go beyond expectations. Eager to leverage academic knowledge and skills in a dynamic environment, contributing to impactful projects and advancing professionally.'),\n",
              " Document(metadata={'resume_id': 'Deekshith_Kuchana (1) - Deekshith kuchana', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS\\n\\nProgramming Languages\\n\\nPython, Java, C\\n\\nMachine Learning Frameworks\\n\\nScikit-learn\\n\\nData Visualization and Analysis Databases Version Control IDEs WebTechnologies\\n\\nPandas, NumPy, Matplotlib, Seaborn\\n\\nMySQL\\n\\nGit\\n\\nJupyter Notebook, Visual Studio Code, Anaconda, Spyder\\n\\nHTML, CSS, Bootstrap\\n\\nSoft Skills\\n\\nProblem Solving, Teamwork and Collaboration, Communication Skills, Time Management\\n\\n## RELATED COURSEWORK\\n\\n- Machine Learning, Deep Learning, Data Science, Algorithms, Data Structures, Statistics,Linear Algebra, Calculus, Python Programming\\n- Supervised and Unsupervised Learning, Deep Learning: Neural Networks, CNNs, RNNs, Natural Language Processing (NLP), Computer Vision, Feature Engineering and Selection, Model Evaluation and Hyperparameter Tuning, Data Preprocessing and Cleaning, Cross-Validation Techniques'),\n",
              " Document(metadata={'resume_id': 'Deekshith_Kuchana (1) - Deekshith kuchana', 'chunk_id': 2, 'gpa_value': 96.2, 'gpa_scale': 100.0, 'gpa_normalized': 9.62, 'gpa_found': True}, page_content='## EDUCATION\\n\\nBachelor of Technology (B.Tech) in Computer Science (AI-ML) Vaagdevi Engineering College Intermediate Narayana Junior College Result: 96.2%\\n\\n2021-2025 2019-2021\\n\\n## CERTIFICATIONS\\n\\nCisco:\\n\\nData Analytics Essentials, Introduction to Data Science'),\n",
              " Document(metadata={'resume_id': 'Deekshith_Kuchana (1) - Deekshith kuchana', 'chunk_id': 3, 'gpa_value': 99.0, 'gpa_scale': 100.0, 'gpa_normalized': 9.9, 'gpa_found': True}, page_content='## PROJECTS\\n\\n## Thyroid Classification\\n\\nThyroid Classification Developed a machine learning model for thyroid disease classification, achieving over 99% accuracy using Python, Scikit-learn, and Grid Search. Utilized Random Forest, SVM, STMO, and advanced hyperparameter tuning techniques to enhance diagnostic precision.'),\n",
              " Document(metadata={'resume_id': 'Sandesh Dhamane_AI and DS - Sandesh Dhamane', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SANDESH BABASAHEB DHAMANE\\n\\n+91-7218257751 | sandeshdhamane03@gmail.com | www.linkedin.com/in/sandesh-dhamane\\n\\n## OBJECTIVE\\n\\nTo obtain a challenging role in a leading company where I can leverage my skills and experience, contributing to the growth and success of the organization.'),\n",
              " Document(metadata={'resume_id': 'Sandesh Dhamane_AI and DS - Sandesh Dhamane', 'chunk_id': 1, 'gpa_value': 85.44, 'gpa_scale': 100.0, 'gpa_normalized': 8.54, 'gpa_found': True}, page_content='## EDUCATION\\n\\nZeal College of Engineering and Research Narhe, Pune\\n\\nNov 2022 - Present\\n\\nPursuing BE in Artificial Intelligence and Data Science || SPPU\\n\\n9.64 SGPA\\n\\nGovernment Polytechnic Awasari Kh, Pune\\n\\nAug 2019 - Jul 2022\\n\\nDiploma || Maharashtra State Board of Technical Education\\n\\n85.44%\\n\\nKarmveer Bhaurao Patil Vidyalaya Sarola Kasar, Ahmednagar SSC || Maharashtra State Board,Pune\\n\\nMarch 2019\\n\\n87%'),\n",
              " Document(metadata={'resume_id': 'Sandesh Dhamane_AI and DS - Sandesh Dhamane', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Key Skills : Python3 | Tkinter | Firebase\\n\\nUsing Python3 and Tkinter, I developed a cricktracker that collects cricket match score and stores it in Firebase.  The  application  features  tkinter  is  used  for  GUI  for  input  fields  like  player  name,  toss  win, batting,  bowling.  From  these  input  those  data  can  store  in  the  firebase.  This  project  enhanced  my understanding of GUI development, Firebase integration, and data management in desktop applications.\\n\\n- Tableau Covid-19 Dashboard\\n\\nKey Skills : Tableau\\n\\nDeveloped a data visualization dashboard using Tableau to analyze COVID-19 datasets. Extracted key insights on infection rates, recovery trends, and regional impacts, enhancing data-driven decision-making. This project improved my proficiency in data visualization and analytical skills'),\n",
              " Document(metadata={'resume_id': 'Sandesh Dhamane_AI and DS - Sandesh Dhamane', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## TECHNICAL SKILLS\\n\\nLanguages : Python, MySQL, Python Libraries-(Numpy, Pandas, Matplotlib, Seaborn)\\n\\nTools : Jupyter Notebook , Tableau, MS Excel\\n\\nSkills : Data Analysis, Data Visualization, Data Preprocessing\\n\\n## INTERNSHIP\\n\\nCelebal Technologies\\n\\nData Science summer Intern\\n\\n## LANGUAGES\\n\\nEnglish || Hindi || Marathi\\n\\n## CERTIFICATIONS\\n\\nData Visualization using Tableau - ZCOER, March 2024 Python Programming - Core2web , Feb 2024\\n\\nJun 2024 - Aug 2024'),\n",
              " Document(metadata={'resume_id': 'Zulfikar_resume - Zulfikar Charoliya', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Zulfikar Charoliya\\n\\nIT student\\n\\nThird-year IT student at VIT Pune with strong problem-solving and coding skills; excels in team settings, takes ownership of projects, and delivers high-quality results quickly.'),\n",
              " Document(metadata={'resume_id': 'Zulfikar_resume - Zulfikar Charoliya', 'chunk_id': 1, 'gpa_value': 8.51, 'gpa_scale': 10.0, 'gpa_normalized': 8.51, 'gpa_found': True}, page_content=\"## EDUCATION\\n\\n## B.tech in Information technology\\n\\nVishwakarma Institute of Technology, Pune 11/2022 - 05/2026 , 8.51 CGPA\\n\\n## 12th Boards\\n\\nSona 'I' English Medium High School 07/2020 - 04/2022 ,\\n\\n81.67 %\\n\\n## 10th Boards\\n\\nSona 'I' English Medium High School\\n\\n06/2019 - 04/2020\\n\\n,\\n\\n85.60 %\"),\n",
              " Document(metadata={'resume_id': 'Zulfikar_resume - Zulfikar Charoliya', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## PROJECTS\\n\\n## Braille Learner\\n\\n- Created Braille Learner with ESP8266, servo motors, and 3Dprinted gears, including voice feedback.\\n- Designed web interface for easy Braille input and interactive learning.\\n\\n## AI-Powered Legal Documentation Assistant\\n\\n- Developed an AI-powered legal document processing system using NLP and ML, supporting multiple formats (PDF, DOC, TXT) for efficient document handling and error detection.\\n- Implemented a user-friendly interface for seamless integration into legal workflows, enhancing processing speed and accuracy.\\n\\n## Vehicle Crash Detection and Alert System\\n\\n- Developed a Vehicle Crash Detection System with sensors and GPS to detect accidents and calculate severity in realtime.\\n- Programmed automatic alerts to emergency contacts and hospitals, ensuring faster response and timely rescue.\\n\\n## ChatTix\\n\\n- Developed an advanced ticketing system utilizing WPPConnect and Gemini API for efficient event booking through WhatsApp.\\n- Implemented multilingual support, dynamic response handling, and user-friendly interaction features to create a seamless and engaging experience for diverse users.'),\n",
              " Document(metadata={'resume_id': 'Zulfikar_resume - Zulfikar Charoliya', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS\\n\\n\\n\\n\\n\\nzulfikarcharoliya92@gmail.com\\n\\n+91 7840973970\\n\\nPune, India linkedin.com/in/zulfikar-charoliya\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nData Structures and Algorithms\\n\\nData Analysis\\n\\nProblem Solving'),\n",
              " Document(metadata={'resume_id': 'Zulfikar_resume - Zulfikar Charoliya', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## ACHIEVEMENTS\\n\\n5 star in Problem Solving, 5 star in Java, 4 star in C++ on HackerRank\\n\\nPatent application in South Africa intellectual property.\\n\\nWinner of Hackspiration'24: Secured first place for developing the Braille Learner, competing against 90 teams.\\n\\nRunner-up of Dexterity '24 -'25 : Secured second place in the Shark Tank competition against 25+ teams.\\n\\nPublished 'AI-POWERED LEGAL DOCUMENTATION ASSISTANT' paper in ICPCSN 2024 (4th International Conference on Pervasive Computing and Social Networking).\\n\\nPublished'VehicleCrashDetectionandAlertSystem' paperinSpringerICDSMLA(5th International Conference on Data Science, Machine Learning &amp; Applications).\\n\\n## CERTIFICATES\\n\\nCompleted Nvidia Fundamentals of Deep Learning Workshop: Gained hands-on experience with deep learning techniques and tools.\\n\\nCertified in Mendix Rapid Developer (Low-Code App Development)\"),\n",
              " Document(metadata={'resume_id': 'Sai_Nageswara_Raju_CV - Raju', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS\\n\\n- Python\\n- Machine Learning\\n- Cloud Computing\\n- Linux OS\\n- SQL\\n- C\\n- C++\\n- Arduino UNO'),\n",
              " Document(metadata={'resume_id': 'Sai_Nageswara_Raju_CV - Raju', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## EDUCATION\\n\\n- Sreenidhi Institute of Science and Technology\\n\\nBachelor of Technology - Electronics and Computer Engineering ◦ GPA: 7.55\\n\\n- Narayana Junior College\\n- Narayana Concept School\\n\\nIntermediate - MPC\\n\\n- Percentage: 96.3\\n\\nSchool\\n\\n- GPA: 9.3'),\n",
              " Document(metadata={'resume_id': 'Sai_Nageswara_Raju_CV - Raju', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## PROJECTS\\n\\n## · PREDICTING FLIGHT DELAYS USING MACHINE LEARNING\\n\\nTools: Machine Learning Algorithm Logistic Regression, Jupyter notebook, Flask framework\\n\\n- This project predicts the appropriate time difference that may be incurred with the flight when the details of the flight have been provided.\\n- Developed and tested algorithms like Random Forest, Multi Layer Perceptron, Ridge Classifier, Decision Tree and Logistic Regression with the data set.\\n- Created a comparison graph and table of accuracy of all algorithms, among which Logistic Regression produced the highest accuracy.\\n- Applied Logistic Regression to perform the predictions and developed a web page that takes input and predicts the output.\\n- HEART DISEASE PREDICTION USING MACHINE LEARNING ALGORITHMS\\n\\nFeb 2023 - July 2023\\n\\nTools: Machine Learning Algorithms Support Vector Classification, Variational Quantum Classifier, Jupyter notebook\\n\\n- This project is developed to predict whether a person has heart disease or any issues related to heart.\\n- The algorithm is fed, trained and tested with a dataset consisting of various attributes of different people, such as blood pressure, sugar levels, cholesterol, fasting blood sugar, maximum heart rate, etc.\\n- Trained and tested a few algorithms and finally deployed Support Vector Classification (SVC) and Variational Quantum Classifier (VQC) to predict the output.\\n- TARANA - ROBOTICS\\n\\nTools: Arduino UNO, Arduino IDE, Servo motor, RFID Module (RC522), Fingerprint Module (R307)\\n\\n- This project is developed to monitor and note the entry and exit time stamps of vehicles in educational institutions.\\n- Used RFID (Radio Frequency Identification) technology to perform this task.\\n- When RFID transmitter and receiver comes close to a certain range, it makes an entry into the Excel sheet.\\n- We also used the fingerprint module to only allow authorized people to enter the vehicle (bus) by placing the module at the entrance of the bus.\\n\\nMarch 2022 - July 2022\\n\\n## Sai Nageswara Raju Lolabhattu\\n\\n+91 6305754601 | lsnraju666@gmail.com | 06/05/2003 Hyderabad, Telangana, India\\n\\nNov 2020 - June 2024 Hyderabad, India\\n\\nJune 2020 Hyderabad, India\\n\\nMarch 2018 Hyderabad, India\\n\\nJan 2024 - May 2024\\n\\n## · JWALA RATHI - ROBOTICS\\n\\nTools: Arduino MEGA, Temperature Sensor(LM35), Gas Sensor(MQ-2), GPS Module, Ultrasonic Sensor(HC-SR04)\\n\\n- This is a small fire fighting robot that detects smoke and temperature regulations within the confined space and takes action in necessary conditions.\\n- This bot not only detects smoke, it sprays water through a nozzle, trying to eliminate fire at its early stage.\\n- In case of any fire accidents, it sends the location of the mishap to the concerned department by using GPS and GSM modules in required circumstances.\\n\\n## · THRINETHRA - ROBOTICS\\n\\nApr 2021 - June 2021\\n\\nTools: Arduino UNO, Arduino IDE, Colour sensor(TCS230), Speaker Module(JQ6500), UV Sensor(GUV A-S12SD)\\n\\n- Thrinethra is a tool for blind people that helps to identify the value of the currency notes.\\n- This bot uses a color sensor and UV sensor to identify the value and authenticity of the note.\\n- It has a speaker module through which it produces the sound of the value of currency.'),\n",
              " Document(metadata={'resume_id': 'Sai_Nageswara_Raju_CV - Raju', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## VOLUNTEER EXPERIENCE\\n\\n- Head of Event - Roboveda'2023\\n\\nThe Robotics Club - SNIST\\n\\n- Served as a Technical Event Head for an event called Gati.\\n- Developed team-leading, teamwork, time management and decision-making skills.\\n- Coordinator of Event - Roboveda'2022\\n\\nThe Robotics Club - SNIST\\n\\n- Served as a Technical Event Coordinator for an event called Gati.\\n- Developed teamwork, critical thinking and time management.\\n- Volunteer - Roboveda'2021\\n\\nThe Robotics Club - SNIST\\n\\n- Served as a volunteer for an event called Ranveera.\\n- Developed communication, project management and design skills.\\n\\n## LANGUAGES KNOWN\\n\\n- English\\n- Telugu\\n- Hindi\\n\\n## HOBBIES\\n\\n- Reading books, Playing Basketball, Playing Cricket, Cycling\\n\\nNovember-2023\\n\\nDecember-2022\\n\\nDecember-2021\"),\n",
              " Document(metadata={'resume_id': 'AnushaDixit_DS_LM - Anusha Dixit', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education\\n\\nB.K. BIRLA COLLEGE\\n\\nMaster of Science\\n\\n,  Data Science\\n\\n2022 - 2024\\n\\nSMT. CHM COLLEGE\\n\\nBachelor of Science ,  Computer Science\\n\\n2019 - 2022'),\n",
              " Document(metadata={'resume_id': 'AnushaDixit_DS_LM - Anusha Dixit', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Technical  Skills\\n\\nLanguages and Tools\\n\\n: Python, SQL, Tableau, Excel, Git, Github\\n\\nLibraries &amp; Frameworks\\n\\n: Numpy, Pandas, Matplotlib, Seaborn, SkLearn, TensorFlow, Pytorch, NLP, LangChain\\n\\nMathmatics for ML &amp; DL\\n\\n: Statistics, Probability, Matrices\\n\\nData Analysis &amp; Querying\\n\\n: Data Extraction, Statistical Analysis, SQL Querying, Business Problem Solving'),\n",
              " Document(metadata={'resume_id': 'AnushaDixit_DS_LM - Anusha Dixit', 'chunk_id': 3, 'gpa_value': 82.0, 'gpa_scale': 100.0, 'gpa_normalized': 8.2, 'gpa_found': True}, page_content='## Experience\\n\\n## Data Science and Machine learning Intern | Microrbital Labs - ( Oct 2023 - Nov 2023 )\\n\\n- \\uf0b7 Retail Price Prediction: Developed a model to accurately forecast retail prices, enabling informed pricing strategies and optimizing profitability.\\n- \\uf0b7 Medical Cost Prediction : Built a predictive model to estimate medical costs, facilitating efficient healthcare resource allocation and cost management.\\n- \\uf0b7 Market Basket Analysis: Conducted market basket analysis using SQL queries and Python to uncover insightful customer purchasing patterns, informing targeted marketing initiatives and product placements.\\n\\n## Data Analyst Intern | TCS ION - ( Aug 2023 - Oct 2023 )\\n\\n- \\uf0b7 Crafted interactive graphical representations of financial dataset using Python and SQL.\\n- \\uf0b7 Constructed a predictive model that accurately forecasts employee salaries using machine learning, with the random forest algorithm achieving 82% accuracy .\\n- \\uf0b7 These projects encompassed data collection, preprocessing, model training, and evaluation, enhancing accuracy and insights across diverse applications.'),\n",
              " Document(metadata={'resume_id': 'AnushaDixit_DS_LM - Anusha Dixit', 'chunk_id': 4, 'gpa_value': 83.0, 'gpa_scale': 100.0, 'gpa_normalized': 8.3, 'gpa_found': True}, page_content=\"## Projects\\n\\n## STOCK PRICE PREDICTION OF NEXT 3 DAYS\\n\\n- \\uf0b7 Implemented a Long Short-Term Memory (LSTM) neural network model for stock price prediction, forecasting the next 3 days' prices with 83% accuracy.\\n- \\uf0b7 Performed extensive data preprocessing, including handling missing values, removing outliers, and normalizing financial data to ensure model accuracy.\\n- \\uf0b7 Achieved strong evaluation metrics, demonstrating the model's predictive power for multi-day stock price forecasting.\\n\\n## WALMART SALES ANALYSIS\\n\\n- \\uf0b7 Analyzed Walmart sales data to uncover insights and drive business strategy.\\n- \\uf0b7 Built models to analyze sales performance, inventory levels, and customer preferences.\\n- \\uf0b7 Developed Tableau dashboards to provide stakeholders with real-time sales performance metrics .\\n\\n## NEWS ARTICLES SUMMARIZER\\n\\n- \\uf0b7 Collected a list of news article URLs and developed a pipeline to parse the content automatically.\\n- \\uf0b7 Built a summarizer using LangChain and OpenAI's LLM, generating concise and accurate summaries from lengthy news articles..\\n- \\uf0b7 Integrated LangChain for efficient prompt engineering and handling of LLM queries, improving information retrieval for users by 60%.\"),\n",
              " Document(metadata={'resume_id': 'AnushaDixit_DS_LM - Anusha Dixit', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Achievements &amp; Certifications\\n\\n- \\uf0b7 Earned a Badge of completion for the Data Analysis Using Python - IBM\\n- \\uf0b7 Data Analysis Using Excel  Certification - LinkedIn\\n- \\uf0b7 Foundations Of Machine Learning Certification -  MachineLearningPlus\\n- \\uf0b7 LangChain &amp; Vector DBs in Production Certifications  -  ActiveLoop'),\n",
              " Document(metadata={'resume_id': 'SURAJ__THAPALIYA__RESUME - Su Raz Thapaliya', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SURAJ THAPALIYA\\n\\nDate of Birth: 27/11/1999\\n\\nMobile : 9763435447\\n\\nEmail: raz.thapaliya600@gmail.com\\n\\nAddress: Bafal, Kathmandu\\n\\n## PERSONAL STATEMENT\\n\\nAn individual with 2+ years of experience in the IT industry, specifically in web development, who thrives in a challenging and positive environment, constantly striving to improve himself and, as a result, innovate the work culture for the benefit of all parties involved. He also has a strong interest in AI other emerging technologies.'),\n",
              " Document(metadata={'resume_id': 'SURAJ__THAPALIYA__RESUME - Su Raz Thapaliya', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## EDUCATION\\n\\nBachelor of Science in Computer System Engineering- 2023 (International School of Science and Technology - Tinkune, Kathmandu)'),\n",
              " Document(metadata={'resume_id': 'SURAJ__THAPALIYA__RESUME - Su Raz Thapaliya', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS\\n\\nJavascript, Reactjs, Nextjs, Node, Python, Opencv Mongodb, mysql Git\\n\\n## HISTORY\\n\\n## MERN DEVELOPER\\n\\n(September 2022- August 2024)\\n\\nApp Technology Pvt Ltd.\\n\\n## Responsibilities :\\n\\nAs a full stack developer, I was responsible for\\n\\n- Design, build, and maintain efficient, reusable, and reliable code for both client-side and server-side components.\\n- Work with designers, product managers, and other developers to create user-friendly and scalable web applications.\\n- Develop RESTful  APIs to enable seamless communication between front-end and back-end systems.\\n- Write clean, well-documented code and conduct regular code reviews to maintain quality\\n\\n\\n\\n## React Developer (Intern)\\n\\n(May 2022- August 2022) General Technologies\\n\\nLimited\\n\\n## Responsibilities :\\n\\nAs a Frontend Developer (Intern), I was responsible for\\n\\n- Build and optimize responsive web pages and interactive features using modern web technologies such as HTML, CSS, and JavaScript frameworks (e.g., React, Next)..\\n- Work closely with UX/UI designers, product managers, and back-end developers to implement visual and functional elements in web applications..\\n- Write clean, modular, and well-documented code that follows industry best practices, and participate in code reviews to ensure quality and consistency.\\n- Work on consuming RESTful APIs to enable seamless data flow between the frontend and back-end services.'),\n",
              " Document(metadata={'resume_id': 'Dheeraj_CV - Dheeraj Kumar Prajapati', 'chunk_id': 0, 'gpa_value': 82.0, 'gpa_scale': 100.0, 'gpa_normalized': 8.2, 'gpa_found': True}, page_content=\"## Dheeraj Kumar Prajapati\\n\\n4th Year Undergraduate\\n\\nDepartment of Mechanical Engineering\\n\\nIndian Institute of Technology Kharagpur\\n\\n## Academic Qualifications\\n\\n| Year           | Degree/Certificate                                                       | Institute                                 | CGPA/ %   |\\n|----------------|--------------------------------------------------------------------------|-------------------------------------------|-----------|\\n| 2021 - Present | B.Tech and M.Tech in Mechanical Engineering micro Artificial Engineering | Indian Institute of Technology, Kharagpur | 8.29/10   |\\n| 2020           | Class XII (UP-Board)                                                     | Dr. CIL inter college                   | 82%       |\\n| 2018           | Class X (UP-Board)                                                       | Dr. CIL inter college                   | 90%       |\\n\\n## Internships\\n\\n## Product Development Internship | Dewinter India | Delhi, India\\n\\nMay'24 - Jul'24\\n\\n- Collaborated with Engineering team to identify and resolve issues in a device, leading to the automation of manual operations\\n- Optimized image processing modules for medical field, such as cancer fibrosis and cell cytology, using OpenCV , for automation\\n- Engineered an automated mechanism in SolidWorks with 0.01 mm accuracy, leading prototyping with advanced 3D printing\\n- Used data structures to enhance algorithm efficiency by 15% and a 5-class WBC classification module after in-domain research\\n\\n## Machine learning Internship | Tata Motors | IIT Kharagpur\\n\\nFeb'24 - Apr'24\\n\\nProject Title: Development of a low-cost AI-based tyre specification reading and downstream analytics Instructor: Prof.S K Pal\\n\\n- Utilised proprietary dataset with 1500+ samples, applied data augmentation, created hand-annotated dataset using Roboflow\\n- Handled angled ROI with perspective transformation , cartoonized for readability, and cropped letters for the processing\\n- Finetuned Yolo-v8 on training data, utilized OpenCV's minimum contour area to extract the ROI from the input image.\\n- Trained HOG Transform and YOLO-v8 seg to accurately read characters using geometric features , and tested at TML\"),\n",
              " Document(metadata={'resume_id': 'Dheeraj_CV - Dheeraj Kumar Prajapati', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Projects\\n\\n## Physics-Informed Machine Learning for Solid Mechanics | BTP\\n\\n2024\\n\\n- Simulated complex solid mechanics problems using PINNs with physics constraints and boundary conditions to improve accuracy\\n- Utilized LSWR loss functions, improving the accuracy and generalization of PINNs for predicting displacement and stress fields\\n- Used DeepXDE to simulate square section plate with an internal circle and a rectangular plate, achieving high-fidelity results\\n\\n## Research Intern | Department Of Computer Science | IIT Patna\\n\\nProject Title: Sentiment hate speech detection in Malay Language\\n\\nMay'23 - Aug'23\\n\\nprof S. Saha\\n\\n- Collaborated with Monash University to gather comprehensive information on hate speech and sentiment in Malay language\\n- Utilized M-BERT and XLM-Roberta models for generating embeddings from over 2.2k tweets, addressing imbalance with SMOTE\\n- Prepared a proprietary dataset for hate speech and sentiment detection in Malay using active learning and crowdsourcing\\n- Boosted model accuracy by implementing the Capsule Network on embeddings, achieving an impressive F1-Score of 0.80\"),\n",
              " Document(metadata={'resume_id': 'Dheeraj_CV - Dheeraj Kumar Prajapati', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Generative Adversarial Network's for MNIST Generation | Self Project\\n\\nJan'23-Mar'23\\n\\n- Implemented GANs in PyTorch with BCE, WGAN, and LSGAN Loss functions, utilized 3M+ parameters with ADAM optimizer\\n- Pickled GAN model using Pickle, created Flask App, and utilized the requests library for JSON response handling and deployment\\n- Achieved Inception Score of 8.9 and F1-Score of 0.82 using BCE loss on a dataset of 10k+ samples with a validation split 0.2\"),\n",
              " Document(metadata={'resume_id': 'Dheeraj_CV - Dheeraj Kumar Prajapati', 'chunk_id': 3, 'gpa_value': 96.0, 'gpa_scale': 100.0, 'gpa_normalized': 9.6, 'gpa_found': True}, page_content=\"## Competition and Conference\\n\\n## Open IIT Product Design | IIT Kharagpur\\n\\nMar'22 - Feb'22\\n\\nDeveloped a revolutionary assistive technology product Wear the Ear for people with hearing and vision disabilities\\n\\n- Secured 2nd place in a highly competitive product design competition for Wear the Ear product showcasing team-work\\n- Achieved an accuracy of 96% on the testing set of different sounds of humans, Animals and Machines resulting in a morse output\\n\\n## POSITIONS OF RESPONSIBILITY\\n\\n## Senior Executive Member || Gopali Youth Welfare Society\\n\\n•\\n\\n- Actively participated in various events, gaining hands-on experience in organizing, planning, and managing diverse social events\\n\\nEfficiently maintained Excel sheets, ensuring donation records were updated for smooth society functioning and transparency\"),\n",
              " Document(metadata={'resume_id': 'Dheeraj_CV - Dheeraj Kumar Prajapati', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Technical Skills\\n\\n- Languages and Frameworks: C, C++, Python, STL, NumPy, Pandas, Matplotlib, Sklearn, TensorFlow, Keras, PyTorch\\n- Softwares and utilities: Google Docs, Google Sheets, Excel, VS Code, Git, LaTex, AutoCAD, Solidworks, Ansys, MATLAB\\n\\n## Relevant Coursework\\n\\n- •\\n- Mathematics and Computer Science: Linear Algebra and Complex Analysis, Programming and data structures, Probability and Statistics, Transform Calculus, Advanced Calculus, Partial Differential Equations MOOCs: STATS 110, MIT OCW 18.01\\n- Machine Learning and Finance: Machine Learning Foundation and Applications MOOCs: CS229, CS230, CS231n'),\n",
              " Document(metadata={'resume_id': 'Dheeraj_CV - Dheeraj Kumar Prajapati', 'chunk_id': 5, 'gpa_value': 0.07, 'gpa_scale': 4.0, 'gpa_normalized': 0.18, 'gpa_found': True}, page_content='## Awards and Achievements\\n\\n- Awarded NMMS (NATIONAL MEANS-CUM-MERIT SCHOLARSHIP SCHEME) Scholarship by the Ministry of Education\\n- Led my school scout team as captain and successfully achieved first-place in the district-level scout camping championship.\\n- Cleared National Talent Search Examination, one of the toughest school level examinations world wide with a 0.07% success rate\\n\\n\\n\\ndheerajpra04@gmail.com\\n\\n/phone +91-8957817849\\n\\n/linkedin Linkedin'),\n",
              " Document(metadata={'resume_id': 'resume (2) - Diksha Uniyal', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education\\n\\n•\\n\\nEmail: diksha260303official@gmail.com\\n\\nMobile: +91-9354709955, +91-9899677785\\n\\nDehradun, India\\n\\nOct 2021 - Jul 2025\\n\\n## Graphic Era Hill University\\n\\n- Bachelor of Technology - Computer Science Engineering\\n\\nCourses: Operating Systems, Data Structures, Analysis Of Algorithms, Object Oriented Programming, Artificial Intelligence, Computer Networking, Databases'),\n",
              " Document(metadata={'resume_id': 'resume (2) - Diksha Uniyal', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Skills Summary\\n\\n- Languages : Python, C++, JavaScript, SQL\\n- Tools : Git, Firebase, Flutter, MySQL, OpenCV, Oracle, APIs, Matplotlib, Pandas, Numpy, Docker\\n- Platforms : Linux, Google Cloud, MS-Azure Cloud, Windows, ArcGIS, VS code, Jupyter Notebook\\n- Data Science : Dataset preprocessing, Data Integration, Data Analysis, Data Visualization, Geospatial Data\\n- Computer Vision : Object Detection, Image Classification, Semantic Segmentation, GANs, Transformer models\\n- Natural Language Processing : Word Tokenization, NER, POS, Word Embedding, Spacy, NLTK\\n- Machine Learning : Tensorflow, Keras, Pytorch, Decision Tree Learning, Random Forest, Regression, Text Mining\\n- Deep Learning : ANN, CNNs(VGG, Faster R-CNN, ResNet, PointCNN), U-Net Architectures, YOLO.'),\n",
              " Document(metadata={'resume_id': 'resume (2) - Diksha Uniyal', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Experience\\n\\n•\\n\\nHyderabad, India\\n\\nAug 2024 - Oct 2024\\n\\n## National Remote Sensing Center (NRSC) - ISRO\\n\\n- Summer Intern\\n- Geospatial Machine Learning Model for Weather Forecasting and Prediction : Developed a model for weather prediction that includes rainfall prediction, humidity prediction from past atmospheric data using machine learning techniques.\\n- Tools Used : API integeration, Decision Tree, Regression, preprocessing techniques\\n\\n## AAIWAY INDIA\\n\\n- Research Analytics and Development Intern\\n\\nBengaluru, India\\n\\nSep 2023 - Mar 2024\\n\\n- Web Application Development : Developed a web application for Diabetes Management in healthcare clinics.\\n- Tools Used : Flutter, Dart, TensorFlow, Keras, Firebase, SQL, Python\\n\\n## Technology Business Incubator\\n\\n- Research Intern\\n\\nDehradun, India\\n\\nApr 2024 - Jul 2024\\n\\n- Research Work : Discovered and reviewed various research papers related to cutting-edge technology for Chatbot development in various sectors like agriculture, healthcare etc.\\n\\n## Graphic Era Deemed to be University\\n\\n- AI &amp; IOT Intern\\n\\nDehradun, India\\n\\nJul 2022 - Oct 2022\\n\\n- Visual Question And Answering Through Satellite Images : Developed a computer vision model to identify various classes of objects in satellite images.\\n- Tools Used : Python, OpenCV, TensorFlow, Keras'),\n",
              " Document(metadata={'resume_id': 'resume (2) - Diksha Uniyal', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Projects (Projects Link)\\n\\n- Chatbot for Mental Health Assistance : Developed a chatbot that connects users with similar preferences using socket.io. It offers guidance, relaxation and meditation resources. Tools: HTML, CSS, JavaScript, React.\\n- Sign Language Translation Model : Built a model to generate text from sign language, assisting disabled people. Tools: Machine learning models like Long Short Term Memory, computer vision techniques.\\n- Healthcare Web Application : Developed an interface for communication between doctors and patients, with features like report uploads and authentication. Tools: Flutter, Firebase, MySQL.'),\n",
              " Document(metadata={'resume_id': 'resume (2) - Diksha Uniyal', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Publications\\n\\n- Artificial Intelligence Enabled Disease Prediction System in Healthcare Industry (ICBDS 2023) : Contributed to data preprocessing and ML model development (Random Forest, Regression, Decision Tree) to predict diseases using medical data. (Publication Link)\\n- Artificial Intelligence Integrated Rice Crop Disease Detection Using Drones for Smart Farming (ICCPCT 2024) : Worked with YOLO to detect rice crop diseases from drone images. (Publication Link)'),\n",
              " Document(metadata={'resume_id': 'resume (2) - Diksha Uniyal', 'chunk_id': 6, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Hackathons\\n\\n- Team shortlisted in Top 20 in Data Engineering Hackathon (Hack2Skill) by Informatica\\n- Team shortlisted for Round 1 in MahaKumbh 2025 Hackathon by IIIT Allahabad\\n\\n•\\n\\n•'),\n",
              " Document(metadata={'resume_id': 'Rohan resume - Gopathi Rohan', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Gopathi Rohan | Mail  | LinkedIn | +91 9059911867\\n\\n## Career Objective\\n\\nTo pursue a challenging career and be part of a progressive organization that gives scope to enhance my knowledge , skills and to reach the pinnacle in the computing and research field with sheer determination , dedication , and hard work . Motivated and analytical B.Tech Computer Science Engineering student with a specialization in Artificial Intelligence and Machine Learning.\\n\\n## Academic Details\\n\\n| Course/Specialization                          | I NSTITUTION                                        | %/CGPA   |   COMPLETION |\\n|------------------------------------------------|-----------------------------------------------------|----------|--------------|\\n| B.Tech : Computer Science Engineering (AI &ML) | Vignana Bharathi Institute Of Technology, Hyderabad | 7.2/10   |         2025 |\\n| Board of Intermediate Education                | Nano Junior college, Hyderabad                      | 84.4/100 |         2021 |\\n| Secondary School Certificate                   | Lotus Lap Public School, Hyderabad (SSC)            | 9.8/10   |         2019 |'),\n",
              " Document(metadata={'resume_id': 'Rohan resume - Gopathi Rohan', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## RELEVANT  COURSEWORK  and Skills\\n\\n- Introduction to Python\\n- Introduction to Machine Learning\\n- Artificial Intelligence\\n- Introduction to Data Structures and Algorithms\\n- Languages : C, Python, Java, Html, Css\\n- Frameworks &amp; Libraries : Standard C Library,  NumPy, Pandas, Matplotlib, TensorFlow'),\n",
              " Document(metadata={'resume_id': 'Rohan resume - Gopathi Rohan', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## B.Tech Project\\n\\n## Music Recommendation System Using Machine Learning\\n\\n- Developed a machine learning model on music recommendation system.\\n- Implemented many machine learning algorithms such as matrix factorization , clustering  , deep learning and sequence modeling.\\n- Utilized various machine learning algorithms to enhance the accuracy of music recommendation and user requirements.\\n\\n## Voice-Activated Virtual Assistant Using Machine Learning and Natural Language Processing\\n\\n- Developed a Voice-Activated Virtual Assistant(VAVA)  to create an interactive and intuitive user experience .\\n- Utilized machine learning algorithms and the Natural Language Processing engine.\\n- VAVA developed is very capable of understanding  and responding to user commands in natural language.\\n- Leveraged machine learning models like Automatic Speech Recognition for converting spoken language into text was used.\\n- Enhanced user experience by creating a reliable and efficient virtual assistant that simplifies everyday tasks.\\n\\n## Certifications\\n\\n- Google Cloud Generative-AI Virtual Internship, Eduskills(present)\\n- Ui Path Rpa Developer Advanced(April-June 2024)\\n- Blockchain, Certified By Infosys Spring Board(April-June 2024)\\n- Salesforce Developer, Certified by SmartInternz(Sep-Nov 2023)\\n- Data Structures And Algorithms Using Python, Certified by Infosys(Sep-Dec 2022)\\n- C Programming Essentials, Certified by Cisco(Jan-April 2022)\\n\\n## Positions/Responsibilities\\n\\nJuly 2024 -Present\\n\\n- Natural Language Processing\\n- Data Mining and Data Warehousing\\n- Database Managament System\\n- Operating System\\n- Software Engineering\\n- Cloud Computing\\n- Computer Networks\\n\\nJuly 2024 - Present\\n\\n## · Member of TEDX-VBIT core team  (Role : Production Team) · ROBOTICS CLUB VBIT -Logistics Team\\n\\n| Personal Details   |\\n|--------------------|\\n\\n· DOB : 1 st  September 2003 · Languages Known : Telugu , English , Hindi'),\n",
              " Document(metadata={'resume_id': 'Resume Rishikesh(!) - P S Rishikesh', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## P S Rishikesh\\n\\n## ELECTRONICS AND COMMUNICATION ENGINEER/NASSCOM Certified Developer\\n\\n9972741817/7022427352 · rishi191003@gmail.com · www.linkedin.com/in/P-S-Rishikesh08B176283/ https://github.com/rishikeshgithu/                   https://www.kaggle.com/rishi1903\\n\\n## CARRER OBJECTIVE\\n\\nAn ambitious student with a strong interest in entrepreneurship, coding, and the Electronics Industry 4.0. Driven by passion, I actively joined startups during my college years, aiming to contribute to their growth while immersing myself in the dynamic world of technology. My goal is not only to learn and expand my skills but also to play a pivotal role in the advancement of both personal and the company I engage with.'),\n",
              " Document(metadata={'resume_id': 'Resume Rishikesh(!) - P S Rishikesh', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## EDUCATION\\n\\nB.Tech, Electronics and Communication , Amrita Vishwa Vidyapeetham Bangalore, 2021-2025 ( NIRF Ranking 16 in 2021)\\n\\n## PROFESSIONAL CERTIFICATION\\n\\n- NASSCOM Certificate for Full Stack Development (12 months)\\n- Coding Ninjas Certificate of Excellence in Data Science and Machine Learning (11 Months)\\n- Coding Ninjas Certificate in Python and C++ (12 months)\\n- Emertxe Embedded System Course (9 months)'),\n",
              " Document(metadata={'resume_id': 'Resume Rishikesh(!) - P S Rishikesh', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## WORK EXPERIENCE\\n\\nMom and POP -Data Science/Machine Learning Intern(Stipended)\\n\\n05/2024 - Present  .\\n\\nProject Title: Market Basket Analysis -Given Different Transaction Datasets, Find Transaction Patterns Using Apriori Algorithm and Data Visualization.\\n\\nProject Title: Bill Reading in Khmer Language and English Language using OCR\\n\\nTech Stack: Python,Streamlit,Market Basket Analysis, Data science , Data Analysis, Matplotlib,Pandas,Handling datasets,Apriority Algorithm,OCR,Docusmo.\\n\\nIIT  Delhi  Research  Project -Python  Intern  and  Embedded  Systems  under  Dr  Vamsi  Challamala Associate Professor, Dept of Applied Mechanics 05/2024 -06/2024\\n\\nProject Title: Low-Design of ROV for Underwater Applications using Camera, Sonar  and multisensory Data Fusion algorithms for underwater Navigation and Sensing.\\n\\nTech Stack: Python, Sensor integration, Remote Sensing\\n\\nIISC Research Project -IOT/Data Mining Intern under Dr Vishal Singh Associate Professor, Design and Manufacturing Lab(Stipended) 04/2024-06/2024\\n\\nProject Title: Data Collection using Raspberry pi 4 and Raspberry pi 3 for Handwash Cleaning techniques using Camera and Create a Dataset For training Machine Learning Algorithm.\\n\\nTech Stack: Raspberry-Pi4/3,Python,Open-CV,DataScience,ML,Circuit designing, Soldering, Cloud Computing\\n\\nGovt Funded Research Project (IIT Hyderabad Tihan) - Embedded AI Intern under IIT Researcher Dr Jaya Sharma / Dr Pradyumn Sharma 02/20240 -05/2024\\n\\nProject  Title:  Low-Cost  Unmanned  Autonomous  Ground  Vehicle  (UGV)  Prototype  for  Reconnaissance  and Surveillance using Raspberry Pi, Lidar Technology Coding, and Integration to Rover\\n\\nTech Stack: C++,Python, ML, Open CV , Circuit Designing, Raspberry pi-4, IOT\\n\\n## Atto Communication Bangalore IOT Intern\\n\\n01/2024 -04/2024\\n\\nGained expertise in MQTT and Lora Chirpstack. Installed a specialized OS on Raspberry Pi 4 for Chirpstack integration. Used Docker and Nix for deploying Chirpstack's application. Planned to use this setup to collect sensor data in remote areas with limited connectivity.\\n\\nTech Stack: Raspberry PI-4,Chirp Stack, Docker, Sensor, LORA, Gateway-Chirpstack OS, IOT, Ubuntu\\n\\n## Rytesense Technology -AI Application Developer\\n\\n02/2024 - 03/2024\\n\\nDeveloped Voice-to-Voice AI for mic communication. Implemented speech-to-text with fast-whisper and Vosk. Used Twilio for live phone call streaming. Integrated improved stream for AI speech generation in calls using Python.\\n\\nTech Stack: Voice Based AI, LLM, LM Studios, Python, Twilio, Sound Analysis and noise removal, API, TTS, Speech to text\\n\\n## Maskottchen Tech Python Developer Intern\\n\\n10/2023 - 02/2024\\n\\nHelp Develop Frontend of Django based Patient Optical Diagnostic Web Application.Improved websites style and functionality.\\n\\nTech Stack: Python , Django, Html, CSS, JavaScript, Backend\"),\n",
              " Document(metadata={'resume_id': 'Resume Rishikesh(!) - P S Rishikesh', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILL\\n\\n- Programming Languages: C++, C, Java, Python, Bash, MATLAB\\n- Technologies: Microcontroller (Raspberry Pi-4, Pic, Arduino, Esp8266, Esp32), Machine Learning, Automation, ROS, Embedded System, Computer Vision, Linux (Ubuntu)\\n- Databases: MySQL /Version Control: Git / Cloud Services: AWS'),\n",
              " Document(metadata={'resume_id': 'Resume Rishikesh(!) - P S Rishikesh', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## PROJECT LINK\\n\\n· [1]= https://drive.google.com/file/d/1LPeTKmAeQCS\\\\_dL3cw6p4ZMApNIAuMp8h/view?usp=drive\\\\_link'),\n",
              " Document(metadata={'resume_id': 'Chirag_Btech_AI - Chirag Budakoti', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SUMMARY\\n\\nComputer Science student with expertise in Python, JavaScript, and full-stack development  using  Django,  Flask,  and  React.  Skilled  in  automation  testing, DevOps,  and  data  visualization,  with  projects  in  areas  like  custom  browser development, data dashboards, and AI-based clustering. Experienced in cloud architecture  and  actively  pursuing  advanced  learning  in  web  and  software development.\\n\\n## CONTACT\\n\\n9667597918\\n\\nPhone:\\n\\nchiragbudakoti12334@gmail.com\\n\\nEmail:\\n\\nLinkdin:\\n\\nhttps://www.linkedin.com/in/chira g-budakoti-212902263/'),\n",
              " Document(metadata={'resume_id': 'Chirag_Btech_AI - Chirag Budakoti', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS\\n\\n- Python, Java, javascript, C, PHP (programming languages known)\\n- Linux, Windows (Operating systems)\\n- Django,Flask,React, Laravel (web frameworks)\\n- Selenium,Bs4, Spyder(automation and web scraping)\\n- MySQL, Sqlite3, Mongo DB (data bases)\\n- git, docker, Jenkins(developer operations)\\n- TensorFlow, scikit, numpy, pandas (for Ai and machine learning models)\\n- AWS (cloud)'),\n",
              " Document(metadata={'resume_id': 'Chirag_Btech_AI - Chirag Budakoti', 'chunk_id': 3, 'gpa_value': 74.0, 'gpa_scale': 100.0, 'gpa_normalized': 7.4, 'gpa_found': True}, page_content='## EDUCATION\\n\\n## Higher Secondary Certificate(HSC)\\n\\nKendriya vidyalaya NFC · 2009-2021 Science stream PCM with CS 74%\\n\\n## Bachelor of Technology in Computer Science (AI)\\n\\nAbdul Kalam Technical University • 2021-2025\\n\\n## LANGUAGES\\n\\n- Hindi - Native\\n- English - Proficient'),\n",
              " Document(metadata={'resume_id': 'Chirag_Btech_AI - Chirag Budakoti', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## EXPERIENCE\\n\\n## Cloud Aechitecturing (training)\\n\\naws academy • sep 2024 - sep 2024\\n\\n- In Cloud Architecting training, I learned to design scalable, reliable cloud infrastructures and gained hands-on experience with services like EC2, S3, and VPCs to optimize cloud resource management and security.\\n- Additionally, I explored best practices for cloud deployment and automation using AWS tools.\\n\\n## Data Analytics (Internship)\\n\\n## IBM Company • july - aug 2024\\n\\n- Analyzed large datasets using Python, SQL, and Excel to extract actionable insights.\\n- Developed automated dashboards and reports to streamline decision-making processes.\\n- Collaborated with cross-functional teams to define data requirements and improve business outcomes.'),\n",
              " Document(metadata={'resume_id': 'Chirag_Btech_AI - Chirag Budakoti', 'chunk_id': 6, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Instagram comment scrapper(project)\\n\\n- Created an Instagram comment scraper with Selenium for data extraction.\\n- Improved post navigation, comment collection, data accuracy, and analysis efficiency.'),\n",
              " Document(metadata={'resume_id': 'Chirag_Btech_AI - Chirag Budakoti', 'chunk_id': 7, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Cb-blogs (project)\\n\\n- Created a blog website with Flask and SQLite3, integrating user authentication, post management, commenting, responsive UI design, data security, and efficient data retrieval.'),\n",
              " Document(metadata={'resume_id': 'Chirag_Btech_AI - Chirag Budakoti', 'chunk_id': 8, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Chatbot song recommender system(project)\\n\\n- Developed a chatbot that recommends songs based on user preferences using NLP.\\n- Integrated APIs for personalized music suggestions and analyzed song data.\\n- Designed a user-friendly interface for seamless interaction.'),\n",
              " Document(metadata={'resume_id': 'Mohit_CV - Mohit Lohani', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='Artificial Intelligence                                                               linkedin.com/in/mohit-lohani-548207216\\n\\nDr. B.R. Ambedkar National Institute of Technology, Jalandhar                    github.com/mohitlohani7'),\n",
              " Document(metadata={'resume_id': 'Mohit_CV - Mohit Lohani', 'chunk_id': 1, 'gpa_value': 73.0, 'gpa_scale': 100.0, 'gpa_normalized': 7.3, 'gpa_found': True}, page_content='## EDUCATIOn\\n\\n| Degree         | Institute/Board                                       | CGPA/Percentage   | Year      |\\n|----------------|-------------------------------------------------------|-------------------|-----------|\\n| M.Tech in AI   | National Institute of Technology, Jalandhar           | On-going          | 2024-2026 |\\n| MBA(Part-Time) | Mahatma Jyotiba Phule Rohilkhand University, Bareilly | 73%(on-going)     | 2022-2025 |\\n| B.Tech         | Mahatma Jyotiba Phule Rohilkhand University, Bareilly | 78.40%            | 2018-2022 |'),\n",
              " Document(metadata={'resume_id': 'Mohit_CV - Mohit Lohani', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## ExPERIEncE\\n\\n## The Spark Foundation [ ]\\n\\n\\n\\n## Data Science and Bussiness Analyst Intern\\n\\n- Conducted a comprehensive analysis of sales data to identify key trends and insights\\n- Used Excel and Power BI to create visualizations that highlighted areas for improvement\\n- Presented findings to the class, demonstrating the impact of data-driven decisions on business performance\\n\\n## Adama India Private Limited [ ]\\n\\n## Graduate Apprentice Trainee\\n\\nSep 2022-Feb 2023\\n\\nDahej , Gujarat\\n\\n- Analyze large datasets using SQL queries to extract insights and identify trends.\\n- Create interactive data visualizations using the tool and Tableau to communicate findings\\n- Ensure data integrity through cleaning and preprocessing\\n- Stay updated on industry best practices and emerging technologies'),\n",
              " Document(metadata={'resume_id': 'Mohit_CV - Mohit Lohani', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## PROjECTs\\n\\n- Sales Analysis and Forecasting Project\\n\\nTools: Power BI, SQL\\n\\n- Analyzed historical sales data to identify trends and KPIs using SQL queries.\\n- Created interactive Power BI dashboards to visualize sales trends and product performance.\\n- Implemented forecasting models in Power BI to predict future sales.\\n- Delivered insights that improved inventory management and marketing strategies.\\n- System Performance Analysis and Forecasting\\n\\nTools: Power BI, SQL, Python, Linux Kerne\\n\\n- Collected system performance metrics (e.g., CPU utilization, memory usage) from the Linux kernel and stored them in a SQL database.\\n- Used Python to clean, process, and analyze the data, identifying trends and patterns.\\n- Created interactive dashboards in Power BI to visualize current system performance and forecast future trends, enabling data-driven decisions.'),\n",
              " Document(metadata={'resume_id': 'Mohit_CV - Mohit Lohani', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLs\\n\\n- Programming Languages : [Python, C, C++(Basic )]\\n- Technologies : Data Analysis and Visualization (Numpy,Pandas, Matplotlib, Power BI), Machine Learning (Scikit-learn, TensorFlow), Deep Learning\\n- Tools : Power BI, SQL (PostgreSQL), Jupyter Notebook,\\n\\n## CERTIFICATIOns\\n\\n| Issuing Organization 1 , SQL(Basic) Skill assessment by HackerRank    | July 2023   |\\n|-----------------------------------------------------------------------|-------------|\\n| Issuing Organization 2 , Python(Basic) Skill assessment by HackerRank | May 2023    |\\n\\n- Top Ranker in Essay Competition Organized by Bajaj\\n- Top Ranker in AutoCAD Test organized by Internshala\\n- Among in top Ranker in B.Tech 7&amp;8 semesters with 8.42 and 9.14 SGPA\\n\\n## PosITIOns of REsPOnsIBILITy\\n\\n- Position  A , Member, Virtual Lab Committee, Virtual LAB University Level Virtual Lab Program held at Bareilly Aug 2021\\n- Position  B, Member, Organizing Committee, Onederclub National Youth Festival at MJP\\n\\nMay 2020\\n\\nOct 2023 - Nov 2023\\n\\nRemote\\n\\nAug 2023\\n\\nOct 2023'),\n",
              " Document(metadata={'resume_id': 'yashg4824  - YASH GUPTA', 'chunk_id': 1, 'gpa_value': 94.4, 'gpa_scale': 100.0, 'gpa_normalized': 9.44, 'gpa_found': True}, page_content='## Education\\n\\n## Netaji Subhas University of Technology (erstwhile NSIT), Delhi, India\\n\\n- Course: B.Tech. Information Technology (Geoinformatics) | CGPA: 8\\n\\nDAV Public School Dwarka, Delhi, India                                                                                                                   2021 - 2022\\n\\n- AISSCE (Class XII), Aggregate: 94.40 %\\n\\nDAV Public School Dwarka, Delhi, India                                                                                                                   2019 - 2020\\n\\n- AISSE (Class X), Aggregate: 90.00 %'),\n",
              " Document(metadata={'resume_id': 'yashg4824  - YASH GUPTA', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Skills\\n\\n- ●\\n\\n- Langauge:\\n\\nC++, Python, Javascript, SQL, JQuery, Express.js\\n\\n- Toolkit : Git, MySQL, Microsoft Azure AI, QGIS, Google Earth Engine\\n\\n- Soft Skills : Leadership, Event Management, Public Speaking\\n\\n- Interests: Web Development,Competitive Programming, Machine Learning, DSA'),\n",
              " Document(metadata={'resume_id': 'yashg4824  - YASH GUPTA', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Work Experience\\n\\n## Indian Space Research Organisation | Space Technology Cell, IIT Delhi Certificate\\n\\nSummer Intern under Prof Dhanya CT, Chair Professor, IIT D\\n\\n- Developed the \"Drought Monitoring Portal\" for IIT Delhi\\'s Jal Suraksha Portal, integrating the SNEPI Index to display realtime drought conditions. Utilized Google Earth Engine, WebGIS, and Matlab to process precipitation &amp; evapotranspiration data for drought detection. The project is part of ongoing research at IIT Delhi and was integrated into the Jal Suraksha Portal, enhancing India\\'s real-time drought monitoring capabilities\\n\\nTech Stack : JS, Leaflet.js, Node.js, Express.js, Matlab, Google Earth Engine Github\\n\\n## Microsoft Workshop | Certified Microsoft Innovative Educator\\n\\nMayÕ19\\n\\n- Participated in Microsoft in Education 2 month Workshop, explored Microsoft Software to integrate education in 2021 Projects\\n\\n## Voice Assisted Chatbot for ISROÕs Bhuvan Portal\\n\\n## JanÕ24\\n\\nDeveloped an API-based Voice Assisted Chatbot for ISRO\\'s Bhuvan portal, aimed at enhancing user experience and accessibility.\\n\\n- The innovative chatbot employs AI4Bharat, an IIT Madras\\'s Speech To Text model, fine-tuned on the Hindi common voice dataset for superior speech-to-text capabilities.Its leverages Lang chain Library and Gemini API for text generation, and personalised the chatbot to seamlessly navigate ISROÕs Geospatial Data Portal.\\n\\n## URJA | Solar Sarthi: Transforming Energy with AI\\n\\nAprilÕ24\\n\\nDeveloped an API-based Chatbot for Embracing Sustainable Development , to streamline approach to transitioning to solar energy\\n\\n- Chatbot analyse energy usage, provides access to government incentives and subsidies, utilise advanced algorithms to calculate optical  Solar Panel, offered guidance on panel selection and maintenance based on cost-effectiveness\\n- Github Repository: Project | Certificate\\n\\n## Built a Face Recognition Application Using Python'),\n",
              " Document(metadata={'resume_id': 'yashg4824  - YASH GUPTA', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Academic and Extracurricular Achievements\\n\\n- Offered Summer Research Intern at NRSC Hyderabad\\n- Cleared the Practice round of Facebook Meta HackerCup by securing 2165 rank &amp; 7875 Rank in Round 1 Certificate\\n- Grabbed an AIR 10 among 50 teams selected out of 4037 teams in the Initial Round and an Position in Top 24 in the Grand Finale of IISF 2023 Space Hackathon Organised by ISRO\\n- Bank of Baroda Hackathon 2024 Finalists , Selected among top 200 teams out of 26K Submission\\n- Secured 3rd Position out of 30+ teams &amp; Cash Prize 3000 INR in Solvesphere Hackathon at E-SummitÕ2024 , IIIT D\\n- WEB3 Ideation 1st Runner-Up by GirlScript Foundation\\n\\n## Positions of Responsibility\\n\\nCadet NCC NSUT | Tech team | Contributed in NCC Website\\n\\nSepÕ23 - Present\\n\\nExecomm Member | The Debugging Society                                                                                                  SepÕ23 - Present\\n\\n- Event Lead, CodeQuest - Digital Scavenger Hunt -Led the design, execution, and logistics of a campus-wide digital scavenger hunt with programming challenges during Annual fest Moksha-Innovision 2024\\n\\n## YASH GUPTA\\n\\nyash.gupta.ug23@nsut.ac.in | Github | LINKEDIN | Codeforce |+91 - 8595609721\\n\\n2023 - 2027\\n\\nMayÕ24-JulyÕ24'),\n",
              " Document(metadata={'resume_id': 'Sumedh_Resume (3) - Sumedh Kole', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Sumedh Uday Kole\\n\\nBachelor of Technology\\n\\nAerospace + Entrepreneurship Engineering\\n\\nIndian Institute of Technology, Kharagpur'),\n",
              " Document(metadata={'resume_id': 'Sumedh_Resume (3) - Sumedh Kole', 'chunk_id': 1, 'gpa_value': 94.33, 'gpa_scale': 100.0, 'gpa_normalized': 9.43, 'gpa_found': True}, page_content='## EDUCATION\\n\\n•\\n\\n- Indian Institute of Technology Kharagpur\\n\\nB.Tech + M.tech (Dual Degree) - Aerospace Engineering; GPA: 8.56\\n\\n•\\n\\n## Sanjay Ghodawath Olympiad Schooll\\n\\nSenior Secondary School; Grade: 94.33%\\n\\n•\\n\\n## Nav Krishna Valley School\\n\\nHigh School; Grade:\\n\\n92.00%\\n\\n## INTERNSHIPS\\n\\n## Passive Mine Classification using Quantum Machine Learning\\n\\nProf.Indranil Hazra (research intern)\\n\\n+91-8208711684 sumedhkole@gmail.com LinkedIn\\n\\nWest Bengal, India December 2021 - Present Maharashtra, India May 2021 Maharashtra, India May 2019\\n\\nOn-site\\n\\nApr 2024- Present\\n\\n- Engineered an ANN achieving 70% accuracy on 350+ data points, surpassing prior research results\\n- Trained the model in Keras with StandardScaler preprocessing and sparse categorical cross-entropy loss\\n- Designed and built the hybrid quantum-ANN model using Tensorflow and Qiskit , aiming for over 90% accuracy\\n\\n## Fish Species Recognition and Biomass Detection\\n\\nProf.Jayraj P. (research intern)\\n\\nOn-site\\n\\nDec 2023-Apr 2024\\n\\n- Analyzed the Fish4Knowledge dataset of 23,000+ images using data augmentation and noise reduction\\n- Developed and optimized a CNNbased ResNet-10 model, achieving 99.41% accuracy\\n- Created a 500+ image dataset with Label-Img and performed object tracking using OpenCV\\n- Designed YOLOv8 with BoTSORT , achieving 92.99% precision, 73.69% recall, and 85.59% mAP50'),\n",
              " Document(metadata={'resume_id': 'Sumedh_Resume (3) - Sumedh Kole', 'chunk_id': 2, 'gpa_value': 83.29, 'gpa_scale': 100.0, 'gpa_normalized': 8.33, 'gpa_found': True}, page_content='## PROJECTS\\n\\n## LLM-Powered Equity News Analysis Tool\\n\\nSelf Project\\n\\nFeb 2024-Mar 2024\\n\\n- Loaded and preprocessed news articles dynamically using TextLoader and UnstructuredURLLoader\\n- Deployed RecursiveCharacterTextSplitter for effective text chunking and developed a responsive Streamlit interface\\n- Used OpenAI embeddings for tokenization and text segmentation , with FAISS for vector storage and retrieval\\n\\n## Brain MRI Segmentation with SA-UNet\\n\\nSelf Project\\n\\nMay 2024-Jun 2024\\n\\n- Improved Low Grade GliomasMRI dataset of 110 patients using normalization and patch extraction\\n- Implemented SA-UNet with spatial attention Mechanisms for brain MRI segmentation using Dice loss function\\n- Achieved 83.29% validation and 87.21% accuracy, enhancing medical diagnostics and image analysis\\n\\n## COURSEWORK INFORMATION\\n\\n- Computer Science : Programming and Data structures Theory, Programming and Data structures Laboratory\\n- Mathematics : Advanced Calculus, Linear Algebra,Transform Calculus ,Numerical Solutions of PDE\\n- Aerospace : Introduction to Flight Vehicle Controls, Aerospace Structures, Thermodynamics and Aerospace Propulsion Systems, Introduction to Aerodynamics, Low-Speed Aerodynamics, Dynamics for Aerospace Engineers\\n- MOOCs : Python for Data Science, Generative AI for everyone, LangChain for LLM Application Development, Data Structures and Algorithms, Quantum Machine Learning,Economics, Multi AI Agent System with crewAI'),\n",
              " Document(metadata={'resume_id': 'Sumedh_Resume (3) - Sumedh Kole', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS AND EXPERTISE\\n\\n- Programming Languages/Libraries : C, C++, Python, Qiskit, Numpy, Pandas, Scikit Learn, Matplotlib, Keras, Pytorch, Tensorflow\\n- Software and Skills : jupyter notebook, Google Colab, Visual Studio Code, Code Blocks, FreeCad, MS Office, TinkerCad, MATLAB, QLattice, Label-Img, Kaggle, PyCharm, SQL\\n- Soft Skills : Leadership, Event Management, Writing, Public Speaking, Time Management\\n\\n## Extra Curriculum Activities\\n\\n- National chess player with a valid international classical rating of 1228 from the FIDE\\n- Certified in CPR and conducted discussions on mental health as a National Service Scheme volunteer\\n- Represented the Radhakrishnan Hall of Residence chess team that won at the General Championship 2022-2023'),\n",
              " Document(metadata={'resume_id': 'ARBAB MEHMOOD CV - ARBAB MEHMOOD', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## ARBAB MEHMOOD\\n\\nDate of birth:\\n\\n01/11/2002\\n\\nNationality:\\n\\nPakistani\\n\\nGender:\\n\\nMale\\n\\n## CONTACT\\n\\n\\n\\nKHAILD MEHMOOD C/O MALIK PROPERTY DEALER PAF ROAD NIAZI PLAZA MIANWALI.PUNJAB,PAKISTAN 4200 MIANWALI, Pakistan (Home)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\narbab2k2019@gmail.com\\n\\n(+92) 3255661708\\n\\nlinkedin.com/in/arbabmehmood-0735a9254\\n\\n+923255661708 (WhatsApp)'),\n",
              " Document(metadata={'resume_id': 'ARBAB MEHMOOD CV - ARBAB MEHMOOD', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## ABOUT ME\\n\\nI am actively pursuing an AI internship to elevate my Python prowess, particularly in harnessing the power of NumPy, Pandas, and Matplotlib. My goal is to seamlessly apply these skills to cutting-edge AI projects, guided by industry luminaries. With an insatiable thirst for knowledge, I am poised to coalesce theoretical understanding with practical implementation, catalyzing innovative solutions. My unwavering dedication to continuous growth fuels my ambition to enrich team dynamics, while seizing every opportunity for mentorship and handson experience to re fi ne my technical acumen.'),\n",
              " Document(metadata={'resume_id': 'ARBAB MEHMOOD CV - ARBAB MEHMOOD', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## EDUCATION AND TRAINING\\n\\n\\n\\n13/09/2021 - CURRENT Rawalpindi\\n\\nBachelor in Software Engineering PMAS-Arid Agriculture University Rawalpindi\\n\\nWebsite https://www.uaar.edu.pk/\\n\\n27/12/2023 - 01/01/2024 Remote, Pakistan\\n\\nInternship Machine Learning Mentorness\\n\\nWebsite https://www.mentorness.com/'),\n",
              " Document(metadata={'resume_id': 'ARBAB MEHMOOD CV - ARBAB MEHMOOD', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## DIGITAL SKILLS\\n\\nGoogle meet, Microsoft powerpoint Zoom &amp; Telegram Microsoft: Microsoft Word, Microsoft PowerPoint, Microsoft Outlook, Microsoft Teams'),\n",
              " Document(metadata={'resume_id': 'ARBAB MEHMOOD CV - ARBAB MEHMOOD', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## LANGUAGE SKILLS\\n\\nMOTHER TONGUE(S): Urdu Other language(s): English\\n\\nListening C1\\n\\nSpoken production B2\\n\\nReading B1\\n\\nSpoken interaction B2\\n\\nWriting B2\\n\\nLevels: A1 and A2: Basic user; B1 and B2: Independent user; C1 and C2: Pro fi cient user\\n\\n## CONFERENCES AND SEMINARS\\n\\n\\n\\n## 16/12/2020 - 16/12/2020\\n\\n## Certi fi cate of Participation( Women Empowerment webinar)\\n\\nWomen Empowerment webinar which was held on (16 December, 2020)\\n\\n## CURRENT INTERNSHIPS\\n\\n## 25/04/2024 - CURRENT\\n\\n## The Sparks Foundation Remote Internship (IOT &amp; Computer Vision)\\n\\nThe Graduate Rotational Internship Program is a unique o ff er for students and recent graduates to experience and join The Sparks Foundation. In addition to skills-speci fi c tasks, we encourage interns to build a credible professional pro fi le.\\n\\nLink https://internship.thesparksfoundation.info/\\n\\n## 05/04/2024 - CURRENT\\n\\nInter info tech Remote (AI Engineer Internship )\\n\\nLink https://www.infotechinc.com/\\n\\n## 01/04/2024 - CURRENT\\n\\n## CODETECH IT SOLUTIONS\\n\\nLink https://codtechitsolutions.com/'),\n",
              " Document(metadata={'resume_id': 'ARBAB MEHMOOD CV - ARBAB MEHMOOD', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## COMMUNICATION AND INTERPERSONAL SKILLS\\n\\n## Team Manager\\n\\nDemonstrating my prowess in verbal communication, I have excelled as a Team Manager within the All Pakistan Student Council, orchestrating diverse activities such as organizing free medical camps with fi nesse. This role has not only honed my ability to e ff ectively convey ideas and instructions but has also underscored my capacity to foster collaboration and synergy within teams. Leveraging this experience, I am poised to bring a dynamic and impactful approach to project and human resource management, driving success and fostering innovation within any endeavor.\\n\\nLink https://apsu.pk/\\n\\n## Event Organizer\\n\\nWrite here the description...As a Cultural and Social Event Organizer at the Student Welfare Association Mianwali, I lead in planning and executing diverse events, from cultural festivals to community outreach programs. By combining creativity with strategic planning and stakeholder collaboration, I've orchestrated transformative experiences that enrich student life and promote social awareness. My commitment to enhancing student welfare has made a signi fi cant impact, establishing our association as a hub for community enrichment and cultural celebration.\\n\\nLink https://www.facebook.com/groups/swami10/\"),\n",
              " Document(metadata={'resume_id': 'Resume_Shikhar_USAR(G.G.S.I.P.U) - Shikhar Kanojia', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education\\n\\n## • Bachelor of Technology in Automation and Robotics\\n\\n2021-25\\n\\nUNIVERSITY SCHOOL OF AUTOMATION AND ROBOTICS Surajmal Vihar New Delhi\\n\\nCGPA:8.21\\n\\n## • Diploma in Computer Science Engineering\\n\\nYear: 2022\\n\\nCHHATRAPATI SHAHU JI MAHARAJ GOVERMENT POLYTECHNC AMBEDKARNAGAR U.P,\\n\\nPercentage:78.64.'),\n",
              " Document(metadata={'resume_id': 'Resume_Shikhar_USAR(G.G.S.I.P.U) - Shikhar Kanojia', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## · (Diploma Minor)- Project Submarine Rock Vs Mine Prediction System (M.L )model\\n\\nA ML based simulation model designed to detect and differentiate rocks v/s mines.\\n\\n- -Develop a machine learning model to differentiate between submarine rocks and mines.\\n- -Used Live detection techniques and simulation. Use sonar dataset predict to capture underwater objects.\\n- -Enhance underwater safety for navigation, defense, and exploration. Provide accurate, real-time predictions to identify potential hazard\\n- -Technology Used: Python,css ,sonardata set,pycharm .\\n\\n## · (Diploma Major) -Vechile Service Management System ( Web Deveploment+ML Model)\\n\\nDevelop a web-based Vehicle Service Management System with user registration, scheduling, and service tracking\\n\\n- -Integrate a machine learning model to predict maintenance needs based on vehicle data.\\n- -Technology Used: Python java script, Django, HTML Css.\\n\\n## · B.Tech 2 nd Year Internet Of Things(Iot) Car\\n\\nThis project involves developing an IoT-enabled car system to enhance vehicle monitoring and maintenance.\\n\\n- -Tracking world-wide cases using google maps and live API stats and datasets.\\n- -Transmitting real-time data to a central server for analysis..\\n- -Creating a user-friendly app for status updates, alerts, and maintenance recommendations.\\n- -Technology Used : Arduino , IoT Sensors, Bluetooth Module,Ultrasonic Sensor,GPS Module,Battery Pack,DC Motors,Motor Driver Module.'),\n",
              " Document(metadata={'resume_id': 'Resume_Shikhar_USAR(G.G.S.I.P.U) - Shikhar Kanojia', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Experience\\n\\n## · Summer Training On (Python With Machine Learning\\n\\nSoftpro India pvt Ltd., Lucknow\\n\\n- -Comprehensive understanding of machine learning algorithms and techniques..\\n- -Proficiency in Python programming for machine learning applications.\\n- -Hands-on experience in data preprocessing, model building, and evaluation.\\n- -Implementation of supervised and unsupervised learning techniques.\\n- -Real-world application of machine learning models for predictive analytics and decision-making.\\n- -In-depth understanding of AWS cloud computing services,including TensorFlow, PyTorch, scikit-learn, Keras, OpenCV, Google AI Platform, Amazon, Microsoft Azure Machine Learning,\\n\\n## · Internship Course on RPA (Robotic Process Automation)\\n\\nNIELIT, Gorakhpur\\n\\n01 July - 29 July 2023\\n\\nOnline\\n\\n- -Introduction to RPA, Basics of Automation and Business Process Management (BPM), Understanding RPA Tools and Platforms (e.g., UiPath, Automation Anywhere, Blue Prism), RPA Development Environment Setup, Creating and Managing RPA Workflows, Data Manipulation and Integration in RPA, Error Handling and Debugging in RPA, RPA Deployment Strategies and Best Practices, Advanced RPA Concepts and Cognitive Automation,Industry Applications, and Future Trends in RPA.\\n\\n## · Internship Course on Robotics\\n\\nElectrocus Solutions Pvt Ltd., Lucknow\\n\\n-\\n\\n- -Basic Electronics and Microcontroller Programming: Learn about electronic components, circuits, and programming microcontrollers like Arduino. NodeMCU ESP8266\\n- -Sensor Integration, Actuator Control, and CNC Networking: Explore sensor integration (e.g., ultrasonic, IR) for environmental perception, actuator control (e.g., motors, servos), and CNC machine operation. Develop skills in CNC networking for machine communication and control.\\n\\n02 Aug - 31 Aug 2023\\n\\nOffline\\n\\n+91-8840587593 shikharsk72@gmail.coml GitHub LinkedIn\\n\\n15 sep - 30 oct 2021\\n\\nOfline\\n\\nNational Institute of Electronics &amp; Information,\\n\\n28 June- 04 Aug 2024\\n\\nOffline\\n\\nAn Autonomous Scientific Society under administrative control of Ministry of Electronics &amp; Information Technology (MoE&amp;IT),Government of India\\n\\nMentor: Ghanshyam Shivhare Additional Director (Scientist-D) (Training Co-ordinator)\\n\\n- --Completed a 6-week internship where I developed an Adaptive Gesture-Responsive Robot Simulation for Hazardous Environments . This project involved building a gesture recognition system using LSTM and CNN algorithms, and simulating robotic operations with ROS , Gazebo , and RViz for control and visualization .\\n- -Utilized AI tools such as TensorFlow , Keras , and OpenCV for implementing deep learning models and real-time image processing.\\n- -Gained experience in AI , robotics , and Python programming , applying adaptive learning algorithms to enhance robotic interaction and automation.'),\n",
              " Document(metadata={'resume_id': 'Resume_Shikhar_USAR(G.G.S.I.P.U) - Shikhar Kanojia', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Technical Skills and Interests\\n\\nLanguages\\n\\n: C/C++, Python, HTML+CSS\\n\\nLibraries\\n\\n:Numpy, Pandas, TensorFlow,Scikitlearn,Keras,Matplotlib,SciPy,Gazebo\\n\\nRobotics simulation tools : Autocad and Solidworks software, ROS (Robotic Operating System) and MATLAB basic Cloud/Databases :ROS 2 Cloud Extensions,Google Cloud Robotics, Relational Database(mySql)\\n\\nRelevent Coursework : Data Structures &amp; Algorithms, Operating Systems, Database Management System, Software Engineering.\\n\\nAreas of Interest :Robotics,R.P.A(Robotic Process Automation), ROS, MATLAB, Computer Vison, SLAM .'),\n",
              " Document(metadata={'resume_id': 'Anshuman_Resume_Final 3 - ANSHUMAN AWASTHI', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Anshuman Awasthi MTech(Computer Science) Indian Institute of Information Technology Lucknow\\n\\nMob: +91 7068311271\\n\\nEmail: mcs23026@iiitl.ac.in\\n\\n| Degree                                | University/Board                      | CGPA/%/   |\\n|---------------------------------------|---------------------------------------|-----------|\\n| MTech (Computer Science)              | IIIT Lucknow                          | Pursuing  |\\n| BE (Computer Science and Engineering) | Visvesvaraya Technological University | 6.92      |\\n| Intermediate/+2                       | CBSE                                  | 77.6      |\\n| High School                           | CBSE                                  | 9         |'),\n",
              " Document(metadata={'resume_id': 'Anshuman_Resume_Final 3 - ANSHUMAN AWASTHI', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SCHOLASTIC ACHIEVEMENTS\\n\\n| • Secured AIR 79 in JEST (Theoretical Computer Science)             | [2023]   |\\n|---------------------------------------------------------------------|----------|\\n| • Secured AIR 5322 in GATE (Data Science &Artificial Intelligence ) | [2024]   |'),\n",
              " Document(metadata={'resume_id': 'Anshuman_Resume_Final 3 - ANSHUMAN AWASTHI', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## SKILLS &amp; COMPETENCIES\\n\\n- Programming Languages : Python, C, SQL\\n- Tools &amp; Libraries : NumPy, Pandas, Matplotlib, sns, Tensorflow, Keras, Scikit Learn, NLTK, LATEX\\n- Mathematics : Linear Algebra, Probability, Statistics\\n- Miscellaneous : XHTML, CSS, JavaScript, Git, Linux, Generative AI.\\n\\n## RELEVANT COURSES\\n\\n- Advanced Algorithms | Data Mining &amp; Warehousing | Natural Language Processing | Soft Computing | Optimization Techniques [IIITL]\\n- Deep Learning Specialization | NLP Specialization | Tensorflow Developer | MLOps Specialization\\n\\nPROJECTS\\n\\n[Coursera]\\n\\n[Feb'24]\\n\\n[Jul'2024]\\n\\n- Saaransh The Summarizer | Link\\n- Summarizes based on a list of keywords.\\n- URLsummarizer| Link\\n- Summarizes any web page(preferably text dominant)given input URL.\\n- Textbook Content Extraction and RAG System | Link\\n- A Retrieval Augmented Generation (RAG) system for answering questions based on the retrieved content from Textbooks.\\n- Others\\n- Classification( Multiclass classification using Decision Tree and KNN)\\n- Sentiment Analysis\\n- Teaching Assistant | IIIT Lucknow\\n- Responsible for creating questions, correcting answer sheets.\\n\\n- Data Science Intern : TS Foundation\\n\\n- Machine Learning Engineer : Omdena\\n\\n## LINKS\\n\\n## EXTRACURRICULAR ACTIVITIES\\n\\n- GitHub\\n- LinkedIn\\n- Kaggle\\n- Leetcode\\n- Hackathons\\n- Startup: Seeking investment to advance development and market entry.\\n- Blitz: If you've got 5 minutes.\\n\\n## INTERNSHIPS\\n\\n## POSITIONS OF RESPONSIBILITY\\n\\n[Aug'23-Jun'24]\"),\n",
              " Document(metadata={'resume_id': 'My Curriculum Vitae - Pro - Walid Chazbek', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"- Baadaran - Al Chouf, Lebanon\\n- (+961) - 81/645 910\\n- chzbk31002wld@outlook.com\\n- \\\\_Completed the system fundamentals course at the University (system components &amp; Wi-Fi components).\\n- \\\\_Completed the Intro to Computing course at the University (Python and Binary languages).\\n- \\\\_Completed the Programming I course at the University (mainly C++ language).\\n- \\\\_Took and completed the Programming I's LAB at the University.\\n- \\\\_I had worked, me and my classmates, on a project in the University about casino games; it included C++ language and a PowerPoint presentation that came with a Word document work copy.\\n- \\\\_Self-taught front-end web development on You-tube platform (still in progress).\\n- \\\\_Cooking skills (I have a passion in cooking and making desserts from scratch. Furthermore, I am planning on selling my own prepared Goods and working on creating my own brand).\\n- \\\\_I am a diligent and detail-driven individual; I focus on flaws and rectify them in purpose of delivering the best version of my work.\"),\n",
              " Document(metadata={'resume_id': 'My Curriculum Vitae - Pro - Walid Chazbek', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Work experience:\\n\\n- \\\\_We instituted a committee in our village in the purpose of attracting a great number of tourists; I was qualified as one of the most active and persistent member of that committee.\\n- \\\\_Experience in customer service and hospitality.\\n- \\\\_Worked at a computer store (selling laptops and other electronics).'),\n",
              " Document(metadata={'resume_id': 'My Curriculum Vitae - Pro - Walid Chazbek', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education:\\n\\n- \\\\_First school I had been registered in: CSF (College Saint François des Pères Capuçins) \\\\_ Hamra.\\n- \\\\_Second school I had been registered in: La Charité Saint Vincent \\\\_ Clemenceau.\\n- \\\\_Graduated from school in 2019.\\n- \\\\_Computer Science student.\\n- \\\\_Enrolled at AUST-Ashrafieh, Beirut, Lebanon (Sophomore year).'),\n",
              " Document(metadata={'resume_id': 'My Curriculum Vitae - Pro - Walid Chazbek', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Computer skills:\\n\\n- \\\\_Write simple C++/Python programs as I had been taught at the University.\\n- \\\\_Have knowledge in System Fundamentals and how does a computer work (components).\\n- \\\\_Knowledge in Computer Networking (Wi-Fi installation and configuration).\\n- \\\\_Knowledge in Artificial Intelligence field (Generative AI and others).\\n\\n## Languages:\\n\\nArabic (Native), English (Proficient), French (Intermediate), Spanish (Beginner).\\n\\n## Interests and hobbies:\\n\\nArtificial intelligence (Internships), selling and repairing electronic devices (laptops, PCs, phones…), Books and articles, Technology creations and updates, Soccer, Basketball, Fitness and Bodybuilding, Swimming, Hiking, cooking &amp; dessert.\\n\\n## References:\\n\\nMy brother, +(961)-3/212 231, tarekchazbek@gmail.com.'),\n",
              " Document(metadata={'resume_id': 'Ankit Patil Resume - Ankit Patil', 'chunk_id': 1, 'gpa_value': 8.58, 'gpa_scale': 10.0, 'gpa_normalized': 8.58, 'gpa_found': True}, page_content='## Education\\n\\n\\n\\n\\n\\nMaharashtra Institute of Technology, Chh.  Sambhajinagar, India Bachelor of Technology in Artificial Intelligence and Data Science\\n\\nJan  2021 - Jul  2025 CGPA:  8.58/10\\n\\nMaharashtra Institute of Technology, Chh.  Sambhajinagar, India\\n\\nJan  2021 - Jul  2025\\n\\nHonours in Cloud Computing\\n\\nUdacity\\n\\nOct 2024\\n\\nNanodegree in AI Programming with Python'),\n",
              " Document(metadata={'resume_id': 'Ankit Patil Resume - Ankit Patil', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Technical Skills\\n\\nProgramming Languages:\\n\\nPython, R, SQL\\n\\nData Analysis &amp; Wrangling: Data Cleaning, Manipulation, and Visualization with Python, Exploratory Data\\n\\nAnalysis (EDA)\\n\\nMachine Learning:\\n\\nRegression, Classification, Clustering, Decision Trees, Random Forest, NLP\\n\\nTools &amp; Platforms:\\n\\nMicrosoft Azure, Jupyter Notebook, Excel, Power BI, GitHub, Scrapy, Beautiful Soup\\n\\nDatabase Management:\\n\\nMySQL, NoSQL\\n\\nLibraries/Frameworks\\n\\n: TensorFlow, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn'),\n",
              " Document(metadata={'resume_id': 'Ankit Patil Resume - Ankit Patil', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Experience\\n\\nSwiggy                                                                                                                                                    Feb 2024\\n\\n## Campus Ambassador\\n\\n- May 2024\\n\\nRemote\\n\\n- As a Campus Ambassador for Swiggy, I promoted Swiggy's services on campus, engaged with students through events and social media, and helped drive brand awareness and customer engagement.\\n- I acted as a mediator between Swiggy and the student community, contributing to marketing initiatives.\\n\\n## Findability Sciences                                                                                                                                      Apr 2024\\n\\n## Data Scientist Intern\\n\\n-May 2024\\n\\nOnsite\\n\\n- As a Data Scientist Intern at Findability Sciences, I contributed to data analysis projects, utilizing machine learning techniques to extract insights from large datasets.\\n- I worked on building predictive models, data preprocessing, and visualization to support business decision-making.\\n\\n## GDSC MITA\\n\\n## AI/ML Lead\\n\\nJul 2024 - Jul 2024\\n\\nOnsite\\n\\n- As the AI/ML Lead at Google Developer Student Club (DSC) MITA, I led AI and machine learning initiatives, mentoring a team of students in developing innovative solutions. I organized workshops and technical sessions on AI/ML topics, fostering a community of learners.\\n- Developed practical skills in using Cloud and Power Platform tools.\"),\n",
              " Document(metadata={'resume_id': 'Ankit Patil Resume - Ankit Patil', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Projects\\n\\n## AIHireHub: AI Driven Recruitment Platform\\n\\n- AI-driven platform using LLMs and NLP to automate job matching, reducing time-to-hire and minimizing hiring biases.\\n- Implemented data cleaning, keyword extraction, and matching algorithms to improve recommendation accuracy.\\n\\n## Stock Price Prediction and Forecasting Using Stacked Deep Learning\\n\\n- Developed a machine learning model to predict future stock prices by analyzing historical market data and identifying trends to assist in making informed investment decisions.\\n\\n## Product Search Engine and Recommendation System\\n\\n- Developed a search engine utilizing natural language processing techniques to enable product search in the Amazon Product Dataset by calculating cosine similarity between user queries and product information.\\n\\n## LexifyAI -AI-Powered Legal Assistant\\n\\n- Developed an AI chatbot to assist users in understanding legal queries based on recent changes in Indian law (IPC to BNS).\\n- Integrated natural language processing (NLP) models for real-time, informative responses.\\n\\n## Certifications\\n\\nMicrosoft Certified:\\n\\nAzure AI Engineer Associate (AI-102)\\n\\nMicrosoft Certified:\\n\\nAzure AI Fundamentals (AI-900)\\n\\nMicrosoft Certified:\\n\\nAzure Fundamentals (AZ-900)\\n\\nOracle Cloud Infrastructure:\\n\\nGenerative Al Certified Professional (1Z0-1127-24)\\n\\nIBM:\\n\\nData Science Certified\\n\\nRedhat Certified:\\n\\nRedhat Certified System Administrator (RHCSA)\\n\\nNPTEL Certified:\\n\\nData Analytics with Python\\n\\nDatacamp Certified:\\n\\nData Analyst in Power BI'),\n",
              " Document(metadata={'resume_id': 'Ankit Patil Resume - Ankit Patil', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Achievements &amp; Extracurriculars\\n\\n- AWS AI/ML Scholar\\n- Maths Wiz Award\\n\\n## Key Strengths\\n\\nStrong  problem-solving and analytical skills.\\n\\nExcellent communication and collaboration skills with experience working in global teams.\\n\\nAdaptive learner, initiative-taking, and adaptable to recent technologies.'),\n",
              " Document(metadata={'resume_id': 'Ankit Patil Resume - Ankit Patil', 'chunk_id': 6, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Values and Soft Skills\\n\\nCuriosity &amp; Innovation:\\n\\nEnthusiastic about pioneering the future with innovative technologies.\\n\\nIntegrity  &amp;  Sincerity:\\n\\nCommitted to ethical and responsible conduct in all tasks.\\n\\nTeamwork &amp; Diversity: Believe in collaboration and value diverse viewpoints to create impactful solutions.'),\n",
              " Document(metadata={'resume_id': 'Resume_Soham_Y - Soham Yedgaonkar', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='- •\\n- github.com/sohamyedgaonkar · linkedin.com/in/soham-yedgaonkar · sohamyedgaonkar@gmail.com\\n\\nProfessional Description\\n\\nAn innovation-focused tech enthusiast with experience in developing and maintaining software systems and solving problems related to various computer science domains.\\n\\nSeeking opportunities as a Software Engineering Intern, Machine Learning Intern, or Data Science Intern.'),\n",
              " Document(metadata={'resume_id': 'Resume_Soham_Y - Soham Yedgaonkar', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education\\n\\n## Pune Institute of Computer Technology\\n\\n2022-2026\\n\\nB.E. Information Technology\\n\\nCurrent SGPA: 9.05\\n\\nCourses: Object-Oriented Programming, Data Structures &amp; Algorithms, Calculus, Database Management, Storage Solutions, Computer Networks, Software Engineering'),\n",
              " Document(metadata={'resume_id': 'Resume_Soham_Y - Soham Yedgaonkar', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Skills and Competencies\\n\\nTechnologies: Software Development, Data Science, Machine Learning, Artificial Intelligence, Data Analytics, MLOps, CI/CD\\n\\nLanguages: Python (proficient), C/C++, Java, Bash, JavaScript, HTML/CSS, MySQL\\n\\nTools: Git/GitHub, Hugging Face, VS Code, LangChain, Jupyter Notebook, SQL, Linux, Docker, Kubernetes\\n\\nLibraries:\\n\\nNumpy, PyTorch, Transformers, Scikit-learn, Pandas, Flask, Keras, Matplotlib'),\n",
              " Document(metadata={'resume_id': 'Resume_Soham_Y - Soham Yedgaonkar', 'chunk_id': 3, 'gpa_value': 35.0, 'gpa_scale': 100.0, 'gpa_normalized': 3.5, 'gpa_found': True}, page_content='## Professional Experience\\n\\n## Research and Development Intern at CDAC\\n\\nJuly 2024 - Present\\n\\n- Engineered and fine-tuned computer vision models by experimenting with over 7 diverse architectures, achieving a 35% increase in object detection accuracy\\n- Collected and processed a dataset of 50,000 real-life images, leading to a improvement in model precision for drone-based object classification\\n- Collaborating with a team of CDAC scientists to deliver end-to-end solutions, reducing model deployment time by 30%\\n- Integrated highly scalable object detection models with drones, achieving 95% accuracy in real-time classification during field tests'),\n",
              " Document(metadata={'resume_id': 'Resume_Soham_Y - Soham Yedgaonkar', 'chunk_id': 4, 'gpa_value': 99.6, 'gpa_scale': 100.0, 'gpa_normalized': 9.96, 'gpa_found': True}, page_content=\"## Projects\\n\\n## Gest Do It Deep Learning, Machine Learning, Scikit-learn, Computer Vision, Flutter, Algorithms, Jupyter Notebook Jan-Mar.\\n\\n2024\\n\\n- Led a team of 5 for the Impetus Innovation competition.\\n- Developed an OS-independent Desktop app to ease dataset Human-Computer Interaction using Hand gesture recognition, achieving 99.6% accuracy with a dataset of 20,000 samples.\\n- Developed and deployed Random Forest, K-means, and DNN models to analyze user behavior, leading to an 80% increase in predictive accuracy and reducing scrap prediction by 90%.\\n\\n## Market-Pulse - Stock Trends Prediction using LLMs Python, Flask, Web Scraping, NLP\\n\\n- Engineered an innovative tool to evaluate stock market trends prediction just from a news URL.\\n- Aggregated structured data from 20+ sources to build the dataset.\\n- Integrated and hosted fine-tuned financial LLMs with Flask, along with a webpage built with HTML, CSS, and JavaScript, ensuring constant software troubleshooting.\\n\\n## Automatic License Plate Detection using YOLOv8 Object Detection, Computer Vision, EasyOCR May-Jun. 2024\\n\\n- Designed and implemented a system using YOLOv8 and EasyOCR for detecting and reading license plates in real-time.\\n- Achieved an accuracy of 98.5% in detecting and recognizing license plates from images and video streams.\\n- Optimized the model's performance to run on embedded systems like Raspberry Pi, ensuring efficiency and scalability.\\n\\n## Certifications\\n\\n## Intermediate Machine Learning Kaggle\\n\\nApr. 2023\\n\\n- Gained proficiency in machine learning concepts and tools, including handling missing data, feature engineering, and model validation.\\n\\n## Stanford's Machine Learning Specialization Coursera\\n\\nJan-Apr. 2023\\n\\n- Completed courses on Supervised and Unsupervised Learning, and achieved expertise in regression, classification, clustering, and reinforcement learning.\"),\n",
              " Document(metadata={'resume_id': 'Resume_Soham_Y - Soham Yedgaonkar', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Achievements\\n\\nTop Machine Learning Voice on LinkedIn\\n\\nJun-Jul. 2024\\n\\n## Soham Yedgaonkar\\n\\n2024\\n\\n2024'),\n",
              " Document(metadata={'resume_id': 'Resume Mollika - Mollika Garg', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## EDUCATION\\n\\n## Birla Institute of Technology Mesra\\n\\nIntegrated Msc Mathematics and Computing ( 5 Yrs)'),\n",
              " Document(metadata={'resume_id': 'Resume Mollika - Mollika Garg', 'chunk_id': 2, 'gpa_value': 98.0, 'gpa_scale': 100.0, 'gpa_normalized': 9.8, 'gpa_found': True}, page_content=\"## WORKEXPERIENCE\\n\\n## Microsoft\\n\\nSoftware Engineering Intern (AI Phone Team)\\n\\n- Developed an Android application using Kotlin that continuously monitors the user's screen, capturing screenshots and applying Azure OCR to extract text every 5 seconds with 98 %accuracy.\\n- Utilized LLM to categorize extracted text and timestamps into work, communication, and entertainment categories, storing actionable moments in Room DB to allow users to filter, add, and manage events.\\n\\n## Business Next\\n\\nMachine Learning Intern\\n\\n- Worked on a deep learning-based NLP approach for automatic speaker diarization using state-ofthe-art techniques, with the goal of enhancing speech analysis in scenarios involving multiple speakers by accurately segmenting and identifying individual speakers in the audio recordings.\\n\\n## Neel Blue Technologies\\n\\nMachine Learning Intern\\n\\n- Developed a computer vision system using Flask to automatically detect UPS logos on trucks, enabling efficient tracking and identification of UPS vehicles for improved delivery management.\\n- Implemented deep learning techniques such as YOLO and CNN to achieve an accuracy of 95 %.\"),\n",
              " Document(metadata={'resume_id': 'Resume Mollika - Mollika Garg', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## TECHNICAL SKILLS\\n\\nProgramming Languages:\\n\\nPython, C++, C, Javascript, Kotlin, Java, bash\\n\\nFrameworks and Databases:\\n\\nAndroid Apps, Node.js, Django, Flask, MySQL\\n\\nAI / ML Architectures:\\n\\nComputer Vision (CNN, YOLO), GenAI (LLMs), NLP (Transformers)'),\n",
              " Document(metadata={'resume_id': 'Resume Mollika - Mollika Garg', 'chunk_id': 4, 'gpa_value': 1.0, 'gpa_scale': 4.0, 'gpa_normalized': 2.5, 'gpa_found': True}, page_content='## SELECTED PROJECTS\\n\\n## Urban Water Logging Detection for Timely Intervention and Mitigation\\n\\nCODE\\n\\n- Developed a computer vision system using OpenCV to classify water-logged areas and non-waterlogged areas in streets using input image from street camera and a danger level is predicted from a score ranging from 0 to 1 . Implemented SVM and Random Forest along with feature extraction from image to achieve an accuracy of 85 . 1 %on validation data.\\n\\n## Tackling Dengue Cases in India: ML-based Approach for Early Detection and Prevention CODE\\n\\n- Developed a website that predicts dengue cases based on climate factors using KNN and SVM, and utilized QGIS to extract Sentinel-2 satellite images for detecting stagnant water areas, applying image processing techniques and Mapbox to display hotspots and suggest safer routes.'),\n",
              " Document(metadata={'resume_id': 'Resume Mollika - Mollika Garg', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## ACHIEVEMENTS\\n\\n- Top 5 Finalist for building Tackling Dengue cases project in IEEE Mega Project.\\n- Special Mention for building Urban Water-Logging Detection project in Tech-A-Thon.\\n\\n## POSITION OF RESPONSIBILITY\\n\\nVice President: Society for Data Science\\n\\nTechnical Head: Geeks for Geeks Club\\n\\nMay'22-July'22\\n\\nMay'23-Aug'23\\n\\n## Mollika Garg\\n\\n\\n\\n] LinkedIn a Github\\n\\nH +91 9810906498\\n\\n8.00/10.0\\n\\nSep'20-Present\\n\\nMay'24-Jul'24\\n\\n2022\\n\\n2021\\n\\nJun'23-May'24\\n\\nOct'22-Jun'24\"),\n",
              " Document(metadata={'resume_id': 'Resume - Prapti Pakkala', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='+91 8971169626\\n\\npraptipakkala@gmail com\\n\\npakkala-3697a624b?u'),\n",
              " Document(metadata={'resume_id': 'Resume - Prapti Pakkala', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## HARD SKILL\\n\\n- Ct+ Programming for Robotics Application\\n- Actively working with ROS-2 Humble\\n- Ardupilot Firmware\\n- Sensor Fusion for autonomous Navigation'),\n",
              " Document(metadata={'resume_id': 'Resume - Prapti Pakkala', 'chunk_id': 2, 'gpa_value': 85.5, 'gpa_scale': 100.0, 'gpa_normalized': 8.55, 'gpa_found': True}, page_content='## SOFT SKILL\\n\\n- Effective Communication\\n- Teamwork\\n- Networking\\n- Problem-Solving\\n\\n## EDUCATIO N\\n\\n- Ramaiah Institute Of Technology\\n\\nBachelor of Engineering BE, Electronics and Communications Engineering 2022-2026\\n\\n- The Indian High School, Dubai\\n\\n12th graduate, PCMB\\n\\nApril 2008 Jun 2022\\n\\nSecured 85.5% in 12th CBSE board examsSecured 93% in 1Oth CBSE board exams.\\n\\n## PRAPTI PAKKALA\\n\\n## Student\\n\\n## PROFILE\\n\\nLam a third-year electronics student with a strong passion for learning and a keen interest in robotics and automation. am particularly drawn to the integration of electronics in autonomous systems, where sensor fusion, control algorithms, and embedded systems come together to enable intelligent robotic behavior . My   background in electronics has provided me with solid foundation in circuit   design, which am eager to extend toward robotics applications, including building and controlling robotic systems. I am open to exploring diverse fields within robotics, electronics and believe in an interdisciplinary approach towards learning anything'),\n",
              " Document(metadata={'resume_id': 'Resume - Prapti Pakkala', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## WORK EXPERIENCE\\n\\n## Edhitha Unmanned Aerial Systems\\n\\nJan 2023 1 months year\\n\\n## Key responsibilities:\\n\\n- Utilized ROS for sensor Integration and real time control of AUV s\\n- Simulated vehicle dynamics using SITL for Ardusub and Ardupilot firmware.\\n- Worked on attaining autonomous navigation of underwater vehicles using MAVROS.\\n- Worked on the research and development of the thrust rig setup.\\n- Implemented Mission Planning and autonomous navigation using Ardupilot firmware.\\n\\n## Schneider Center for Home Automation and Building Automation\\n\\nSeptember 2023 -2 weeks\\n\\n- Trained on the real life application of the Schneider appliances in the home automation and Building Management systems\\\\_\\n- Programming push buttons, multi touch pro switch to control dimmable ,non dimmable lights and blinds using various sensors\\n- Familiarised with the ETS-5 platform and HVAC-BMS system'),\n",
              " Document(metadata={'resume_id': 'Resume - Prapti Pakkala', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## ACHIEVEMENTS\\n\\n- Qualified the round of DIDI Project Design Space, which involved converting a traditional gargoor to a living space for sea turtles. first\\n- Participated in the Singapore AUV Challenge 2024 conducted by IEEE OES held in Singapore and got an overall rank of 18 among 21 qualified teams and 7th fastest among 75 teams all over the world\\n- Participated in a workshop on building firefighting robots-IEEE RITB\\n- Attended a workshop on PCB design; circuit simulation and familiarised with proteus software-IEEE RITB\\n- Was awarded the prestigious sheikh Hamdan award for Academic Excellence'),\n",
              " Document(metadata={'resume_id': 'Resume.PunithHM - Punith H M', 'chunk_id': 0, 'gpa_value': 20.0, 'gpa_scale': 100.0, 'gpa_normalized': 2.0, 'gpa_found': True}, page_content=\"Programming on Python , Udemy\\n\\n## Zetatek Technologies Pvt Ltd, India\\n\\n## Intern , Bengaluru\\n\\n- During my Software development Internship, I played a key role in developing robust C-based client-server applications for efficient data transfer. I contributed significantly to the integration of MariaDB into the server-side architecture, enhancing database reliability. Utilizing the Msys2 tool(gcc compiler) for the development of code, I ensured the smooth integration of database functionality. The completion of the internship demonstrated my dedication, adaptability, and proficiency in TCP/IP, UDP, and MariaDB integration.\\n\\n## PUNITH H M\\n\\n+919743297568 • punithpuni020202@gmail.com • Gokula 1st Stage, Mathikere, Bangalore, Karnataka, 560054, India\\n\\n• DOB: 02/02/2002 • LinkedIn\\n\\nElectronics and Telecommunication Engineering graduate with hands-on experience in IoT , AI , and software development We developed a smart hydroponic system for real-time monitoring using ESP32 and Python , enhancing urban farming efficiency by 20%. Contributed to the integration of MariaDB and built C-based client-server applications during an internship at Zetatek Technologies Pvt Ltd, improving database reliability and data transfer speed by 15%. Proficient in Python , Arduino IDE , GIT, Linux, and machine learning , with a strong focus on automation and innovative solutions.\\n\\n## Core Competencies\\n\\nProgramming Languages:\\n\\nPython, C#\\n\\nWeb Development:\\n\\nHTML, CSS\\n\\nVersion Control:\\n\\nGIT\\n\\nOperating Systems:\\n\\nLinux\\n\\nDevelopment Tools/IDE's:\\n\\nVisual Studio, Jupyter Notebook, Arduino IDE\\n\\nFrameworks:\\n\\n.NET\"),\n",
              " Document(metadata={'resume_id': 'Resume.PunithHM - Punith H M', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education\\n\\nM S Ramaiah Institute Of Technology:\\n\\nBE in Electronics And Telecommunication Engineering,\\n\\n(CGPA-7.17), Dec 2021 - May 2024\\n\\nSiddaganga Polytechnic:\\n\\nDiploma in Electronics and Communication Engineering,\\n\\n(Percentage - 78.23), Jul 2018 - Oct 2021'),\n",
              " Document(metadata={'resume_id': 'Resume.PunithHM - Punith H M', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Projects\\n\\n## Dynamic Nutrient Microdosing System for Precision Hydroponics:\\n\\n.\\n\\nJan 2024 - May 2024\\n\\n- Innovative IoT-Enhanced Hydroponics: Developed an advanced hydroponic system using ESP32 and Blynk for real-time remote monitoring of water, temperature, and pH levels, enhancing urban farming efficiency.\\n- Smart Agriculture Solutions: Implemented IoT technology for seamless data transmission and remote management, enabling users to efficiently oversee hydroponic setups from any location, improving urban space utilization.\\n- AI-Driven Plant Health Monitoring: Created a CNN model and a web application using Python and Flask for detecting tomato leaf deficiencies, allowing users to upload images and receive automated diagnostics to ensure optimal plant health in hydroponic systems.\\n\\nSkills: Arduino IDE, Python, C program, Machine Learning, IoT\\n\\n## Automatic pH Controller:\\n\\n- Designed and Developed an Automatic pH Controller using Nodemcu ESP8266.\\n- Maintains the desired pH value of the solution and displays real-time pH values in IoT Application.\\n\\n## Certifications'),\n",
              " Document(metadata={'resume_id': 'Resume.PunithHM - Punith H M', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Professional Experience\\n\\nJan 2023 - Apr 2023\\n\\nJun 2023\\n\\nFeb 2024 - Mar 2024'),\n",
              " Document(metadata={'resume_id': 'Aziz Bayu Pratama - Curriculum Vitae - 4IA04_Aziz Bayu Pratama', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## AZIZ BAYU PRATAMA\\n\\nazizbayupratama46@gmail.com | +6281290848269 | linkedin.com/in/aziz-bayu-pratama | https://github.com/azizbp\\n\\n## PROFILE\\n\\nI am an Informatics Students with strong foundation in Data Science and Machine Learning. I have  a  deep  interest  at  Machine  Learning  and  AI  development.  During  my  daily  life  as college student,  I had joined HIMTI Gunadarma as Staff of Social Society Division, I had been  involved  at  Exchange  Student  Kampus  Merdeka  Bela  Negara  with  Data  Science Profession Learning Path, I had hands-on experience as Computer Vision Internship during 3 months at Kecilin, and I also a proud alumnus of Bangkit Academy Batch 1 2024.'),\n",
              " Document(metadata={'resume_id': 'Aziz Bayu Pratama - Curriculum Vitae - 4IA04_Aziz Bayu Pratama', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## EDUCATION\\n\\n## Bachelor of Informatics Engineering, Gunadarma University\\n\\n- •\\n\\n- GPA : 3.84\\n- Relevant Courework : Introduction to Artificial Intelligence, Artificial Intelligence Technology, Big Data Computing, Lepkom Courses (Oracle SQL, Microsoft SQL Server).'),\n",
              " Document(metadata={'resume_id': 'Aziz Bayu Pratama - Curriculum Vitae - 4IA04_Aziz Bayu Pratama', 'chunk_id': 2, 'gpa_value': 91.0, 'gpa_scale': 100.0, 'gpa_normalized': 9.1, 'gpa_found': True}, page_content='## EXPERIENCES\\n\\n## Staff of Social Society, HIMTI Gunadarma\\n\\n- Organizing service activities from students to the social community\\n- Fundraising coordinator for Teknik Informatika Mengabdi 4.0\\n- Volunteer for Teknik Informatika Mengabdi 4.0\\n\\n## Computer Vision Engineer Intern, KECILIN\\n\\nJul 2023 - Okt 2023\\n\\n- Prepare and create dataset for training Yolo using labelimg for project like vehicle detection, OCR plate number, and personal protective equipment\\n- Making model for car color detection with CNN scratch Tensorflow with 91% accuracy and 90% validation\\n- Make an API with FastAPI for sending vehicle capture, to process OCR detection\\n- Do research for increasing FPS Yolo inference in Raspberry and Jetson, increase the FPS for 20%\\n\\n## Bangkit Academy 2024 Machine Learning Cohort\\n\\nFeb 2024 - Jul 2024\\n\\n- Do self-paced learned with Coursera about Image Processing and Classification, Natural Language Processing, Sequences, Time Series, and Prediction, Generative AI, Tensorflow.js, Tensorflow Lite, etc\\n- Working together with 7 members in a team to make final project Android Apps that can help parents to recognize their child emotion and the symptoms of autism immediately\\n- In my team, I build the computer vision model for autism recognition with MobileNetV2 and TF Lite, reach 87% accuracy and 81% validation\\n- Communicate actively, give advice during team discussion along final capstone project'),\n",
              " Document(metadata={'resume_id': 'Aziz Bayu Pratama - Curriculum Vitae - 4IA04_Aziz Bayu Pratama', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Hard Skill\\n\\n- Machine Learning : Scikit-Learn, Pandas, Numpy, Seaborn, Matplotlib\\n\\n- Computer Vision : YoloV8, Roboflow, Tensorflow, MobileNetV2'),\n",
              " Document(metadata={'resume_id': 'Aziz Bayu Pratama - Curriculum Vitae - 4IA04_Aziz Bayu Pratama', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Soft Skill\\n\\n- Teamwork\\n- Time Management\\n- Communication\\n- Analytical Skills\\n\\n2021 - Present\\n\\nNov 2022 - Jul 2023'),\n",
              " Document(metadata={'resume_id': 'Harshit_Resume_one (1) - HARSHIT SRIVASTAVA', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Harshit Srivastava\\n\\nLucknow, 226017 (IN) | 9170997725 |  sriharshit2004@gmail.com\\n\\nLinkedIn  Github'),\n",
              " Document(metadata={'resume_id': 'Harshit_Resume_one (1) - HARSHIT SRIVASTAVA', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Professional Summary\\n\\nI am a Software Development Engineer (SDE) in training, currently pursuing my engineering degree. I have experience in Java, Python , and web development . My strengths include data structures and algorithms , IoT systems for temperature-sensitive monitoring , and data analysis . I am eager to expand my knowledge in AI/ML and apply best practices to create efficient, scalable solutions. Currently seeking opportunities to further my career in software engineering.'),\n",
              " Document(metadata={'resume_id': 'Harshit_Resume_one (1) - HARSHIT SRIVASTAVA', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Experience\\n\\n## Data Acquisition Engineer - Intern, Radio Design India.\\n\\n- Developed IoT solutions using Raspberry Pi and Python for real-time temperature data collection.\\n- Automated temperature data collection at 20-second intervals using Python scripts executed through Git Bash.\\n- Supported the integration of sensor data into a database for storage and future analysis.\\n- Monitored and maintained temperature-sensitive systems, ensuring accurate data collection and product safety.'),\n",
              " Document(metadata={'resume_id': 'Harshit_Resume_one (1) - HARSHIT SRIVASTAVA', 'chunk_id': 3, 'gpa_value': 99.9, 'gpa_scale': 100.0, 'gpa_normalized': 9.99, 'gpa_found': True}, page_content='## Project:  Voting Application backend\\n\\n- Developed a robust Voting Application backend using Node.js, Express.js, and MongoDB\\n- Built an API with 10 RESTful endpoints for managing polls and votes\\n- Wrote over 1,200 lines of code to ensure functionality and performance\\n- Achieved 99.9% uptime during the testing phase'),\n",
              " Document(metadata={'resume_id': 'Harshit_Resume_one (1) - HARSHIT SRIVASTAVA', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education\\n\\nNoida Institute of Engineering and Technology,  Bachelor of Technology St. Marys School, Isc\\n\\n11/2021 - 07/2025\\n\\n2021'),\n",
              " Document(metadata={'resume_id': 'Harshit_Resume_one (1) - HARSHIT SRIVASTAVA', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Skills\\n\\nNode.js | Express.js | Django | JavaScript | Python | MySQL | Data analysis | Machine Learning'),\n",
              " Document(metadata={'resume_id': 'ATS_Resume_Dev - Dev Bhanushali', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Dev Bhanushali\\n\\n+91-7337647505 | dev.bhanushali.btech2022@sitpune.edu.in | Pune, Maharashtra - 411021 LinkedIn | GitHub | Google Play Store'),\n",
              " Document(metadata={'resume_id': 'ATS_Resume_Dev - Dev Bhanushali', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SUMMARY\\n\\n- AI student passionate in the field of Software Development and applied AI research with hands-on experience in app development, predictive maintenance and Gen AI.\\n- My international academic exposure and academic conference participation have honed my skills in communication and diverse AI projects.\\n- Experienced in developing fully functional software apps, novel features for predictive maintenance, applying advanced deep learning techniques, and achieving high accuracy in real-world applications.'),\n",
              " Document(metadata={'resume_id': 'ATS_Resume_Dev - Dev Bhanushali', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Past Experience\\n\\n## App Developer Intern - SCMIA (Symbiosis Centre for Medical Image Analysis)\\n\\nJuly 2023 - September 2023\\n\\n- Built an EPROM (Electronic patient reported outcome measure) web app using the Flutter Framework and Python Rest API Backend.\\n- The web app consists of a login dashboard with a dynamic questionnaire generated from data fetched from a remote database.\\n- The responses are then saved in a separate table for a specific user.'),\n",
              " Document(metadata={'resume_id': 'ATS_Resume_Dev - Dev Bhanushali', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## PROJECTS\\n\\n## GDSC SIT Pune App\\n\\nGithub (Server) | Github (Android App)\\n\\n- App for the GDSC Club at Symbiosis Institute of Technology that updates members about upcoming events and shows the latest tech news.\\n- User Interface developed using the Flutter, Backend server developed using NodeJs, Firebase as the Database Solution.\\n- Collaborated with Dr. Harsh Dhiman on a ball bearing predictive maintenance project.\\n- Developed and applied a novel feature for predicting wind turbine faults using Suzlon windmill timeseries data.\\n- Co-authored and presented the research paper \"Enhancing Wind Turbine Reliability through Proactive High Speed Bearing Prognosis Based on Adaptive Threshold and Gated Recurrent Unit Networks\" at the Flagship Conference, IECON 2023 - 49th Annual Conference of the IEEE Industrial Electronics Society at the Marina Bay Convention Centre, Singapore.\\n\\nBearing Prognosis using Gated Recurrent Unit Networks            April 2023 - October 2023'),\n",
              " Document(metadata={'resume_id': 'ATS_Resume_Dev - Dev Bhanushali', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Research Publication\\n\\nOctober 2022 - January 2023\\n\\n## Road Pothole Binary Classification\\n\\n## Github\\n\\n- Worked on a computer vision project for binary classification of road potholes using the novel Bag of Visual Words technique, a method not previously applied to this domain, contributing to potential improvements in road maintenance.\\n- Developed and deployed Machine Learning classification models, resulting in high accuracy and reliable performance.\\n\\n## Bearing Fault Prediction and Generalization using Slope Adaptive Signal Decomposition December 2023 - November 2024\\n\\n- Worked under the supervision of Dr. Pooja Kadam on a ball bearing prognosis project using the Pronostia dataset.\\n- Developed a novel feature extraction method called \"Slope Adaptive Signal Decomposition\" to accurately predict faults in ball bearings.\\n- Analyzed data from 17 ball bearings under three different conditions, demonstrating high prediction accuracy .\\n- Enhanced the generalization capability of recurrent neural networks, enabling models trained on one condition to perform well on other conditions without prior exposure.\\n\\n## Hindi Handwritten Text Synthesis using Generative Methods\\n\\n## Github\\n\\n## July 2024 - November 2024\\n\\n- Worked Independently on a novel Handwritten Text Generation problem for the Hindi language with no papers in this specific domain.\\n- Developed a novel dataset using language primitives from the CALAM dataset, amounting to over 40 Lakh annotated Image samples.\\n- Worked on a generative architecture using PyTorch that can generate images of handwritten text using its digital text annotation with State of The Art results and low computation cost at inference .\\n- Deployed the model using Quart and Flutter for Android and IOS devices.\\n\\n## Portfolio Prediction using Montecarlo Simulation and Antithetic Variates Github July 2024 - November 2024\\n\\n- Worked on a portfolio prediction problem to find the optimal choice of stocks.\\n- Data generation using Monte Carlo simulation and variance reduction using antithetic variates.\\n- Proposed a novel LSTM - GRU hybrid model for future prediction of portfolio given stock allocations resulting decent score metrics.'),\n",
              " Document(metadata={'resume_id': 'ATS_Resume_Dev - Dev Bhanushali', 'chunk_id': 5, 'gpa_value': 90.0, 'gpa_scale': 100.0, 'gpa_normalized': 9.0, 'gpa_found': True}, page_content='## EDUCATION\\n\\n## B.Tech in Artificial Intelligence\\n\\nSymbiosis Institute of Technology (Full Time) Current Average GPA: 8.6\\n\\n## B.Tech in Computer Science and Artificial Intelligence March 2024 - August 2024\\n\\nTechnische Hochschule Ingolstadt (Summer Semester Exchange Student)\\n\\n## High School (CBSE)\\n\\nBGS National Public School, Bangalore\\n\\nClass 10 th  Boards: 90%\\n\\nClass 12 th  Boards: 85%'),\n",
              " Document(metadata={'resume_id': 'ATS_Resume_Dev - Dev Bhanushali', 'chunk_id': 6, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS\\n\\nDeep Learning, Prognostics, Computer Vision, Object Oriented Programming, Design Patterns, Data Structures and Algorithms, Flutter, SQL, Python, Java, JavaScript, C, C#\\n\\n## EXTRACURRICULAR Participation\\n\\n## Mobile App Developer, Janhvi Foundation\\n\\nJune 2024 - November 2024\\n\\n- Developed a mobile app to track employee attendance through daily image and video uploads.\\n- Implemented a backend server for storing attendance data, ensuring efficient and accurate tracking of employee work using Firebase.\\n\\n## Google Developer Students Club - Flutter Lead\\n\\nJune 2022 - June 2024\\n\\n- Lead the Flutter Department under the GDSC Club of SIT for 2 consecutive years.\\n- Developed and locally distributed a working app for the club that can update club members about upcoming events, a separate section for displaying the latest tech news, as well as an account system using a simple custom built dynamic role management system, using the Flutter framework and NodeJS.\\n- Conducted a workshop on flutter basics, covering Basic UI components and an introduction to the BLOC pattern for state management.'),\n",
              " Document(metadata={'resume_id': 'ATS_Resume_Dev - Dev Bhanushali', 'chunk_id': 7, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Hacktopia 2023 - Hackathon Event\\n\\nAugust 2023\\n\\n- Placed in the top 35 teams out of 600 teams overall and top 10 in the healthcare domain out of 40 teams in Hacktopia, a national level hackathon hosted by Guru Nanak Institute of Technology (GNIT).\\n- Developed and deployed a hosted, full stack Machine Learning web application (TensorFlow + Flask + Flutter) which classifies parameters (Name of Pathology Astrocytoma / Glioblastoma, Grade - G2 / G3, IDH Status - Mutant / Wild, MGMT Unmethylated / Methylated, 1p/19q co-deletion status - Codeleted / Non - Codeleted), and segments regions of tumors from an MRI Scan of the human brain (T1, T2 and Flair) with reliable performance and high accuracy.\\n\\n2022 - 2026\\n\\n2018 - 2022'),\n",
              " Document(metadata={'resume_id': 'resume_intern-1 - Akshitha B', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Boreddy Akshitha Reddy\\n\\nEmail:\\n\\nakshithareddyboreddy03@gmail.com\\n\\nPhone:\\n\\n+91 6303255300'),\n",
              " Document(metadata={'resume_id': 'resume_intern-1 - Akshitha B', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education\\n\\n- BTech in Artificial Intelligence and Data Science. CPI: 6.53\\n\\n## Indian Institute of Technology(IIT) Patna\\n\\nPatna, India\\n\\nNovemeber 2022 - May 2026 (Expected)\\n\\n•'),\n",
              " Document(metadata={'resume_id': 'resume_intern-1 - Akshitha B', 'chunk_id': 2, 'gpa_value': 96.0, 'gpa_scale': 100.0, 'gpa_normalized': 9.6, 'gpa_found': True}, page_content='## Sri Chaitanya College of Education\\n\\nHyderabad, India\\n\\nTelangana State Board of Intermediate Education. Percentage: 96 %\\n\\n2019 - 2021\\n\\n•\\n\\n- Dr. KKR Gowtham Schools\\n\\nkushaiguda, India\\n\\nThe Board of Secondary Education, Telangana. Grade: 9.8\\n\\n2018 - 2019'),\n",
              " Document(metadata={'resume_id': 'resume_intern-1 - Akshitha B', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Projects\\n\\n## Dummy Faculty Application website\\n\\n- Language: HTML, CSS, PHP, MySQL\\n\\n## Source Code\\n\\n- Collaborated with a team member to develop a website that simplifies faculty registration and ensures data integrity\\n- Implemented PDF Generation and Email-Linked Password Reset : Designed and developed a feature enabling Users will generate PDFs using the provided data. Integrated a secure password reset functionality linked to the user's email addresses to enhance user experience and account security.\\n\\n## Predicting Stock Price Direction using Support Vector Machines\\n\\n## Language: Python\\n\\n- Developed a predictive model using Support Vector Machines (SVM) to forecast stock price movements based on historical data.\\n- Engineered features including daily returns, moving averages, and lagged values using Python libraries (pandas, NumPy). Applied SVM with a linear kernel using sci-kit-learn to achieve accurate predictions of stock price direction.\\n- Evaluated model performance using metrics like accuracy score and classification reports. Visualized cumulative returns of the strategy compared to market returns using Matplotlib\\n- Notebook link\"),\n",
              " Document(metadata={'resume_id': 'resume_intern-1 - Akshitha B', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Skills\\n\\n- Programming/Development Languages/Tools/Operating Systems: C, C++, Python, SQL, HTML, CSS, JavaScript, MATLAB, NumPy, Pandas, Matplotlib, LATEX, Git, Android Studio, Windows, Linux\\n\\n## Course work\\n\\n- Courses: Artificial Intelligence, Machine learning, Database Management Systems, Data Structures and Algorithms, Computer Architecture, Software lab and tools, MySQL, Statistics, Linear Algebra for data science, Probability Theory and Random process, Microeconomics\\n- Summer Analytics (python, Machine Learning) (Consulting - Analytics Club, IIT Guwahati)\\n\\n## Accomplishments\\n\\n- Secured a position among the top 10,000 out of 155,538 candidates. in JEE Advanced 2022.\\n- Ranked as top 1.9 percentile out of more than 1.02 million candidates in JEE Mains 2022.\\n\\n## Societies/Extra-Curricular Activities\\n\\n- Co-Mentor, Student Mentorship Program, IIT Patna\\n- Correspondent, Forthright, Student Media Collective, IIT Patna\\n\\nSource Code\\n\\n•\\n\\nGitHub:\\n\\ngithub.com/Boreddyakshithareddy3k\\n\\nLinkedIn:\\n\\nlinkedin.com/in/akshitha-reddy-583960256/'),\n",
              " Document(metadata={'resume_id': 'Resume - Nahid Kawsar', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Objective\\n\\nAspiring machine learning engineer with a strong foundation in applied mathematics, specializing in NLP, deep learning, and generative AI. Highly skilled in leveraging machine learning frameworks and data science tools to solve complex problems. Seeking opportunities to apply technical expertise and research-driven insights to innovative AI projects and contribute to impactful solutions.'),\n",
              " Document(metadata={'resume_id': 'Resume - Nahid Kawsar', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education\\n\\n| Noakhali Science and Technology University BSc in Applied Mathematics (Final semester), Current CGPA: 3.63   | Ongoing   |\\n|--------------------------------------------------------------------------------------------------------------|-----------|\\n| Rangpur Government CT College                                                                                |           |\\n| HSC in Science, GPA: 4.58                                                                                    | 2019-2020 |\\n| Nekmorod Alimuddin Govt High School                                                                          |           |\\n| SSC in Science, GPA: 4.91                                                                                    | 2017-2018 |\\n\\n## Certificates\\n\\nEmployability Skills\\n\\n: Wadhwani Foundation - JobReady\\n\\nData Science Foundations :\\n\\nGreat Learning\\n\\nSQL\\n\\n: Introduction to SQL - Simplilearn\\n\\nIntroduction to R\\n\\n: Great Learning\\n\\nExcel for Data Science :\\n\\nGreat Learning\\n\\nPower BI\\n\\n: Analyzing and Visualizing Data - Simplilearn\\n\\nMachine Learning :\\n\\nSimplilearn\\n\\nNeural Networks :\\n\\nGreat Learning\\n\\nGenerative AI\\n\\n: Microsoft - Career Essentials in Generative AI\\n\\nDeep Learning with Keras :\\n\\nSimplilearn\\n\\nAdditional Certifications :\\n\\nFor more certifications, please visit my LinkedIn profile.'),\n",
              " Document(metadata={'resume_id': 'Resume - Nahid Kawsar', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Technical Skills\\n\\nProgramming Languages\\n\\n: Python (primary for ML), R, C/C++, Fortran\\n\\nMathematical Computing\\n\\n: Mathematica (University Course)\\n\\nData Visualization :\\n\\nTableau, Power BI, ggplot2, Seaborn, Matplotlib\\n\\nMachine Learning :\\n\\nscikit-learn, TensorFlow (Keras)\\n\\nDeep Learning\\n\\n: ANN, CNN, RNN, LSTM, Transformers, Attention Mechanism\\n\\nGenerative AI\\n\\n: LLM, Langchain, Huggingface\\n\\nTransfer Learning\\n\\n: VGG16, VGG19, AlexNet, ResNet, EfficientNet, MobileNet\\n\\nOther Tools\\n\\n: Microsoft Excel, Word, PowerPoint, Photoshop\\n\\n## H.M.Nahid Kawsar\\n\\nThakurgaon, Ranisonkail, Bangladesh\\n\\n/mobile-alt\\n\\n+8801737334530\\n\\n/envelope nahidkawsarnhd3@gmail.com · /github nahidkawsar\\n\\n/linkedin-in h-m-nahid-kawsar-232a86266'),\n",
              " Document(metadata={'resume_id': 'Resume - Nahid Kawsar', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Projects\\n\\nMovie Review Analysis - Sentiment Analysis, GitHub: Link\\n\\nNLP project\\n\\nWeb Application for Wine Quality Prediction, GitHub: Link\\n\\n```\\nEnd to end Machine Learning Project\\n```\\n\\nChest X-ray with VGG16 Transfer Learning, GitHub: Link\\n\\nCNN Project\\n\\nData Analytics Dashboard with Power BI, GitHub: Link\\n\\nPower BI project\\n\\nMore Projects\\n\\n:\\n\\nFor additional projects, please visit my GitHub profile at github.com/nahidkawsar.\\n\\n## Volunteering\\n\\n| NSTU Society For The Disabled, Cause: Civil Rights and Social Action   | Joint Secretary         |\\n|------------------------------------------------------------------------|-------------------------|\\n| Chitrokrit, Cause: Arts and Culture                                    | Documentation Secretary |\\n\\n## Languages\\n\\nBangla\\n\\n: Native\\n\\nEnglish :\\n\\nFluent\\n\\nHindi :\\n\\nIntermediate'),\n",
              " Document(metadata={'resume_id': 'Resume - Nahid Kawsar', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Awards\\n\\nScientific Article Writing Competition :\\n\\nCertificate\\n\\nIntroduction to Research Methodology :\\n\\nCertificate\\n\\n## Recommendation\\n\\n'Nahid consistently impresses with the high-quality assignments he completes. His strong work ethic and passion for data science, especially in machine learning and deep learning, are evident. I wholeheartedly recommend H.M. Nahid Kawsar for any opportunities.'\\n\\n- Forhad Mahmud Lecturer, Department of Applied Mathematics, Noakhali Science and Technology University. (Recommendation available on LinkedIn)\\n\\nScopus: Forhad Mahmud on Scopus\"),\n",
              " Document(metadata={'resume_id': 'Aditi Prabakaran Resume  - Aditi Prabakaran', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## ADITI PRABAKARAN\\n\\n+918925828883 | adip.2k5@gmail.com | www.linkedin.com/in/aditi-prabakaran | https://github.com/Aditi2k5'),\n",
              " Document(metadata={'resume_id': 'Aditi Prabakaran Resume  - Aditi Prabakaran', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Summary\\n\\nAspiring Software Engineer with recent experience as a Software Engineering Fellow at Headstarter AI. Enhanced user engagement with an AI chatbot web app and developed web applications using industry-standard tools. Familiar with creating impactful applications that support cross-functional collaboration. Enthusiastic to apply engineering skills in dynamic internship opportunities to drive innovation.'),\n",
              " Document(metadata={'resume_id': 'Aditi Prabakaran Resume  - Aditi Prabakaran', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Education\\n\\n## SRM University\\n\\nComputer Science Engineering\\n\\n- Achievements: GPA: 9.4\\n- Courses: Python, C/C++, Java, DSA'),\n",
              " Document(metadata={'resume_id': 'Aditi Prabakaran Resume  - Aditi Prabakaran', 'chunk_id': 3, 'gpa_value': 85.0, 'gpa_scale': 100.0, 'gpa_normalized': 8.5, 'gpa_found': True}, page_content='## Work Experience\\n\\n## Headstarter AI\\n\\nSWE Fellowship\\n\\nJan 2027\\n\\nRemote\\n\\nSep 2024 - Present\\n\\n- Engineered an AI chatbot web application leveraging React, Firebase, and Material UI for the frontend, integrating the Groq API to provide personalized allergy-free recipes, enhancing user engagement within a collaborative team environment.\\n- Completed an intensive 12-week software engineering fellowship, developing three web applications using Firebase, TypeScript, and ReactJS, and tested out ideas that contributed to enhanced coding proficiency and effectiveness.\\n\\n## Corizo\\n\\nTraining Internship Course\\n\\nRemote\\n\\nJan 2024 - Mar 2024\\n\\n- Developed a basic stock price prediction model using fundamental Machine Learning concepts and Python, demonstrating proficiency in data analysis with libraries such as scikit-learn and pandas, achieving an 85% accuracy rate in predictive performance.'),\n",
              " Document(metadata={'resume_id': 'Aditi Prabakaran Resume  - Aditi Prabakaran', 'chunk_id': 4, 'gpa_value': 40.0, 'gpa_scale': 100.0, 'gpa_normalized': 4.0, 'gpa_found': True}, page_content='## Personal Projects\\n\\nClubHub | Tech stack: Javascript, React, CSS | https://club-hub-srmrmp.vercel.app/\\n\\nOct 2024\\n\\n- Architected and implemented ClubHub,  web application using React.js that streamlines club discovery for university students, increasing campus engagement by centralizing information for student organizations\\n- Engineered a responsive and accessible user interface utilizing React components, React Router, and modern CSS frameworks, resulting in a 40% reduction in time spent searching for club information\\n\\n## EcoMate | Tech Stack: HTML/CSS, Javascript, Groq API | https://github.com/Aditi2k5/ecomate\\n\\nOct 2024\\n\\n- Developed EcoMate, a responsive web application using HTML5/CSS3 that enables users to monitor and optimize their utility consumption, demonstrating front-end development expertise\\n- Implemented interactive data visualization using Chart.js library to create dynamic graphs, allowing users to analyze their monthly energy and water usage trends\\n- Built an intuitive user interface focused on data entry and visualization, resulting in a streamlined user experience for tracking environmental impact'),\n",
              " Document(metadata={'resume_id': 'Aditi Prabakaran Resume  - Aditi Prabakaran', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Skills\\n\\nProgramming Languages:\\n\\nPython, C++, JavaScript\\n\\nWeb Technologies:\\n\\nReact.js, HTML/CSS\\n\\nVersion Control:\\n\\nGitHub\\n\\n## Leadership Position\\n\\nE-Cell, IIT Guwahati                                                                                                                                                  Nov 2024\\n\\nCampus Ambassador\\n\\nIIE Cell, SRM Ramapuram                                                                                                                                        Oct 2024\\n\\nTechnical Team Member'),\n",
              " Document(metadata={'resume_id': 'Atharva Domale Resume - Atharva Domale', 'chunk_id': 1, 'gpa_value': 7.0, 'gpa_scale': 10.0, 'gpa_normalized': 7.0, 'gpa_found': True}, page_content='## Education\\n\\n## Maharashtra Institute of Technology, Chh. Sambhajinagar, India\\n\\nBachelor of Technology in Artificial Intelligence and Data Science\\n\\n\\n\\nJan 2022 - Jul 2025\\n\\nGPA: 7/10\\n\\nCoursework: Data Science, Data Analytics, Machine Learning, Deep Learning and ANN , Statistics, Linear algebra.'),\n",
              " Document(metadata={'resume_id': 'Atharva Domale Resume - Atharva Domale', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Technical Skills\\n\\n- Programming Languages : Python, R, SQL, C\\n- AI/ML Frameworks : TensorFlow, PyTorch, Scikit-learn, Matplotlib, Seaborn, Pandas, NumPy, Matplotlib, Seaborn\\n- Database Management : MySQL, MongoDB\\n- Cloud Platforms : Microsoft Azure, Google Cloud\\n- Documentation &amp; Reporting : MS Excel, Power BI, Google Sheets, MS Word\\n- Familiar With : Flask, FastAPI, Git, Docker, Hugging Face, GPT models, PV Data Management, Automation'),\n",
              " Document(metadata={'resume_id': 'Atharva Domale Resume - Atharva Domale', 'chunk_id': 3, 'gpa_value': 15.0, 'gpa_scale': 100.0, 'gpa_normalized': 1.5, 'gpa_found': True}, page_content='## Experience\\n\\n## KasNet Technologies Pvt. Ltd.\\n\\n## Microsoft and PMI internship\\n\\nJul 2024 - Aug 2024\\n\\nRemote\\n\\n- Assisted in the development and implementation of machine learning models for customer behavior prediction.\\n- Performed data preprocessing and model optimization to improve accuracy by 15%.\\n- Provided technical support, troubleshooting AI-related issues, and conducted model validation tests.'),\n",
              " Document(metadata={'resume_id': 'Atharva Domale Resume - Atharva Domale', 'chunk_id': 4, 'gpa_value': 90.0, 'gpa_scale': 100.0, 'gpa_normalized': 9.0, 'gpa_found': True}, page_content=\"## Projects\\n\\n## Image Classification using Deep Learning | Python, TensorFlow, Keras, MySQL\\n\\n- Developed a deep learning model to classify images from the CIFAR-10 dataset, achieving an accuracy of 90%.\\n- Performed data preprocessing, augmentation, and feature extraction using Conv2D and MaxPooling layers.\\n- Integrated the model with a MySQL database to store and retrieve classified images and results.\\n\\n## Sales Data Analysis for Retail Company | Python, Pandas, SQL, Power BI\\n\\n- Analyzed historical sales data to identify key trends and insights, improving the company's decision-making processes.\\n- Used Python and SQL for data preprocessing and analysis, and visualized insights using Power BI dashboards.\\n- Recommendations based on the analysis led to a 10% increase in sales by optimizing inventory management.\\n\\n## Predictive Analytics for Customer Churn | Python, Scikit-learn, Matplotlib\\n\\n- Built a predictive model using logistic regression to analyze customer churn based on historical data.\\n- Preprocessed customer data using Pandas and visualized results with Matplotlib, improving retention strategies.\\n- The model helped the client identify at-risk customers, leading to a 20% reduction in churn rates.\\n\\n## Certifications\\n\\n- Microsoft Certified: Azure AI Engineer Associate\\n- Oracle Cloud Infrastructure 2024: Generative Al Certified Professional\\n- Microsoft Certified: Azure AI Fundamentals\\n- Microsoft Certified: Azure Fundamentals\\n\\n## Key Strengths\\n\\n- Strong understanding of Generative AI technologies and their real-world applications.\\n- Proficient in data analysis and model optimization to improve process efficiency.\\n- Excellent collaboration and communication skills, working effectively with cross-functional teams.\\n- Strong documentation and reporting abilities, with a focus on PV case processing and regulatory compliance.\\n- Committed to continuous learning and staying up-to-date with AI advancements.\"),\n",
              " Document(metadata={'resume_id': '(Shivam Dubey)-Resume - Shivam Shailendra Dubey', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Shivam Shailendra Dubey ~ Frontend Developer ~ \\uf028 : +919860939549                                                                              At Future18 Digital\\n\\n\\n\\n\\uf02a\\n\\n\\uf048\\n\\n: Malad, Maharashtra\\n\\nLinkedIn\\n\\n: Shivam Shailendra Dubey\\n\\n: shivamdubey72080@gmail.com'),\n",
              " Document(metadata={'resume_id': '(Shivam Dubey)-Resume - Shivam Shailendra Dubey', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## PROFILE SUMMARY\\n\\nTo work in a professionally managed organization, and to be part of a mutually beneficial system, where in I can contribute to the growth and can find ample opportunities for learning and self-development. Frontend Developer with experience in building userfriendly and visually appealing interfaces. Skilled in HTML5, CSS3, JavaScript, and Bootstrap, with a strong ability to translate design mockups and wireframes into responsive web pages. Proven track record of collaborating closely with design teams and implementing modern web development best practices to optimize website performance and enhance user experience. Notable projects include developing the front-end for Future18 Digital.\\n\\n## ACADEMIC CREDENTIALS\\n\\nBachelor of Engineering (Computer Engineering) from Mumbai University in 2024\\n\\nDiploma (Computer Engineering) from MSBTE University in 2021\\n\\nHSC from Maharashtra State board in 2018\\n\\nSSC from Maharashtra State board in 2016'),\n",
              " Document(metadata={'resume_id': '(Shivam Dubey)-Resume - Shivam Shailendra Dubey', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Project Title: TreeHosuse August 2024 October 2024\\n\\nProject Details: TreeHouse is a dynamic property platform that enhances the real estate experience with integrated video features. By focusing on rich video content, users can enjoy immersive property tours, informative webinars, and expert insights directly on the website. This engaging approach not only showcases listings in a captivating way but also helps buyers and renters make informed decisions through visual storytelling.'),\n",
              " Document(metadata={'resume_id': '(Shivam Dubey)-Resume - Shivam Shailendra Dubey', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Project Title: Rvaastu July 2024 October 2024\\n\\nProject Details: Rvaastu is an innovative property management platform designed to streamline the real estate experience. With a focus on responsive front-end development, it offers users an intuitive interface to explore, manage, and connect with properties seamlessly  across  all  devices.  Whether  browsing  listings  or  engaging  with  property  features,  Rvaastu  ensures  a  user-friendly experience tailored for modern needs.'),\n",
              " Document(metadata={'resume_id': '(Shivam Dubey)-Resume - Shivam Shailendra Dubey', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Project Title: GoGetter Jul 2024 August 2024.\\n\\nProject Details: GoGetter is an all-in-one booking platform that streamlines travel and utility services, allowing users to easily book train and flight tickets, mobile recharges, gas bookings, and more. With a user-friendly interface and a variety of services at their fingertips,  users  can  manage  their  travel  and  everyday  needs  in  one  convenient  app.  GoGetter  aims  to  simplify  the  booking experience, making it easier for users to stay connected and travel effortlessly.'),\n",
              " Document(metadata={'resume_id': '(Shivam Dubey)-Resume - Shivam Shailendra Dubey', 'chunk_id': 6, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Project Title: Gurukrupa placement &amp; education May 2023 to Jun 2023.\\n\\nProject Details: Developed the front-end of GuruKrupa Placement &amp; Education Solutions Pvt Ltd. website from scratch, ensuring a user-friendly and visually appealing interface. Collaborated closely with the design team to translate mockups and wireframes into responsive web pages using HTML5, CSS3, and JavaScript. Implemented modern web development best practices to optimize website performance and enhance user experience.'),\n",
              " Document(metadata={'resume_id': '(Shivam Dubey)-Resume - Shivam Shailendra Dubey', 'chunk_id': 7, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SIGNATURE SKILLS\\n\\nCoding                       -   Java, Python, Django, PHP.\\n\\nWeb Development     -   HTML, CSS, and Generative AI, MY-SQL, React JS, Bootstrap, WordPress.\\n\\nTools                          -   Eclipse IDE, Android Studio, Jupyter Notebook, VS Code, IDLE Python, Git.'),\n",
              " Document(metadata={'resume_id': '(Shivam Dubey)-Resume - Shivam Shailendra Dubey', 'chunk_id': 8, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SIGNATURE SKILLS\\n\\nSoft-Skills Training in Rubicon.\\n\\nPython training at Besant Technologies.\\n\\nDeep Insight: Exploring Advanced AI Realms.\\n\\n## DECLARATION\\n\\nI hereby declare that the above particulars are true to the best of my knowledge and belief.\\n\\nShivam Shailendra Dubey'),\n",
              " Document(metadata={'resume_id': 'Basit_s AI Resume - Basit Ali', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Basit Ali\\n\\n## Computer Science\\n\\nComputer Science undergraduate with a strong focus on artificial intelligence and machine learning\\n\\n\\n\\n\\n\\n\\n\\nbasitali71019@gmail.com\\n\\n+92 3152277904\\n\\nKarachi, Pakistan\\n\\nlinkedin.com/in/basit-ali-code404\\n\\ngithub.com/basitali1509'),\n",
              " Document(metadata={'resume_id': 'Basit_s AI Resume - Basit Ali', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## EDUCATION\\n\\n## Bachelor of Computer Science\\n\\nNED University of Engineering &amp; Technology\\n\\n10/2021 - 06/2025\\n\\n,'),\n",
              " Document(metadata={'resume_id': 'Basit_s AI Resume - Basit Ali', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## PERSONAL PROJECTS\\n\\n## Automated System for Digitization of Financial Documents and Analysis (09/2024 - Present)\\n\\n- Implemented Optical Character Recognition (OCR) to digitize and extract data from scanned financial documents like receipts, invoices, and statements\\n- Used Natural Language Processing (NLP) to categorize and organize extracted data into structured formats for easy access and analysis\\n- Enabled detailed analysis of financial data, providing insights into spending patterns, financial health, and trends\\n- Automated manual data entry tasks, reducing errors and improving the speed and efficiency of financial document processing\\n\\n## Customer Reviews Detection (05/2024 - 07/2024)\\n\\n- Implemented Support Vector Machine (SVM) to classify customer reviews as positive or negative\\n- Integrated BERT LLM for spam detection in reviews, improving classification performance\\n- Developed a functional website enabling users to upload CSV files of customer reviews for analysis\\n- Designed interactive graphs and tables to effectively demonstrate analysis results'),\n",
              " Document(metadata={'resume_id': 'Basit_s AI Resume - Basit Ali', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS\\n\\n\\n\\nPython\\n\\nTensorflow\\n\\nData Analysis\\n\\nData Preprocessing\\n\\nData Visualization\\n\\nML OPS\\n\\nMachine Learning\\n\\nDeep Learning\\n\\nNLP\\n\\nMySQL\\n\\nProblem Solving\\n\\nGit\\n\\n\\n\\n\\n\\n## CERTIFICATIONS\\n\\nIntroduction to Machine Learning\\n\\nKaggle\\n\\n## Intermediate Machine Learning\\n\\nKaggle\\n\\nIntro to Deep Learning\\n\\nKaggle\\n\\nSupervised Machine Learning: Regression and Classification\\n\\nCoursera\\n\\nThe AI Awakening: Implications for the Economy and Society\\n\\nCoursera\\n\\n## LANGUAGES\\n\\n## English\\n\\nFull Professional Proficiency\\n\\n## Urdu\\n\\nNative or Bilingual Proficiency\\n\\n## INTERESTS'),\n",
              " Document(metadata={'resume_id': 'Mayur_Chaudhari_Resume - Mayur Chaudhari', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Mayur Chaudhari\\n\\n## IT Engineer\\n\\nPhone\\n\\n739 197 9660\\n\\nE-mail mayurchaudhari160@gmail.com\\n\\nI'm an aspiring I.T Engineer with Technical Advancement as my ultimate focus. I am able to work well both in a deadlines. team environment as well as using my own initiative. I am able to work well under pressure and adhere to strict\\n\\n\\n\\nC / C++\\n\\nJava , Python, j Query,  Bootstrap\\n\\nMy SQL , AngularJS\\n\\nHTML 4 , HTML 5 &amp; CSS\\n\\nAJA X ,JSON\\n\\nSpringboot , Hibernate\\n\\n\\n\\nTime Management\\n\\nGood Communication Skills Active Listening\\n\\nTeamwork and Collaboration\\n\\nFast Grasper\\n\\n\\n\\n2016-08 -\\n\\n2021-08\\n\\nBachelor of Engineering: Information Technology\\n\\nSKN Sinhgad Institute of Technology And Science - Lonavala\\n\\n2015-07 -\\n\\n2016-04\\n\\nHSC\\n\\nD.N.C VP's Arts, Science &amp; Commerce Jr. College - Jalgaon\\n\\n\\n\\nTitle :- Disease Prediction Based On Symptoms Provided by Patient.\\n\\nDescription :- In this system we provide a disease prediction service for patients by which they can predict the disease by mentioning the symptoms they are having. For the implementation of this web service we had done coding using python.\\n\\nTechnology Used :- Java , Python.\\n\\n\\n\\nFront End Development - HTML &amp; CSS\\n\\nJava Full Stack Development - CSS ,HTML 4 ,HTML 5 , j Query , Bootstrap , AJA X , JSON, AngularJS, SQL\\n\\n\\n\\nListening Music\\n\\nReading\\n\\nTravelling\\n\\nAdventures\"),\n",
              " Document(metadata={'resume_id': 'Saaquib Motiwala Resume-6 (1) - saaquib motiwala', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Saaquib Motiwala\\n\\n❖ ❖ ❖ Portfolio saaquibmotiwala@gmail.com +91 9328577695 Vadodara, Gujarat /GitHub  link'),\n",
              " Document(metadata={'resume_id': 'Saaquib Motiwala Resume-6 (1) - saaquib motiwala', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## SUMMARY\\n\\nAs a future data scientist, I have a strong background in deep learning, machine learning, and data analytics in addition to real-world backend API development expertise. I have successfully created and put into use predictive models and user-friendly online apps that have successfully solved real-world issues. My excitement for investigating novel approaches and procedures in the area is fueled by my love for data-driven decision-making.\\n\\nI'm looking for internships right now where I can use my technical expertise and add to creative initiatives. I can take on challenging tasks because to my analytical approach and problem-solving skills, and I work best in group settings where I can share my knowledge and learn from others. I can't wait to use my expertise and imagination to assist businesses in realizing the full potential of their data .\"),\n",
              " Document(metadata={'resume_id': 'Saaquib Motiwala Resume-6 (1) - saaquib motiwala', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## PROJECTS\\n\\n## Traveler's Guide App\\n\\nJul. 2024 -Present\\n\\n- Developed an app that provides comprehensive information about various tourist destinations, categorizing places based on type (e.g., historical, natural, cultural).\\n- Integrated an AI chatbot feature to assist users in creating personalized itineraries tailored to their interests and preferences.\\n- Implemented a user-friendly interface that allows easy navigation and exploration of categorized tourist attractions.\\n- Included detailed descriptions, photos, reviews, and ratings for each tourist spot to enhance user experience and decision-making.\\n- Enabled users to filter and search for attractions based on location, category, and popularity.\\n- Designed the chatbot to handle user queries, suggest places to visit, and dynamically adjust itineraries based on user feedback.\\n- Integrated location services to provide directions and travel times for each suggested itinerary stop.\\n- I learned how to design custom APIs, web scrape from different platforms, and construct bespoke artificial intelligence for custom data through this project.\\n\\n## AI Recipe Generator\\n\\nMar. 2024 -Apr. 2024\\n\\n- The application is specifically designed to assist users in generating recipes.\\n- It aims to make cooking easier by suggesting recipes based on ingredients users already have.\\n- The platform is designed to be convenient and easy to use, focusing on providing a smooth and intuitive experience for all types of users.\\n- The interface allows quick and effortless input of ingredients and recipe discovery.\\n- The project taught me how to combine artificial intelligence with practical applications .\\n\\n## Disease Predictor\\n\\nJan. 2024 -Feb. 2024\\n\\n- A machine learning-based web application designed to predict diseases based on user-input symptoms.\\n- Key Features of the project:\\n- o User Symptom Input: A form or chatbot interface where users enter their symptoms.\\n- o Disease Prediction: The application uses trained machine learning models to predict possible diseases based on the input symptoms.\\n- o Confidence Scores: Provides prediction results with confidence scores for each predicted disease.\\n- o Medical Reference: Offers information about the predicted diseases and their potential treatments.\\n- This project helped me to understand using various machine learning models for actual data solving real world problems\\n\\n## Series/Movie Tracker Web App\\n\\nJun. 2022 - Aug. 2022\\n\\n- Developed a web version of an existing mobile app, utilizing the mobile app's private API for backend communication..\\n- Private API Integration: Handled the complexity of integrating with a private API, including managing rate limits, authentication, and error handling.\\n- Leveraged the mobile app's private API to provide real -time updates and data fetching.\\n- Understand the private Api calls\\n- I learned how an API's core operations operate and how to take use of this feature from this project.\\n\\n## Meter Reader App\\n\\nOct. 2021 -Feb. 2022\\n\\n- Developed an app to assist with electric meter reading, streamlining the process for field workers.\\n- Integrated functionality to display routes and locations, helping users navigate efficiently to each site.\\n- Enabled direct entry of meter readings within the app, removing the need for manual paperwork.\\n- Improved workflow efficiency by digitizing the reading and reporting process, reducing time spent on data entry.\\n- Designed the app with an intuitive user interface to minimize training time and maximize ease of use.\\n- Integrated GPS and map services for real-time tracking and route optimization.\\n- Ensured secure data storage and transmission to maintain accuracy and confidentiality of meter readings.\\n- Enhanced productivity by automating data submission directly from the field to central databases.\"),\n",
              " Document(metadata={'resume_id': 'Saaquib Motiwala Resume-6 (1) - saaquib motiwala', 'chunk_id': 3, 'gpa_value': 9.85, 'gpa_scale': 10.0, 'gpa_normalized': 9.85, 'gpa_found': True}, page_content='## EDUCATION\\n\\n## Maharaj Sayajirao Gaekwad University\\n\\nB.Tech in Computer Science\\n\\n- Attended Aws Seminar\\n\\n## Gujarat Technological University\\n\\nDiploma in Computer Science\\n\\n- Gpa: 9.85/10\\n- Won Parul Tech Expo'),\n",
              " Document(metadata={'resume_id': 'Saaquib Motiwala Resume-6 (1) - saaquib motiwala', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## CERTIFICATIONS, SKILLS &amp; INTERESTS\\n\\n- Certifications: Machine Learning - Edunet Foundation, Vadodara (Sep 2023 - May 2024); Automate Boring Stuff with Python - Udemy (Jun 2021); Learn to Think Like a Programmer with Python - Udemy (May 2021 Jun 2021); Harvard CSE Online Courses\\n- Skills: Data Analytics; Machine Learning; Data Science, Deep Learning; SQL; Python; Numpy; Pandas; Scikitlearn; Communication; Critical Thinking; Data Scraping\\n- Interests: Astronomy, Motorsports Racing, Traveling, Art, Baking, Volunteering\\n\\n2022 - 2025\\n\\nVadodara, Gujarat\\n\\n2019 - 2022\\n\\nVadodara, Gujarat'),\n",
              " Document(metadata={'resume_id': 'SHAHNAWAZ_RESUME (4) - shahnawaz Shaikh', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Summary\\n\\nAspiring Data Scientist with a passion for tackling real-world challenges through a blend of experience, knowledge, and skill set. Proficient in Python and frameworks, eager to leverage expertise in driving impactful solutions.'),\n",
              " Document(metadata={'resume_id': 'SHAHNAWAZ_RESUME (4) - shahnawaz Shaikh', 'chunk_id': 2, 'gpa_value': 8.5, 'gpa_scale': 10.0, 'gpa_normalized': 8.5, 'gpa_found': True}, page_content=\"## Education\\n\\n## Rizvi College of Engineering, Mumbai\\n\\nB.E  in Artificial Intelligence and Data Science\\n\\nJan. '22 - May. '25\\n\\nMumbai, India\\n\\n- Courses: Data Structures and Algorithm, Artificial Intelligence, Machine Learning, Deep Learning, Probability, Statistics, Linear Algebra, Database management and Data warehouse.NLP\\n\\nGPA: 8.5/10\"),\n",
              " Document(metadata={'resume_id': 'SHAHNAWAZ_RESUME (4) - shahnawaz Shaikh', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## Experience\\n\\n## WebMobi 360 | B2B AIML Solutions\\n\\nAI ML Intern\\n\\nSept. '23 - Dec. '23\\n\\nMumbai, India\\n\\n- Designed and developed a model to analyze one-minute interviews, utilizing advanced techniques to provide actionable insights and improvement suggestions for interview. performance.\\n- Successfully design  ed and developed Siamese Neural Networks for one-shot image recognition to achieve high accuracy in identifying images with limited training data\"),\n",
              " Document(metadata={'resume_id': 'SHAHNAWAZ_RESUME (4) - shahnawaz Shaikh', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Skills\\n\\n- Programming : Proficient in Python\\n- Frameworks : Tensorflow, Keras, scikit-learn, Numpy, Pandas, Matplotlib, Seaborn, OpenCV\\n- Data Science &amp; Machine Learning : Data Engineering, ETL, time series analysis, Data gathering, Data cleaning, EDA, Feature engineering, Supervised and Unsupervised learning algos.\\n- Infrastructure &amp; Tools : MySQL, Git version control, AWS cloud, APIs, Tableau, MSOffice, HTML, CSS, Javascript,\\n- Soft Skills : Communication, Leadership, Teamwork, Problem-solving, Positivity\\n- Languages: Hindi, English'),\n",
              " Document(metadata={'resume_id': 'SHAHNAWAZ_RESUME (4) - shahnawaz Shaikh', 'chunk_id': 5, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Projects\\n\\n- AI Medical Chatbot using Llama2\\n\\nDeveloped a real-time medical chatbot utilizing semantic search and efficient information retrieval via Llama 2, Sentence Transformer, Faiss-CPU and Chainlit for interactive healthcare support.\\n\\n- Siamese Neural Networks for One-shot Image Recognition (Webmobi 360)\\n\\nDemonstrated advanced proficiency in integrating multiple libraries and frameworks (Tensorflow,CNN, Keras, OpenCV, numpy, pandas, and Scikit-learn) to create a robust machine learning model capable of efficient one-shot learning, significantly reducing the need for extensive datasets.\\n\\n## Shahnawaz Shaikh\\n\\nAspiring Deep Learning Engineer\\n\\n\\n\\n\\n\\nshanu\\n\\nsshahnawaz567@gmail.com\\n\\nshanu\\n\\n+91 9702611605\\n\\n\\n\\n- Certified AWS cloud foundation (2024) Issued by Amazon Web Services\\n- TCS ion Career Edge - Young Professional (2024) Issued by TCS ION'),\n",
              " Document(metadata={'resume_id': 'Ritik_Sohane_IIITBhopal - Ritik Sohane', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## EDUCATION\\n\\n## Indian Institute of Information Technology (IIIT), Bhopal\\n\\nBachelors of Technology - Information Technology (IT)'),\n",
              " Document(metadata={'resume_id': 'Ritik_Sohane_IIITBhopal - Ritik Sohane', 'chunk_id': 2, 'gpa_value': 9.65, 'gpa_scale': 10.0, 'gpa_normalized': 9.65, 'gpa_found': True}, page_content='## PROFESSIONAL EXPERIENCE\\n\\n## Backend Developer Intern | Sapline Pharma\\n\\nDecember 2021-May 2025\\n\\nMAX SGPA:9.65 CGPA 8.6\\n\\nMay 2024 - July 2024\\n\\n- Optimized backend processes by improving API efficiency ,which resulted in a 30% reduction in reported site issues and enhanced overall user satisfaction over a two-month period\\n- Developed and maintained server-side logic for product management, ensuring accurate data handling for product listings, pricing, and visuals, which improved backend workflow and streamlined updates\\n\\n## Institute Teaching Assistantship|IIIT Bhopal\\n\\nAugust 2023 - January 2024\\n\\n- Led workshops and mentoring sessions for 200+ students in Discrete Data Structure and OOPs , boosted student engagement by 15% through a collaborative learning approach'),\n",
              " Document(metadata={'resume_id': 'Ritik_Sohane_IIITBhopal - Ritik Sohane', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS/EXPERTISE\\n\\n- Technical Skills : C, C++, Java, HTML, CSS, JavaScript, Python , MongoDB, SQL , AWS\\n- Technologies\\\\Frameworks : React JS, ExpressJs, React-Router-DOM, Material UI, Fastapi, Django, Flask, REST\\n- Developer Tools : Git, Github, VS Code, Netlify, Vercel, MS Office Suite, Postman, Linux\\n- Soft Skills: Leadership, Effective Communication, Team Management, Problem Solving, Tech Enthusiast\\n- Relevant Coursework : Object Oriented Programming(OOPS), Operating System, Database Management System (DBMS), Data Structures &amp; Algorithms, Computer Networks, A&amp;ML'),\n",
              " Document(metadata={'resume_id': 'Ritik_Sohane_IIITBhopal - Ritik Sohane', 'chunk_id': 4, 'gpa_value': 40.0, 'gpa_scale': 100.0, 'gpa_normalized': 4.0, 'gpa_found': True}, page_content='## PROJECTS\\n\\n## TechMind | ReactJS, NodeJS, MongoDB, ExpressJS, RestfulAPI, SQL\\n\\nGITHUB\\n\\n- Built a scalable ed-tech platform using the MERN stack, integrating user authentication, course management, and cloud-based media management using Cloudinary , improving user engagement by 40% and media loading times by 35%\\n- Optimized system performance through RESTful API implementation and MongoDB storage, increasing efficiency by 30% and supporting 50% more user data seamlessly\\n\\n## Large Data Statistical Model |Python, Machine Learning, Pandas, Scikit-Learn, Flask\\n\\n\\n\\n- Developed a model by processing and analyzing the Amazon Product Reviews Dataset encompassing over 50,000 reviews\\n- Leveraged advanced statistical modeling and machine learning, achieving 98% accuracy with Random Forest Classifier , and applied data cleaning, exploratory data analysis and regression analysis to optimize business strategies\\n\\n## Invoice Generator |HTML, CSS, Bootstrap, JavaScript, ReactJS, SQL\\n\\n\\n\\n- Engineered a robust Invoice Generator that empowered users to generate polished Invoices with ease, resulting in a 50% reduction in errors and improving overall billing accuracy\\n- Adept at translating intricate business logic into a user-friendly application, underscoring proficiency in Front-end development and its principles'),\n",
              " Document(metadata={'resume_id': 'Ritik_Sohane_IIITBhopal - Ritik Sohane', 'chunk_id': 5, 'gpa_value': 5.0, 'gpa_scale': 10.0, 'gpa_normalized': 5.0, 'gpa_found': True}, page_content='## ACHIEVEMENTS\\n\\n- Achieved the Badge of Knight at LeetCode with a max rating of 1885, ranking among the Top 5% of Coders at Leetcode\\n- Solved 600+Coding Problems on Leetcode, CodeChef and CodeForces, refining my Coding Skills across diverse platforms\\n- Attained top 10 team ranking in the Web Development Hackathon by GDSC IIIT Bhopal\\n- Branch Toppe r in 6th Semester Examinations by scoring SGPA of 9.65\\n\\n## POSITION OF RESPONSIBILITY\\n\\n## Vice President - Student Council, IIIT Bhopal\\n\\nAugust 2024 - Present\\n\\n- Galvanizing student voices by spearheading impactful projects and initiatives and empowering 2000+ students , driving positive change and fostering a cohesive student community\\n\\n## Executive Member - Google Developer Student Club, IIIT Bhopal\\n\\nAugust 2022-August 2023\\n\\n- Coordinated 10+ tech events for 400+ students, including Hackathons on Web 3.0, OpenAi and ML, with 300+ participants , boosting tech engagement and innovation\\n\\n## Campus Ambassador CA\\\\_ID:CA217724 | E-Cell, IIT Bombay\\n\\n- Spearheaded entrepreneurial initiatives as Campus Ambassador for E-Cell IIT Bombay\\n- Enriched engagement between students and E-Cell which results as a 40% growth in participation by organizing 5+ events to foster innovation and entrepreneurial spirit within the campus\\n\\nJuly 2022 - June 2023\\n\\n## Ritik Sohane\\n\\n+91 7054242325 | ritiksohane@gmail.com | LinkedIn | GitHub | Leetcode'),\n",
              " Document(metadata={'resume_id': 'Hema Sri Challa Resume (1) - 28-Hema Sri Challa', 'chunk_id': 0, 'gpa_value': 97.3, 'gpa_scale': 100.0, 'gpa_normalized': 9.73, 'gpa_found': True}, page_content='Seeking a challenging position in a reputed organization where I can learn new skills,\\n\\nBachelor of Technology\\n\\n- 2025\\n\\nCGPA-8.68\\n\\n- 2021\\n\\nPercentage-97.3%\\n\\nSecondary School Certificate (SSC) | Akshara High School, Jangareddygudem. 2018- 2019 GPA-9.8'),\n",
              " Document(metadata={'resume_id': 'Hema Sri Challa Resume (1) - 28-Hema Sri Challa', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content=\"## INTERNSHIP EXPERIENCE\\n\\nRoot Planning Application | Henotic IT Solutions Pvt Ltd\\n\\nJUL 2023 - SEP 2023\\n\\nDeveloped a Java-Based Metro Route Optimization System Using Graph Data Structures and Dijkstra's Algorithm for Efficient Pathfinding. It Allows Users to Explore Metro Networks, Find Optimal Routes Based on Distance and Time, and Navigate Easily via an Interactive Interface. The System Uses Station Codes, Detects Interchange Stations, and Displays Clear Routes with Total Distance or Time.\\n\\n## It's About to Perform Two Tasks (Stock Prediction with LSTM, Titanic\\n\\n## Classification) | Bharat Intern\\n\\nOCT 2023 - NOV 2023\\n\\nIn Python, I've successfully completed the following Data Science tasks:\\n\\n1. Stock Prediction with LSTM: Utilized LSTM to predict stock prices, demonstrating proficiency in time series analysis and machine learning.\\n2. Titanic Classification: Developed a system to predict survival rates on the Titanic, showcasing skills in classification and feature engineering.\\n\\n## Weather Forecast Application | IIDT Blackbucks Private Ltd JUNE 2024 - JULY 2024\\n\\nI developed a responsive web application using HTML, CSS, and JavaScript for precise worldwide weather forecasts. Key features include user-friendly location search, real-time weather data, hourly forecasts, 5-day predictions, and interactive data visualizations. It helps users plan activities with accurate and timely weather information.\\n\\n\\n\\nOperating systems: Windows.\\n\\nScripting Language: HTML, CSS, Java Script\\n\\nProgramming Languages: JAVA, Basics of Python, Basics of C++, Basics of C, Basics of Data Structures and Algorithms.\\n\\nTool: Eclipse, Jupyter Notebook, Visual Studio.\\n\\nCertified in DSA Internship at Henotic IT Solutions Pvt Ltd\\n\\nCertified in Bharat Intern\\n\\nCertified for participation in a 24-hour hackathon focused on Data Science.\\n\\nCertified in Oracle Cloud Infrastructure 2024 Generative AI Certified Professional\\n\\n## ACTIVITIES\\n\\nI have completed two internships in 2023, one of which was with Henotic IT Solutions Pvt Ltd, where I led a group, another with Bharat Intern. In my first year of college, I secured the second position by presenting a PowerPoint on environmental science in a college-level competition. In second year certified for participation in a 24-hour hackathon focused on Data Science Outside of academics and work, I enjoy plantation and watering plants, playing badminton. I am fluent in English and Telugu.\"),\n",
              " Document(metadata={'resume_id': 'B. Umakanth (resume) - B.Umakanth', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## B.UMA KANTH\\n\\nAddress : Thondawada, Chandragiri mandal, Door no:F-block-186  | City, ST ZIP Code :Tirupati,517505  | Phone Number :9949604104  | Email: bumakanth52@gmail.com\\n\\n- \\uf0b7 Career Objective : To work in a stimulating environment where I can apply &amp; enhance my knowledge ,skills to serve the firm to the best of my efforts .\\n- \\uf0b7 Education Qualification:\\n- \\uf0b7 Skills:\\n\\n\\n\\n| Examination   | Discipline   | School/College   | Board/ University   | Year of passing   | Percentage Of marks%   |\\n|---------------|--------------|------------------|---------------------|-------------------|------------------------|\\n\\n## RESUME\\n\\n- \\uf0d8 Technical Skills:\\n1. Programming Languages: C, C++, Java, Python &amp;Web Language\\n2. Software &amp;Tools: VS code, Eclipse\\n3. Operating system: Windows OS\\n4. Web Development:\\n- o Front end : HTML, CSS, Java Script, React J.S\\n- o Backend : Node J.S, Angular j.s.\\n- \\uf0d8 Soft Skills:\\n1. Hard work.\\n2. Good  communication skills.\\n3. Good analytical knowledge.\\n4. Willing to learn new things.'),\n",
              " Document(metadata={'resume_id': 'B. Umakanth (resume) - B.Umakanth', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## \\uf0b7 Project:\\n\\nAgriculture Guidance System: Developed a web platform that offers farmers detailed crop selection advice, comprehensive crop details, and step-by-step farming techniques to optimize agricultural practices.\\n\\n- \\uf0b7 Industrial Training: (Upcoming)\\n- \\uf0b7 Personal Profile:\\n- \\uf0b7 Hobbies and Interests:\\n- \\uf0fc Hobbies: My hobbies are reading books, playing games, Coding, physical exercising.\\n- \\uf0fc Interests: My interests are in programming and Workouts.\\n- \\uf0b7 Extra  curricular activities:\\n- \\uf0fc Team work : I had worked in the team of my project and get the successful result.\\n- \\uf0b7 Declaration: I here by declare that all the above statements are true and complete to the best of my knowledge and belief .\\n\\n- -&gt;Name : B. Umakanth\\n\\n- -&gt;DOB : 12/04/2006\\n\\n- -&gt;Father`s Name : B. Veeraiah\\n\\n- -&gt; Gender : Male\\n\\n- -&gt; Nationality: India\\n\\n- -&gt;Religion : Hindu\\n\\n- -&gt;Language Known : English, Telugu\\n\\n## (B. Umakanth)'),\n",
              " Document(metadata={'resume_id': 'Anuj_CV_updated - Mishra Anuj', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Mishra Anuj\\n\\n## Email-han-clasailier\\n\\n## Pulhun\\n\\n- Frontend\\n\\n- Dackend:\\n\\n- Learning; NLF Computer Vision\\n\\nGnhul'),\n",
              " Document(metadata={'resume_id': 'Nagendra-Maddela_Resume (1) - Nagendra', 'chunk_id': 1, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## EDUCATION\\n\\nIndian Institute of Information Technology, Nagpur, India\\n\\n2021-25\\n\\nBachelor of Technology, Computer Science &amp; Engineering\\n\\nEXPERIENCE\\n\\nCGPA:7.1'),\n",
              " Document(metadata={'resume_id': 'Nagendra-Maddela_Resume (1) - Nagendra', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## Data Science - (training +Project)\\n\\nMay 2024-July 2025\\n\\n## Unified Mentor-  (Remote)\\n\\n- \\uf0b7 Participating in comprehensive training sessions to enhance skills in data science.Working on practical projects to apply theoretical knowledge in real-world scenarios.Collaborating with a team of professionals to develop solutions and improve workflows. \\uf020\\n- \\uf0b7 Learning and utilizing tools and technologies such as Python, PowerBI, SQL,Data Visualization techniques. \\uf020\\n- \\uf0b7 And also worked on projects like predictive model for crop production Analysis, Entertainer Data Analysis and Heart Disease Diagnostic Analysis.\\n\\n## AI &amp; Data Science  (Intern)\\n\\n## Coding Junior -  ( Remote )\\n\\n- \\uf0b7 Engaged in fine-tuning large language models (LLMs) to improve performance and accuracy.Collaborated with a team to develop and implement strategies for enhancing model outputs. \\uf020\\n\\n\\uf020\\n\\n- \\uf0b7 Utilized tools and frameworks such as TensorFlow, Hugging Face Transformers,\\n- \\uf0b7 Contributed to research and development efforts by experimenting with various model architectures and hyperparameters. \\uf020'),\n",
              " Document(metadata={'resume_id': 'Nagendra-Maddela_Resume (1) - Nagendra', 'chunk_id': 3, 'gpa_value': 97.0, 'gpa_scale': 100.0, 'gpa_normalized': 9.7, 'gpa_found': True}, page_content='## PROJECTS\\n\\n- \\uf0b7 Face  Emotion  Recognition. Developed  a  model  to  recognize  and  classify  facial  emotions  from  images. Integrated the model into a real-time application.( Python, TensorFlow, Keras, OpenCV, Scikit-learn.)(Github Link) \\uf020\\n\\n\\uf020\\n\\n- \\uf0b7 Skin Lesion Cancer Classification. Developed a model to classify skin lesions using MNIST 10000 image data. Achieved 97% accuracy using different techniques and hyperparameters in classifying skin lesions; developed a  user-friendly interface for dermatologists to use in clinical settings. (Python, TensorFlow, Over Sampling, Transfer Learning)(Github Link) \\uf020\\n\\n\\uf020\\n\\nJune 2024 - August 2024\\n\\n## NAGENDRA MADDELA\\n\\nmaddela3435@gmail.com ⋄ linkedin.com/nagendra ⋄ Github ⋄ 91+ 7993663435\\n\\n\\uf020\\n\\n- \\uf0b7 Medical  Chatbot. Developed  a  chatbot  to  assist  users  with  medical  inquiries  and  provide  health-related information. Integrated Pinecone Vector Database for efficient storage and retrieval of medical information. Deployed the chatbot on a web platform using Flask.( Python, LangChain,Pinecone VectorDB,Flask,HuggingFaceLlama2 model). (Github Link) \\uf020'),\n",
              " Document(metadata={'resume_id': 'Nagendra-Maddela_Resume (1) - Nagendra', 'chunk_id': 4, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS\\n\\n- \\uf0b7 Technical Skills Machine Learning (ML), Deep Learning (DL), Natural Language Processing (NLP), Generative AI (GenAI), SQL, Statistics \\uf020\\n- \\uf0b7 Frame works &amp; tools Numpy, Pandas, Matplotlib, Seaborn, Tensorflow, Scikit learn, Langchain, Power BI, Vector DataBase, RAG System \\uf020\\n\\n\\uf020\\n\\n- \\uf0b7 AWS Skills AWS EC2, S3, Deployment Programming Languages C++, C, Python\\n\\n## EXTRA-CURRICULAR ACTIVITIES\\n\\n- \\uf0b7 Solving DSA Problems on : Leetcode, Coding Ninjas,\\n\\n\\uf020'),\n",
              " Document(metadata={'resume_id': 'Pakeeza_CV - MUNIZA SOCIAL MEDIA', 'chunk_id': 0, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## PERSONAL INFO\\n\\n\\n\\nFemale\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPakistani\\n\\n0321-5592675\\n\\nPakeezabaloch696@gmail.com\\n\\nSaeela,Jhelum\\n\\n\\n\\n- https://www.linkedin.com/in/ pakeeza-rashid-917570279/'),\n",
              " Document(metadata={'resume_id': 'Pakeeza_CV - MUNIZA SOCIAL MEDIA', 'chunk_id': 1, 'gpa_value': 85.0, 'gpa_scale': 100.0, 'gpa_normalized': 8.5, 'gpa_found': True}, page_content='## EDUCATION\\n\\n## PUNJAB UNIVERSITY 2021-2025\\n\\n- BS MANAGEMENT 6th Semester (Continue)\\n- Fsc Pre-Medical\\n- 85% Marks\\n\\n2020 - 2021\\n\\nASPIRE COLLEGE ,JHELUM\\n\\n2018 - 2020\\n\\nGOVT GIRLS HIGH SCHOOL, SAEELA\\n\\n- Biology\\n- 87% Marks'),\n",
              " Document(metadata={'resume_id': 'Pakeeza_CV - MUNIZA SOCIAL MEDIA', 'chunk_id': 2, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## SKILLS\\n\\n- A.I Basics\\n- Python  ( continuous learning)\\n- Sales Expert\\n- Internet Browsing Skills\\n- Time Management\\n- Effective Communication\\n\\n## CERTIFICATIONS\\n\\n- AI with XEVEN SOLUTION\\n\\n## LANGUAGES\\n\\n- English\\n- Urdu\\n\\n\\n\\n## PROFILE\\n\\nProficient in Teaching , Facebook advertising, international sales, and marketplace  listings,  with  a  proven  track  record  of  growth.  Committed  to continuous learning in AI with Python, aiming to leverage emerging technologies. Dedicated to delivering results through innovation, collaboration, and a passion for lifelong learning. . Eager to apply my expertise and drive for excellence to contribute to the success of a dynamic organization'),\n",
              " Document(metadata={'resume_id': 'Pakeeza_CV - MUNIZA SOCIAL MEDIA', 'chunk_id': 3, 'gpa_value': None, 'gpa_scale': None, 'gpa_normalized': None, 'gpa_found': False}, page_content='## WORK EXPERIENCE\\n\\n## Online Sales Expert\\n\\nat Jhelum tech\\n\\n2022-Present\\n\\n- Developed and executed highly effective Facebook advertising campaigns targeting international (foreign) audiences.\\n- Achieved  exceptional  results in  driving  sales  through  Facebook marketplace listings, leveraging advanced targeting and optimization strategies..\\n\\n## Teaching\\n\\nHome tutor\\n\\n- Successfully provided personalized academic support and instruction to students in a Home Setting.\\n- Tailored  lesson  plans  and  teaching  methodologies  to  meet  the individual learning styles and needs of each student.\\n- Received  positive feedback  from  students &amp; parents  regarding improvements in academic performance and overall learning experience\\n\\n## REFERENCE\\n\\nWill be Provided On demand\\n\\n2022-Present')]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1t6oA-XLz-c_"
      },
      "id": "1t6oA-XLz-c_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}