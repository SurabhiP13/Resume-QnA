{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "LuYOL6F0DeQt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuYOL6F0DeQt",
        "outputId": "f9bafe22-36e0-405f-bc22-df8cf148b5f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  Resume-markdown-docling-zip.zip\n",
            "replace Resume-markdown-docling/(Shivam Dubey)-Resume - Shivam Shailendra Dubey.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# !unzip Resume-markdown-docling-zip.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54eb20c3",
      "metadata": {},
      "source": [
        "### Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "HD2BulRfI42S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD2BulRfI42S",
        "outputId": "ba7bc5d2-2be4-4ed9-8d00-643090ff9b3c"
      },
      "outputs": [],
      "source": [
        "# !pip install docling\n",
        "# !pip install -U sentence-transformers\n",
        "# !pip install rank-bm25\n",
        "# !pip install faiss-cpu\n",
        "# !pip install langchain\n",
        "# !pip install openai\n",
        "# !pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "670481c9",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1d53d14f",
      "metadata": {
        "id": "1d53d14f"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhashlib\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatistics\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_converter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocumentConverter\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InputFormat\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline_options\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PdfPipelineOptions\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\docling\\document_converter.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, ConfigDict, model_validator, validate_call\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabstract_backend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AbstractDocumentBackend\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01masciidoc_backend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsciiDocBackend\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcsv_backend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CsvDocumentBackend\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocling_parse_v4_backend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DoclingParseV4DocumentBackend\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\docling\\backend\\asciidoc_backend.py:20\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     DocItemLabel,\n\u001b[32m      9\u001b[39m     DoclingDocument,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     TableData,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabstract_backend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeclarativeDocumentBackend\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InputFormat\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InputDocument\n\u001b[32m     23\u001b[39m _log = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\docling\\datamodel\\base_models.py:33\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_backend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PdfPageBackend\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabstract_backend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AbstractDocumentBackend\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline_options\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PipelineOptions\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mBaseFormatOption\u001b[39;00m(BaseModel):\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Base class for format options used by _DocumentConversionInput.\"\"\"\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\docling\\datamodel\\pipeline_options.py:15\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     AnyUrl,\n\u001b[32m      9\u001b[39m     BaseModel,\n\u001b[32m     10\u001b[39m     ConfigDict,\n\u001b[32m     11\u001b[39m     Field,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m asr_model_specs, vlm_model_specs\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Import the following for backwards compatibility\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maccelerator_options\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AcceleratorDevice, AcceleratorOptions\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\docling\\datamodel\\asr_model_specs.py:9\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      5\u001b[39m     AnyUrl,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maccelerator_options\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AcceleratorDevice\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline_options_asr_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# AsrResponseFormat,\u001b[39;00m\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# ApiAsrOptions,\u001b[39;00m\n\u001b[32m     12\u001b[39m     InferenceAsrFramework,\n\u001b[32m     13\u001b[39m     InlineAsrNativeWhisperOptions,\n\u001b[32m     14\u001b[39m     TransformersModelType,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m _log = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     19\u001b[39m WHISPER_TINY = InlineAsrNativeWhisperOptions(\n\u001b[32m     20\u001b[39m     repo_id=\u001b[33m\"\u001b[39m\u001b[33mtiny\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     inference_framework=InferenceAsrFramework.WHISPER,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     max_time_chunk=\u001b[32m30.0\u001b[39m,\n\u001b[32m     28\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\docling\\datamodel\\pipeline_options_asr_model.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maccelerator_options\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AcceleratorDevice\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline_options_vlm_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# InferenceFramework,\u001b[39;00m\n\u001b[32m     10\u001b[39m     TransformersModelType,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mBaseAsrOptions\u001b[39;00m(BaseModel):\n\u001b[32m     15\u001b[39m     kind: \u001b[38;5;28mstr\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\docling\\datamodel\\pipeline_options_vlm_model.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdoc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SegmentedPage\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnyUrl, BaseModel, ConfigDict\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StoppingCriteria\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maccelerator_options\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AcceleratorDevice\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\transformers\\__init__.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     28\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     29\u001b[39m     _LazyModule,\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     logging,\n\u001b[32m     49\u001b[39m )\n\u001b[32m     52\u001b[39m logger = logging.get_logger(\u001b[34m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdependency_versions_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[32m     25\u001b[39m pkgs_to_check_at_runtime = [\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtqdm\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpyyaml\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m ]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\transformers\\utils\\__init__.py:25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackbone_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_template_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocstringParsingException, TypeHintParsingException, get_json_schema\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     28\u001b[39m     add_code_sample_docstrings,\n\u001b[32m     29\u001b[39m     add_end_docstrings,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     replace_return_docstrings,\n\u001b[32m     34\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\transformers\\utils\\chat_template_utils.py:40\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mImage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m     43\u001b[39m BASIC_TYPES = (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, Any, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m), ...)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Extracts the initial segment of the docstring, containing the function description\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\__init__.py:2088\u001b[39m\n\u001b[32m   2084\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnable to find torch_shm_manager at \u001b[39m\u001b[33m\"\u001b[39m + path)\n\u001b[32m   2085\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m path.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2088\u001b[39m \u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_initExtension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_manager_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2090\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m _manager_path\n\u001b[32m   2092\u001b[39m \u001b[38;5;66;03m# Appease the type checker: it can't deal with direct setting of globals().\u001b[39;00m\n\u001b[32m   2093\u001b[39m \u001b[38;5;66;03m# Note that we will see \"too many\" functions when reexporting this way; there\u001b[39;00m\n\u001b[32m   2094\u001b[39m \u001b[38;5;66;03m# is not a good way to fix this problem.  Perhaps, try to redesign VariableFunctions\u001b[39;00m\n\u001b[32m   2095\u001b[39m \u001b[38;5;66;03m# so that this import is good enough\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\cuda\\__init__.py:356\u001b[39m\n\u001b[32m    351\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    352\u001b[39m                 \u001b[38;5;66;03m# Don't store the actual traceback to avoid memory cycle\u001b[39;00m\n\u001b[32m    353\u001b[39m                 _queued_calls.append((\u001b[38;5;28mcallable\u001b[39m, traceback.format_stack()))\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_check_capability\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m _lazy_call(_check_cubins)\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDeferredCudaCallError\u001b[39;00m(\u001b[38;5;167;01mException\u001b[39;00m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\cuda\\__init__.py:353\u001b[39m, in \u001b[36m_lazy_call\u001b[39m\u001b[34m(callable, **kwargs)\u001b[39m\n\u001b[32m    350\u001b[39m     _lazy_seed_tracker.queue_seed(\u001b[38;5;28mcallable\u001b[39m, traceback.format_stack())\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    352\u001b[39m     \u001b[38;5;66;03m# Don't store the actual traceback to avoid memory cycle\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     _queued_calls.append((\u001b[38;5;28mcallable\u001b[39m, \u001b[43mtraceback\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\psura\\anaconda3\\Lib\\traceback.py:246\u001b[39m, in \u001b[36mformat_stack\u001b[39m\u001b[34m(f, limit)\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    245\u001b[39m     f = sys._getframe().f_back\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m format_list(\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\psura\\anaconda3\\Lib\\traceback.py:260\u001b[39m, in \u001b[36mextract_stack\u001b[39m\u001b[34m(f, limit)\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    259\u001b[39m     f = sys._getframe().f_back\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m stack = \u001b[43mStackSummary\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m stack.reverse()\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\psura\\anaconda3\\Lib\\traceback.py:449\u001b[39m, in \u001b[36mStackSummary.extract\u001b[39m\u001b[34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[39m\n\u001b[32m    446\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f, lineno \u001b[38;5;129;01min\u001b[39;00m frame_gen:\n\u001b[32m    447\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f, (lineno, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_extract_from_extended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\psura\\anaconda3\\Lib\\traceback.py:500\u001b[39m, in \u001b[36mStackSummary._extract_from_extended_frame_gen\u001b[39m\u001b[34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[32m--> \u001b[39m\u001b[32m500\u001b[39m         \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mline\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\psura\\anaconda3\\Lib\\traceback.py:373\u001b[39m, in \u001b[36mFrameSummary.line\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mline\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lines \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    375\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\psura\\anaconda3\\Lib\\traceback.py:351\u001b[39m, in \u001b[36mFrameSummary._set_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    348\u001b[39m lines = []\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lineno \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.lineno, \u001b[38;5;28mself\u001b[39m.end_lineno + \u001b[32m1\u001b[39m):\n\u001b[32m    350\u001b[39m     \u001b[38;5;66;03m# treat errors (empty string) and empty lines (newline) as the same\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     line = \u001b[43mlinecache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlineno\u001b[49m\u001b[43m)\u001b[49m.rstrip()\n\u001b[32m    352\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.filename.startswith(\u001b[33m\"\u001b[39m\u001b[33m<\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    353\u001b[39m         line = linecache._getline_from_code(\u001b[38;5;28mself\u001b[39m._code, lineno).rstrip()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\psura\\anaconda3\\Lib\\linecache.py:26\u001b[39m, in \u001b[36mgetline\u001b[39m\u001b[34m(filename, lineno, module_globals)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgetline\u001b[39m(filename, lineno, module_globals=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     23\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a line for a Python source file from the cache.\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m    Update the cache if it doesn't contain an entry for this file already.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     lines = \u001b[43mgetlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m1\u001b[39m <= lineno <= \u001b[38;5;28mlen\u001b[39m(lines):\n\u001b[32m     28\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m lines[lineno - \u001b[32m1\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\psura\\anaconda3\\Lib\\linecache.py:42\u001b[39m, in \u001b[36mgetlines\u001b[39m\u001b[34m(filename, module_globals)\u001b[39m\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m cache[filename][\u001b[32m2\u001b[39m]\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupdatecache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m:\n\u001b[32m     44\u001b[39m     clearcache()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\psura\\anaconda3\\Lib\\linecache.py:171\u001b[39m, in \u001b[36mupdatecache\u001b[39m\u001b[34m(filename, module_globals)\u001b[39m\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtokenize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    172\u001b[39m         lines = fp.readlines()\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m, \u001b[38;5;167;01mSyntaxError\u001b[39;00m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\psura\\anaconda3\\Lib\\tokenize.py:455\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(filename)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen\u001b[39m(filename):\n\u001b[32m    452\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Open a file in read only mode using the encoding detected by\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[33;03m    detect_encoding().\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     buffer = \u001b[43m_builtin_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    457\u001b[39m         encoding, lines = detect_encoding(buffer.readline)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Any\n",
        "import hashlib\n",
        "import statistics\n",
        "\n",
        "from docling.document_converter import DocumentConverter\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pickle\n",
        "import re\n",
        "from typing import List, Dict, Any\n",
        "from rank_bm25 import BM25Okapi\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "\n",
        "# Constants\n",
        "RESUME_PDF_PATH = \"Submit your resume or CV (File responses)\"\n",
        "RESUME_MARKDOWN_PATH = \"Resume-markdown-docling\"\n",
        "MAX_RESUMES = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yjkm8UV6OlGj",
      "metadata": {
        "id": "Yjkm8UV6OlGj"
      },
      "source": [
        "### PDF to Markdown Conversion using docling and saving it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f82e2a59",
      "metadata": {
        "cellView": "form",
        "id": "f82e2a59"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# # Basic PDF to Markdown conversion\n",
        "# from pathlib import Path\n",
        "\n",
        "# # Setup paths\n",
        "# pdf_dir = Path(\"Submit your resume or CV (File responses)\")\n",
        "# output_dir = Path(\"Resume-markdown-docling\")\n",
        "# output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# # Get first 200 PDFs\n",
        "# pdf_files = list(pdf_dir.glob(\"*.pdf\"))[:200]\n",
        "# print(f\"Found {len(pdf_files)} PDFs to convert\")\n",
        "\n",
        "# # Convert PDFs\n",
        "# converter = DocumentConverter()\n",
        "# successful = 0\n",
        "\n",
        "# for pdf_file in pdf_files:\n",
        "#     try:\n",
        "#         result = converter.convert(str(pdf_file))\n",
        "#         markdown_content = result.document.export_to_markdown()\n",
        "\n",
        "#         output_file = output_dir / f\"{pdf_file.stem}.md\"\n",
        "#         output_file.write_text(markdown_content, encoding='utf-8')\n",
        "\n",
        "#         successful += 1\n",
        "#         if successful % 20 == 0:\n",
        "#             print(f\"Converted {successful} files\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Failed: {pdf_file.name}\")\n",
        "\n",
        "# print(f\"Conversion complete: {successful}/{len(pdf_files)} successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "r2Cm85VyOvZt",
      "metadata": {
        "id": "r2Cm85VyOvZt"
      },
      "source": [
        "### Chunking the markdowns based on custom rules\n",
        "=> 3+ separated capital letters to be joined => due to conversion between pdf and markdown\n",
        "\n",
        "=> splitting based on common headers in resume such as experience , summary etc using regex + it needs to be after ## => thats how docling does it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "94a49d8a",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94a49d8a",
        "outputId": "ee375f2c-b8e7-4167-8011-07ebd4ac388d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 263 chunks from 52 resumes\n",
            "Average chunks per resume: 5.1\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# markdown_dir=Path(\"Resume-markdown-docling\")\n",
        "# def fix_spaced_caps(s: str) -> str:\n",
        "#     pattern = re.compile(r'(?<!\\w)(?:[A-Z]\\s+){2,}[A-Z](?!\\w)')  # 3+ capital letters separated by spaces\n",
        "#     def _join(m):\n",
        "#         return m.group(0).replace(' ', '')\n",
        "#     return pattern.sub(_join, s)\n",
        "\n",
        "# def container_chunking(content: str, resume_id: str) -> List[Document]:\n",
        "#     # Remove image tags\n",
        "#     content = re.sub(r'<!-- image -->', '', content)\n",
        "#     #Removing spacing S K I L L -> SKILL\n",
        "#     # Fix spaced out words like \"e x p e r i e n c e\" or \"E X P E R I E N C E\"\n",
        "#     # content = re.sub(r'\\b(\\w)\\s+(\\w)\\s+(\\w)(\\s+\\w)*\\b', lambda m: re.sub(r'\\s+', '', m.group()), content)\n",
        "#     content = fix_spaced_caps(content)\n",
        "\n",
        "#     containers = [\n",
        "#         r'about\\s*me', r'summary', r'profile', r'experience', r'work\\s+experience',\n",
        "#         r'education', r'skill[s]?', r'project[s]?', r'achievement[s]?', r'award[s]?',\n",
        "#         r'publication[s]?', r'competition[s]?', r'hackathon[s]?', r'certification[s]?',\n",
        "#     ]\n",
        "#     container_alt = '|'.join(containers)\n",
        "\n",
        "#     # Anchor to line start, any H1–H6, match only the heading line\n",
        "#     pattern = rf'(?=^#{{1,6}}\\s*(?:.*\\b(?:{container_alt})\\b).*$)'\n",
        "#     chunks = re.split(pattern, content, flags=re.IGNORECASE | re.MULTILINE)\n",
        "\n",
        "#     # Filter empty chunks and create documents\n",
        "#     docs = []\n",
        "#     for i, chunk in enumerate(chunks):\n",
        "#         chunk = chunk.strip()\n",
        "#         if chunk and len(chunk) > 50:\n",
        "#             doc = Document(\n",
        "#                 page_content=chunk,\n",
        "#                 metadata={'resume_id': resume_id, 'chunk_id': i}\n",
        "#             )\n",
        "#             docs.append(doc)\n",
        "\n",
        "#     return docs\n",
        "\n",
        "# # Process all resumes\n",
        "# all_chunks = []\n",
        "# for md_file in markdown_dir.glob(\"*.md\"):\n",
        "#     content = md_file.read_text(encoding='utf-8')\n",
        "#     resume_id = md_file.stem\n",
        "#     chunks = container_chunking(content, resume_id)\n",
        "#     all_chunks.extend(chunks)\n",
        "\n",
        "# print(f\"Created {len(all_chunks)} chunks from {len(list(markdown_dir.glob('*.md')))} resumes\")\n",
        "# print(f\"Average chunks per resume: {len(all_chunks) / len(list(markdown_dir.glob('*.md'))):.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "757de011",
      "metadata": {
        "id": "757de011"
      },
      "source": [
        "Embedding Models\n",
        "\n",
        "Creating embeddings of each chunk in the document(resume) list and storing them in a pickle file (so don't have to keep running it again)\n",
        "PS only works on colab due to version differences. generate on vscode separately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JhO5p1xxExQf",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhO5p1xxExQf",
        "outputId": "5f4823c3-8558-4bfa-820d-878f2c77c670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating OpenAI embeddings for 263 chunks...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding batches: 100%|██████████| 3/3 [00:07<00:00,  2.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 263 chunks and embeddings -> resume_chunks_openai.pkl, resume_embeddings_openai.pkl\n",
            "Embeddings shape: (263, 1536)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# #CREATING OPEN AI EMBEDDINGS FOR ALL CHUNKS\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = (\n",
        "#     userdata.get(\"OPENAI_API_KEY\") or userdata.get(\"openai_api_key\")\n",
        "# )\n",
        "# client=OpenAI()\n",
        "# def get_openai_embeddings(texts: list[str], model: str = \"text-embedding-3-small\", batch_size: int = 100) -> np.ndarray:\n",
        "#     embeddings: list[np.ndarray] = []\n",
        "#     for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding batches\"):\n",
        "#         batch = texts[i : i + batch_size]\n",
        "#         resp = client.embeddings.create(model=model, input=batch)\n",
        "#         embeddings.extend([np.array(item.embedding, dtype=np.float32) for item in resp.data])\n",
        "#     return np.vstack(embeddings) if embeddings else np.zeros((0, 0), dtype=np.float32)\n",
        "\n",
        "# # prepare chunks (prefer in-memory all_chunks, else load saved chunks)\n",
        "# try:\n",
        "#     chunks = all_chunks  # type: ignore[name-defined]\n",
        "# except NameError:\n",
        "#     if os.path.exists(\"resume_chunks.pkl\"):\n",
        "#         with open(\"resume_chunks.pkl\", \"rb\") as f:\n",
        "#             chunks = pickle.load(f)\n",
        "#     else:\n",
        "#         raise RuntimeError(\"No in-memory chunks and resume_chunks.pkl not found.\")\n",
        "\n",
        "# chunk_texts = [doc.page_content for doc in chunks]\n",
        "# print(f\"Generating OpenAI embeddings for {len(chunk_texts)} chunks...\")\n",
        "\n",
        "# # choose \"text-embedding-3-small\" or \"text-embedding-3-large\"\n",
        "# embeddings = get_openai_embeddings(chunk_texts, model=\"text-embedding-3-small\", batch_size=100)\n",
        "\n",
        "# # ====================================================================================================================\n",
        "# # SAVING THE EMBEDDINGS OF CHUNKS AND STORING IN PICKLE FILE\n",
        "# with open(\"resume_chunks_openai.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(chunks, f)\n",
        "\n",
        "# with open(\"resume_embeddings_openai.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(embeddings, f)\n",
        "\n",
        "# print(f\"Saved {len(chunks)} chunks and embeddings -> resume_chunks_openai.pkl, resume_embeddings_openai.pkl\")\n",
        "# print(f\"Embeddings shape: {embeddings.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1IGxdgPczByd",
      "metadata": {
        "id": "1IGxdgPczByd"
      },
      "source": [
        "Trying Hybrid Retrieval\n",
        "\n",
        "\n",
        "For resume based querying, just semantic search doesn't cut it, a lot of the times, the recruiters are looking for some keywords, with semantic similarity it can't match exact keywords hence we need to combine approaches; keyword matching +semantic similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0609e86d",
      "metadata": {},
      "outputs": [],
      "source": [
        " # Load saved chunks and embeddings\n",
        "with open('resume_chunks_openai.pkl', 'rb') as f:\n",
        "    chunks = pickle.load(f)\n",
        "\n",
        "with open('resume_embeddings_openai.pkl', 'rb') as f:\n",
        "    embeddings = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc0edb20",
      "metadata": {},
      "source": [
        "### BM25 scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NRqlni71zP6m",
      "metadata": {
        "id": "NRqlni71zP6m"
      },
      "outputs": [],
      "source": [
        "\n",
        "_CLEAN_RX = re.compile(r'[^\\w\\s]')\n",
        "_WS_RX = re.compile(r'\\s+')\n",
        "\n",
        "def clean_and_tokenize(text: str) -> List[str]:\n",
        "    text = text.lower()\n",
        "    text = _CLEAN_RX.sub(' ', text)     # remove punctuation\n",
        "    text = _WS_RX.sub(' ', text).strip()\n",
        "    return [t for t in text.split(' ') if t]\n",
        "\n",
        "class BM25Index:\n",
        "    def __init__(self):\n",
        "        self.bm25 = None\n",
        "        self.docs: List[Document] = []\n",
        "        self.doc_tokens: List[List[str]] = []\n",
        "\n",
        "    def fit(self, chunks: List[Document]):\n",
        "        self.docs = chunks\n",
        "        self.doc_tokens = [clean_and_tokenize(d.page_content) for d in chunks]\n",
        "        self.bm25 = BM25Okapi(self.doc_tokens)\n",
        "\n",
        "    def search(self, query: str, top_k: int = 200) -> List[Dict[str, Any]]:\n",
        "        if self.bm25 is None:\n",
        "            raise RuntimeError(\"Call fit(chunks) before search().\")\n",
        "        q_tokens = clean_and_tokenize(query)\n",
        "        scores = self.bm25.get_scores(q_tokens)\n",
        "        # top-k indices by score\n",
        "        top_idx = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
        "        out = []\n",
        "        for rank, i in enumerate(top_idx, 1):\n",
        "            d = self.docs[i]\n",
        "            out.append({\n",
        "                \"rank\": rank,\n",
        "                \"bm25_score\": float(scores[i]),\n",
        "                \"resume_id\": (d.metadata or {}).get(\"resume_id\"),\n",
        "                \"chunk_id\": (d.metadata or {}).get(\"chunk_id\"),\n",
        "                \"preview\": d.page_content[:400]\n",
        "            })\n",
        "        return out\n",
        "bm25 = BM25Index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u-b1MycG1VyN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-b1MycG1VyN",
        "outputId": "bb015f74-09fd-455f-ca65-7b9f52170f37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BM25 hits: 200\n",
            "[ 1] 30.712  resume=Resume Mollika - Mollika Garg  chunk=3\n",
            "    ## SELECTED PROJECTS ...\n",
            "[ 2] 16.043  resume=Resume Mollika - Mollika Garg  chunk=4\n",
            "    ## ACHIEVEMENTS ...\n",
            "[ 3] 10.347  resume=Resume.PunithHM - Punith H M  chunk=2\n",
            "    ## Projects ...\n",
            "[ 4] 9.850  resume=Zulfikar_resume - Zulfikar Charoliya  chunk=2\n",
            "    ## PROJECTS ...\n",
            "[ 5] 5.875  resume=Basit_s AI Resume - Basit Ali  chunk=2\n",
            "    ## PERSONAL PROJECTS ...\n"
          ]
        }
      ],
      "source": [
        "#checking the retrieval\n",
        "\n",
        "bm25.fit(chunks)  # chunks = your List[Document] from the chunker\n",
        "\n",
        "query = \"Urban Water Logging Detection for Timely Intervention and Mitigation\"\n",
        "hits = bm25.search(query, top_k=200)\n",
        "\n",
        "print(f\"BM25 hits: {len(hits)}\")\n",
        "for h in hits[:5]:\n",
        "    print(f\"[{h['rank']:>2}] {h['bm25_score']:.3f}  resume={h['resume_id']}  chunk={h['chunk_id']}\")\n",
        "    print(\"   \", (h[\"preview\"] or \"\").splitlines()[0][:540], \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "519be95a",
      "metadata": {},
      "source": [
        "### Dense Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JSGtdfXj1W-U",
      "metadata": {
        "id": "JSGtdfXj1W-U"
      },
      "outputs": [],
      "source": [
        "#using openai dense embeddings for retrieval\n",
        "os.environ[\"OPENAI_API_KEY\"] = (\n",
        "    userdata.get(\"OPENAI_API_KEY\") or userdata.get(\"openai_api_key\")\n",
        ")\n",
        "client=OpenAI()\n",
        "\n",
        "\n",
        "class DenseIndexSimple:\n",
        "    def __init__(self):\n",
        "        self.docs: List[Document] = []\n",
        "        self.Xn: np.ndarray | None = None  # L2-normalized embeddings (N, D)\n",
        "        self.dim: int | None = None\n",
        "        self.model_name: str | None = None\n",
        "\n",
        "    def fit(self, chunks: List[Document], embeddings: np.ndarray, model_name: str):\n",
        "        \"\"\"\n",
        "        chunks: your List[Document]\n",
        "        embeddings: np.ndarray of shape (N, D) aligned with chunks\n",
        "        model_name: the embedding model used (e.g., 'text-embedding-3-small')\n",
        "        \"\"\"\n",
        "        if embeddings.ndim != 2 or len(chunks) != embeddings.shape[0]:\n",
        "            raise ValueError(\"Embeddings must be 2D and aligned with chunks.\")\n",
        "        X = embeddings.astype(np.float32)\n",
        "        X = np.ascontiguousarray(X)\n",
        "        norms = np.linalg.norm(X, axis=1, keepdims=True) + 1e-12\n",
        "        self.Xn = X / norms\n",
        "        self.dim = self.Xn.shape[1]\n",
        "        self.docs = chunks\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def _embed_query(self, query: str) -> np.ndarray:\n",
        "        if not self.model_name:\n",
        "            raise RuntimeError(\"Index not initialized with a model_name. Call fit() first.\")\n",
        "        resp = client.embeddings.create(model=self.model_name, input=[query])\n",
        "        q = np.array(resp.data[0].embedding, dtype=np.float32)\n",
        "        if q.shape[0] != self.dim:\n",
        "            raise ValueError(f\"Query dim {q.shape[0]} != index dim {self.dim}. \"\n",
        "                             f\"Use the same embedding model as indexing.\")\n",
        "        q = q / (np.linalg.norm(q) + 1e-12)\n",
        "        return q  # (D,)\n",
        "\n",
        "    def search(self, query: str, top_k: int = 200) -> list[dict]:\n",
        "        if self.Xn is None:\n",
        "            raise RuntimeError(\"Index empty. Call fit() first.\")\n",
        "\n",
        "        # embed + normalize query\n",
        "        q = self._embed_query(query)                 # (D,)\n",
        "        sims = self.Xn @ q                           # (N,)\n",
        "        n = sims.shape[0]\n",
        "        k = max(1, min(top_k, n))                    # clamp to [1, N]\n",
        "\n",
        "        # For small N, argsort is fine and simpler\n",
        "        top_idx = np.argsort(sims)[::-1][:k]\n",
        "\n",
        "        results = []\n",
        "        for rank, i in enumerate(top_idx, 1):\n",
        "            d = self.docs[i]\n",
        "            results.append({\n",
        "                \"rank\": rank,\n",
        "                \"dense_score\": float(sims[i]),\n",
        "                \"resume_id\": (d.metadata or {}).get(\"resume_id\"),\n",
        "                \"chunk_id\": (d.metadata or {}).get(\"chunk_id\"),\n",
        "                \"preview\": d.page_content[:400],\n",
        "            })\n",
        "        return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UKR_LxWJ6h7L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKR_LxWJ6h7L",
        "outputId": "09537d0b-b3f7-4f11-d9ab-690185a8d0ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dense hits: 200\n",
            "[ 1] 0.4335 resume=VES_Ganesh_Deulkar_Resume - Ganesh Deulkar chunk=1\n",
            "[ 2] 0.3864 resume=SHAHNAWAZ_RESUME (4) - shahnawaz Shaikh chunk=2\n",
            "[ 3] 0.3800 resume=Saaquib Motiwala Resume-6 (1) - saaquib motiwala chunk=3\n",
            "[ 4] 0.3674 resume=Mohit_CV - Mohit Lohani chunk=1\n",
            "[ 5] 0.3562 resume=Ankit Patil Resume - Ankit Patil chunk=1\n"
          ]
        }
      ],
      "source": [
        "#checking dense retrieval \n",
        "dense = DenseIndexSimple()\n",
        "dense.fit(chunks, embeddings, model_name=\"text-embedding-3-small\")\n",
        "\n",
        "query = \"mumbai university\"\n",
        "dense_hits = dense.search(query, top_k=200)\n",
        "\n",
        "print(f\"Dense hits: {len(dense_hits)}\")\n",
        "for h in dense_hits[:5]:\n",
        "    print(f\"[{h['rank']:>2}] {h['dense_score']:.4f} resume={h['resume_id']} chunk={h['chunk_id']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10ada0d0",
      "metadata": {},
      "source": [
        "### Combining BM25 and Dense retrieval using RRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "dsb8AnKfD5LH",
      "metadata": {
        "id": "dsb8AnKfD5LH"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "def _make_key(hit: Dict[str, Any]) -> str:\n",
        "    \"\"\"Stable key to identify a chunk across lists.\"\"\"\n",
        "    rid = (hit.get(\"resume_id\") or \"\").strip()\n",
        "    cid = str(hit.get(\"chunk_id\") or \"\").strip()\n",
        "    if rid or cid:\n",
        "        return f\"{rid}::{cid}\"\n",
        "    # Fallback: hash preview if metadata missing\n",
        "    prev = (hit.get(\"preview\") or \"\")[:256]\n",
        "    return \"hash::\" + hashlib.md5(prev.encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "def rrf_fuse(\n",
        "    bm25_hits: Optional[List[Dict[str, Any]]],\n",
        "    dense_hits: Optional[List[Dict[str, Any]]],\n",
        "    k: int = 60,\n",
        "    top_k: int = 180,\n",
        "    weights: Dict[str, float] = None,\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Reciprocal Rank Fusion (RRF): score = sum_s w_s * 1/(k + rank_s)\n",
        "    - bm25_hits / dense_hits: lists with at least {'rank', 'resume_id', 'chunk_id'} (or 'preview').\n",
        "    - k: stabilization constant (common choices: 60, 100).\n",
        "    - top_k: number of fused results to return.\n",
        "    - weights: optional per-source weights, e.g., {'bm25': 1.0, 'dense': 1.0}\n",
        "    \"\"\"\n",
        "    weights = weights or {\"bm25\": 1.0, \"dense\": 1.0}\n",
        "    pool: Dict[str, Dict[str, Any]] = {}\n",
        "\n",
        "    def add_source(hits: Optional[List[Dict[str, Any]]], label: str):\n",
        "        if not hits:\n",
        "            return\n",
        "        for h in hits:\n",
        "            key = _make_key(h)\n",
        "            rec = pool.setdefault(key, {\n",
        "                \"resume_id\": h.get(\"resume_id\"),\n",
        "                \"chunk_id\": h.get(\"chunk_id\"),\n",
        "                \"preview\": h.get(\"preview\"),\n",
        "                # keep original per-source info if present\n",
        "                \"bm25_rank\": None, \"bm25_score\": None,\n",
        "                \"dense_rank\": None, \"dense_score\": None,\n",
        "                \"rrf_score\": 0.0,\n",
        "            })\n",
        "            r = h.get(\"rank\")\n",
        "            if isinstance(r, int) and r >= 1:\n",
        "                rec[\"rrf_score\"] += weights.get(label, 1.0) * (1.0 / (k + r))\n",
        "            # stash per-source details (first occurrence wins)\n",
        "            rank_key = f\"{label}_rank\"\n",
        "            score_key = f\"{label}_score\"\n",
        "            if rec[rank_key] is None:\n",
        "                rec[rank_key] = r\n",
        "            if rec[score_key] is None:\n",
        "                # hit may have 'bm25_score' or 'dense_score'\n",
        "                val = h.get(score_key) or h.get(\"bm25_score\") or h.get(\"dense_score\")\n",
        "                rec[score_key] = float(val) if val is not None else None\n",
        "\n",
        "    add_source(bm25_hits, \"bm25\")\n",
        "    add_source(dense_hits, \"dense\")\n",
        "\n",
        "    fused = sorted(pool.values(), key=lambda x: x[\"rrf_score\"], reverse=True)[:top_k]\n",
        "    # add final rank\n",
        "    for i, rec in enumerate(fused, 1):\n",
        "        rec[\"rank\"] = i\n",
        "    return fused\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VxRZEFNMHvMp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxRZEFNMHvMp",
        "outputId": "c9090817-7028-4cd4-d6df-d540ba146858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 1] RRF=0.04918  bm25_r=1  dense_r=1\n",
            "    ## SELECTED PROJECTS ...\n",
            "[ 2] RRF=0.04788  bm25_r=3  dense_r=2\n",
            "    ## Projects ...\n",
            "[ 3] RRF=0.04572  bm25_r=7  dense_r=3\n",
            "    ## (Google Earth Engine, EDA, LSTM, Project Management)                                                                  ...\n",
            "[ 4] RRF=0.04559  bm25_r=2  dense_r=15\n",
            "    ## ACHIEVEMENTS ...\n",
            "[ 5] RRF=0.04505  bm25_r=5  dense_r=10\n",
            "    ## PERSONAL PROJECTS ...\n",
            "[ 6] RRF=0.04501  bm25_r=6  dense_r=8\n",
            "    ## Professional Experience ...\n",
            "[ 7] RRF=0.04340  bm25_r=12  dense_r=4\n",
            "    ## COMPETITION/CONFERENCE ...\n",
            "[ 8] RRF=0.04156  bm25_r=10  dense_r=17\n",
            "    ## Projects ...\n",
            "[ 9] RRF=0.04149  bm25_r=9  dense_r=20\n",
            "    ## Experience ...\n",
            "[10] RRF=0.04116  bm25_r=15  dense_r=9\n",
            "    ## Publications ...\n"
          ]
        }
      ],
      "source": [
        "# Checking RRF fusion\n",
        "query=\"Urban Water Logging Detection for Timely Intervention and Mitigation\"\n",
        "bm25_hits = bm25.search(query, top_k=200)\n",
        "dense_hits = dense.search(query, top_k=200)\n",
        "\n",
        "fused = rrf_fuse(bm25_hits, dense_hits, k=60, top_k=180, weights={\"bm25\": 2.0, \"dense\": 1.0})\n",
        "for r in fused[:10]:\n",
        "    print(f\"[{r['rank']:>2}] RRF={r['rrf_score']:.5f}  bm25_r={r['bm25_rank']}  dense_r={r['dense_rank']}\")\n",
        "    print(\"   \", (r[\"preview\"] or \"\").splitlines()[0][:120], \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f72987c",
      "metadata": {},
      "source": [
        "### Reranking using Cross Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "lsbirg4iS2lP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345,
          "referenced_widgets": [
            "4bcdf9241b164e35a8a175b5e98fa88e",
            "2e38710927044637a41624f102c45846",
            "46c189f7f01344bab03a2fc2259ed23d",
            "5b0a5a55e9c54cbaaff4ee7c1c8f4b40",
            "3e86221798784c8b8aa502d226eef936",
            "efce9a9252fe4989a5662d0215626949",
            "9d663af70fed4b25a34d11d0c0a14a07",
            "44fe6c843e764eb49816e6d4bc38020a",
            "0777e207188d4bb78dd9072e04f3f624",
            "007972da55ac40bfbfa1488fc544cd19",
            "b910b19e692140ec89e3e10389ed7431",
            "04ef7e88c9fc4bbe8ca9ddf70836e25a",
            "2e6066eb8d6645e08a781418af8dc67c",
            "b8ed57669e6a4e92822b7a792863c4bf",
            "cc8ce45a4cf24af7b6166dd479a03f60",
            "865c93e33f294e569289a2931324996c",
            "659ee9100e27451b9ddead349df3f28c",
            "f99a80150ea8425797a69d64fc219b52",
            "fb1fdb3700734d5d8a4a65bcf7b0fca2",
            "32f185755ed04846af11426139879a89",
            "2123908e271c45cb9c90eb6832221f4e",
            "9fd3a841ae71425c84c45dea71a53a39",
            "71c20f8a79fa45aea3d22337b559b582",
            "a9b024ec8f3f47f28e9eb73fdfc55f8b",
            "75c0baf0931d45bdb97889e95b895c27",
            "ae5d1fc442684262a5c4c20ac794dd2f",
            "17ffa0d91a3142c4b3b1d5bc9fa52976",
            "8f3f3c9763a64a75ba8e294715ccd903",
            "e664571dea16457999ff57c3935b52b8",
            "ad7bdfa98d0d4df9b83daa086d6f2002",
            "4afd5a6623b7427bbf49b63871143fd9",
            "ae14078afba740dc934bb618aaa63a6e",
            "2b4449afe82d46368db8d6f83d83ccb1",
            "880af25ceccb4775a464ece1fb187080",
            "4982718b96154578ac681a6ee223cda8",
            "0b87c7c198c747dea1218b7faad04063",
            "50adfb3aaa3c411ca8113b928394e8d9",
            "b4865e9e1fd0412596b36a253d7175fa",
            "456f472c01aa4ef3bf8b2e1a9bc52fa5",
            "05c8c23052434950b937da29282bca5f",
            "88d57f6d25c84231853789bc817487a2",
            "db6d5d517d1a46178056a0262619b9ff",
            "887cf8b176584e3292c2b33b68e0e308",
            "86705d87935a4b739c62eaa90fa069c3",
            "9389601b26ca46b29f69240bb51fb2d2",
            "9ee23b33b2a24262855ef8ea97200ac9",
            "d560750488e44619ac596f65122cb1b9",
            "9b651a6800d94be8bf4801215e3475ea",
            "40bed0975bab4661a0233f1364791017",
            "20a9053f3bcc4be29730db68e83444b3",
            "fb5f120be85e4ff5aa527263300bd4fd",
            "76ea3317af214f5d8766c3c42d494b76",
            "15cf8b226aba469bb34da98d385fbb11",
            "76bbcfdf95dc4bb6aa6310642367dfe8",
            "d2f9494035e84674935795bfbb1c89f3",
            "9c62a4cbe6a54a0a8d3041c95d83ff95",
            "cecf061316cf4fdeb2f7fd87102a623e",
            "ed85514bf8a34c7d96ffd0890d70f7a3",
            "375d4973c0ae4386aacad1182b7d335f",
            "0458f99cbec54b7fb1d5d22f4597a740",
            "8840544ce48347c5ac528b49c0b0ca3c",
            "600b07e436c64a0daf9c11d55fb4c20e",
            "55d0b6883e94411889bf1e822f68686d",
            "a67b6106e6e34c2e9d29167b3ebcd3a4",
            "40711fae641541ac80155eb6275e224d",
            "dcac28bf011c4bf8bb11ce55209e35e5",
            "e206205a27234365af121b84667d6025",
            "9c844fd4446e42c692a0b02b6821ed2b",
            "09e7891ff62b4d0785f338f291e31583",
            "24ea647e61ed48ddb7161cb67f825513",
            "0df7618577504ead85d1e03ec77f1f80",
            "b72b00737d384e94ac0815cc7b0bd7be",
            "1aeda559506a4c80907a9579ede8043e",
            "6a011db83bdf4ffebf7721ffa52c8907",
            "45fbdef435f04531b1aa2f4a987d52cf",
            "85a536750c764af4afe5b0240dcd10cf",
            "b5de395182db4de99322fd85b78ac133"
          ]
        },
        "id": "lsbirg4iS2lP",
        "outputId": "9b3fbbe2-7082-4cbe-fcc6-8c09bbcdfa8a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bcdf9241b164e35a8a175b5e98fa88e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04ef7e88c9fc4bbe8ca9ddf70836e25a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71c20f8a79fa45aea3d22337b559b582",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "880af25ceccb4775a464ece1fb187080",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9389601b26ca46b29f69240bb51fb2d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c62a4cbe6a54a0a8d3041c95d83ff95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e206205a27234365af121b84667d6025",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "import torch\n",
        "with open('resume_chunks_openai.pkl', 'rb') as f:\n",
        "    all_chunks = pickle.load(f)\n",
        "# Load cross-encoder reranker\n",
        "reranker = CrossEncoder(\n",
        "    \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "def rerank_with_cross_encoder(query: str, fused_results: List[Dict[str, Any]], all_chunks: List[Document], top_k: int = 180) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Rerank fused results using cross-encoder for better relevance\"\"\"\n",
        "\n",
        "    # Get full chunk content for each result\n",
        "    pairs = []\n",
        "    valid_results = []\n",
        "\n",
        "    for r in fused_results:\n",
        "        resume_id = r.get(\"resume_id\")\n",
        "        chunk_id = r.get(\"chunk_id\")\n",
        "\n",
        "        # Find matching chunk\n",
        "        matching_chunk = next(\n",
        "            (c for c in all_chunks if c.metadata.get(\"resume_id\") == resume_id and c.metadata.get(\"chunk_id\") == chunk_id),\n",
        "            None\n",
        "        )\n",
        "\n",
        "        if matching_chunk:\n",
        "            pairs.append((query, matching_chunk.page_content))\n",
        "            valid_results.append(r)\n",
        "\n",
        "    # Get cross-encoder scores\n",
        "    ce_scores = reranker.predict(pairs).tolist()\n",
        "\n",
        "    # Add cross-encoder scores to results\n",
        "    for result, score in zip(valid_results, ce_scores):\n",
        "        result[\"ce_score\"] = float(score)\n",
        "\n",
        "    # Sort by cross-encoder score\n",
        "    reranked = sorted(valid_results, key=lambda x: x[\"ce_score\"], reverse=True)[:top_k]\n",
        "\n",
        "    # Update ranks\n",
        "    for i, r in enumerate(reranked, 1):\n",
        "        r[\"rerank_position\"] = i\n",
        "\n",
        "    return reranked\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G9CSXe21az-A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9CSXe21az-A",
        "outputId": "19d6110c-44ca-4ec8-97ff-239c0cb08d51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deekshith_Kuchana (1) - Deekshith kuchana\n",
            "VES_Ganesh_Deulkar_Resume - Ganesh Deulkar\n",
            "Harshit_Resume_one (1) - HARSHIT SRIVASTAVA\n",
            "resume_intern-1 - Akshitha B\n",
            "Dev Vrat Sharma - Resume - Dev Vrat Sharma\n"
          ]
        }
      ],
      "source": [
        "#Checking RERANKING USING CROSS ENCODER\n",
        "query = \"Candidates who are strictly ML people, no development\"\n",
        "bm25_hits = bm25.search(query, top_k=200)\n",
        "dense_hits = dense.search(query, top_k=200)\n",
        "fused = rrf_fuse(bm25_hits, dense_hits, k=60, top_k=180)\n",
        "\n",
        "# Rerank top 50 results to get final top 10\n",
        "reranked = rerank_with_cross_encoder(query, fused, all_chunks, top_k=180)\n",
        "for r in reranked[:5]:\n",
        "  print(r.get(\"resume_id\", \"\"))\n",
        "# print(\"RERANKED RESULTS:\")\n",
        "# for r in reranked:\n",
        "#     print(f\"[{r['rerank_position']:>2}] CE={r['ce_score']:.4f} RRF={r['rrf_score']:.5f} resume={r['resume_id']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2Jyqn7zuzMJ3",
      "metadata": {
        "id": "2Jyqn7zuzMJ3"
      },
      "source": [
        "### Generating LLM Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8SUWxZMlmb0Y",
      "metadata": {
        "cellView": "form",
        "id": "8SUWxZMlmb0Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "from openai import OpenAI\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = (\n",
        "    userdata.get(\"OPENAI_API_KEY\") or userdata.get(\"openai_api_key\")\n",
        ")\n",
        "client=OpenAI()\n",
        "\n",
        "with open('resume_chunks_openai.pkl', 'rb') as f:\n",
        "    all_chunks = pickle.load(f)\n",
        "\n",
        "def gather_full_resumes(fused_results: List[Dict[str, Any]], all_chunks: List[Document]) -> Dict[str, str]:\n",
        "    \"\"\"Collect all chunks for each resume_id mentioned in fused results.\"\"\"\n",
        "    resume_ids = {r[\"resume_id\"] for r in fused_results if r.get(\"resume_id\")}\n",
        "\n",
        "    resume_content = {}\n",
        "    for rid in resume_ids:\n",
        "        # Get all chunks for this resume\n",
        "        resume_chunks = [c.page_content for c in all_chunks if c.metadata.get(\"resume_id\") == rid]\n",
        "        resume_content[rid] = \"\\n\\n\".join(resume_chunks)\n",
        "\n",
        "    return resume_content\n",
        "\n",
        "def summarize_resumes_with_llm(\n",
        "    query: str,\n",
        "    fused_results: List[Dict[str, Any]],\n",
        "    all_chunks: List[Document],\n",
        "    top_n: int = 5,\n",
        "    max_resume_chars: int = 6000,\n",
        "    max_context_chars: int = 2000\n",
        "):\n",
        "    \"\"\"Generate summaries with both retrieved chunks and full resume context.\"\"\"\n",
        "\n",
        "    # Get top N unique resume IDs\n",
        "    top_resume_ids = []\n",
        "    resume_matched_chunks = {}  # Store which chunks matched for each resume\n",
        "\n",
        "    for r in fused_results:\n",
        "        rid = r.get(\"resume_id\")\n",
        "        if rid:\n",
        "            # Track matched chunks for this resume\n",
        "            if rid not in resume_matched_chunks:\n",
        "                resume_matched_chunks[rid] = []\n",
        "            resume_matched_chunks[rid].append(r)\n",
        "\n",
        "            # Add to top list if not already there\n",
        "            if rid not in top_resume_ids:\n",
        "                top_resume_ids.append(rid)\n",
        "\n",
        "            if len(top_resume_ids) >= top_n:\n",
        "                break\n",
        "\n",
        "    # Gather full resume content\n",
        "    resume_content = gather_full_resumes(fused_results, all_chunks)\n",
        "\n",
        "    summaries = []\n",
        "    for rid in top_resume_ids:\n",
        "        full_resume = resume_content.get(rid, \"\")\n",
        "        matched_chunks = resume_matched_chunks.get(rid, [])\n",
        "\n",
        "        # Get the actual text of matched chunks\n",
        "        matched_texts = []\n",
        "        for m in matched_chunks[:3]:  # Top 3 matched chunks\n",
        "            chunk = next(\n",
        "                (c for c in all_chunks\n",
        "                 if c.metadata.get(\"resume_id\") == rid\n",
        "                 and c.metadata.get(\"chunk_id\") == m.get(\"chunk_id\")),\n",
        "                None\n",
        "            )\n",
        "            if chunk:\n",
        "                matched_texts.append(chunk.page_content)  # Change here to limit the size of chunks being added to the context\n",
        "\n",
        "        # Build context string\n",
        "        matched_context = \"\\n---\\n\".join(matched_texts) if matched_texts else \"N/A\"\n",
        "\n",
        "        # Smart truncation: prioritize important sections\n",
        "        resume_sections = split_resume_into_sections(full_resume)\n",
        "        truncated_resume = smart_truncate_resume(resume_sections, max_resume_chars)\n",
        "\n",
        "        prompt = f\"\"\"You are a recruiter assistant. Analyze this resume and provide:\n",
        "1. A brief summary of the candidate's profile (2-3 sentences)\n",
        "2. How this candidate matches the query: \"{query}\"\n",
        "3. Key strengths relevant to the query\n",
        "\n",
        "Resume ID: {rid}\n",
        "\n",
        "MOST RELEVANT SECTIONS (from search):\n",
        "{matched_context[:max_context_chars]}\n",
        "\n",
        "FULL RESUME:\n",
        "{truncated_resume}\n",
        "\n",
        "Focus on the relevant sections above, but use the full resume for complete context.\n",
        "Provide a concise response.\"\"\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.3,\n",
        "            max_tokens=400\n",
        "        )\n",
        "\n",
        "        summary = response.choices[0].message.content\n",
        "        summaries.append({\n",
        "            \"resume_id\": rid,\n",
        "            \"summary\": summary,\n",
        "            \"rrf_score\": next((r[\"rrf_score\"] for r in fused_results if r.get(\"resume_id\") == rid), None),\n",
        "            \"ce_score\": next((r.get(\"ce_score\") for r in fused_results if r.get(\"resume_id\") == rid), None),\n",
        "            \"matched_sections\": len(matched_chunks)\n",
        "        })\n",
        "\n",
        "    return summaries\n",
        "\n",
        "\n",
        "def split_resume_into_sections(resume_text: str) -> Dict[str, str]:\n",
        "    \"\"\"Split resume into sections based on markdown headers.\"\"\"\n",
        "    sections = {}\n",
        "    current_section = \"header\"\n",
        "    current_content = []\n",
        "\n",
        "    for line in resume_text.split('\\n'):\n",
        "        if line.startswith('##'):\n",
        "            # Save previous section\n",
        "            if current_content:\n",
        "                sections[current_section] = '\\n'.join(current_content)\n",
        "            # Start new section\n",
        "            current_section = line.strip('# ').lower()\n",
        "            current_content = [line]\n",
        "        else:\n",
        "            current_content.append(line)\n",
        "\n",
        "    # Save last section\n",
        "    if current_content:\n",
        "        sections[current_section] = '\\n'.join(current_content)\n",
        "\n",
        "    return sections\n",
        "\n",
        "\n",
        "def smart_truncate_resume(sections: Dict[str, str], max_chars: int) -> str:\n",
        "    \"\"\"Intelligently truncate resume, prioritizing important sections.\"\"\"\n",
        "\n",
        "    # Priority order for resume sections\n",
        "    priority_sections = [\n",
        "        'education', 'experience', 'work experience', 'skills',\n",
        "        'projects', 'summary','publications', 'certifications','about',\n",
        "        'achievements', 'awards'\n",
        "    ]\n",
        "\n",
        "    result = []\n",
        "    current_length = 0\n",
        "\n",
        "    # Add sections by priority\n",
        "    for section_name in priority_sections:\n",
        "        # Find matching section (case-insensitive partial match)\n",
        "        for key, content in sections.items():\n",
        "            if section_name in key.lower():\n",
        "                section_length = len(content)\n",
        "                if current_length + section_length <= max_chars:\n",
        "                    result.append(content)\n",
        "                    current_length += section_length\n",
        "                elif current_length < max_chars:\n",
        "                    # Add partial content\n",
        "                    remaining = max_chars - current_length\n",
        "                    result.append(content[:remaining] + \"\\n...[truncated]\")\n",
        "                    current_length = max_chars\n",
        "                break\n",
        "\n",
        "        if current_length >= max_chars:\n",
        "            break\n",
        "\n",
        "    # Add any remaining important sections not in priority list\n",
        "    for key, content in sections.items():\n",
        "        if current_length >= max_chars:\n",
        "            break\n",
        "        if key not in [s for s in priority_sections]:\n",
        "            section_length = len(content)\n",
        "            if current_length + section_length <= max_chars:\n",
        "                result.append(content)\n",
        "                current_length += section_length\n",
        "\n",
        "    return '\\n\\n'.join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "w-9blyukdz3z",
      "metadata": {
        "id": "w-9blyukdz3z"
      },
      "outputs": [],
      "source": [
        "# reranked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "wFRWAS1sfmXe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFRWAS1sfmXe",
        "outputId": "8e11a446-9261-43db-c74c-f744095d0fec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## Objective\n",
            "\n",
            "Aspiring machine learning engineer with a strong foundation in applied mathematics, specializing in NLP, deep learning, and generative AI. Highly skilled in leveraging machine learning frameworks and data science tools to solve complex problems. Seeking opportunities to apply technical expertise and research-driven insights to innovative AI projects and contribute to impactful solutions.\n",
            "## SUMMARY\n",
            "\n",
            "As a future data scientist, I have a strong background in deep learning, machine learning, and data analytics in addition to real-world backend API development expertise. I have successfully created and put into use predictive models and user-friendly online apps that have successfully solved real-world issues. My excitement for investigating novel approaches and procedures in the area is fueled by my love for data-driven decision-making.\n",
            "\n",
            "I'm looking for internships right now where I can use my technical expertise and add to creative initiatives. I can take on challenging tasks because to my analytical approach and problem-solving skills, and I work best in group settings where I can share my knowledge and learn from others. I can't wait to use my expertise and imagination to assist businesses in realizing the full potential of their data .\n",
            "## Education\n",
            "\n",
            "## Universitas Airlangga\n",
            "\n",
            "B.E. in Robotics and AI\n",
            "\n",
            "GPA: 3.67/4.00\n",
            "\n",
            "Surabaya, Indonesia\n",
            "\n",
            "Aug. 2022 - Jun. 2026\n",
            "\n",
            "- Relevant Courses: Data Structures &amp; Algorithms, OOP, Artificial Intelligence, Machine Learning, Deep Learning, Computer Vision.\n",
            "## PROFILE\n",
            "\n",
            "I am an Informatics Students with strong foundation in Data Science and Machine Learning. I have  a  deep  interest  at  Machine  Learning  and  AI  development.  During  my  daily  life  as college student,  I had joined HIMTI Gunadarma as Staff of Social Society Division, I had been  involved  at  Exchange  Student  Kampus  Merdeka  Bela  Negara  with  Data  Science Profession Learning Path, I had hands-on experience as Computer Vision Internship during 3 months at Kecilin, and I also a proud alumnus of Bangkit Academy Batch 1 2024.\n",
            "## Education\n",
            "\n",
            "## Maharashtra Institute of Technology, Chh. Sambhajinagar, India\n",
            "\n",
            "Bachelor of Technology in Artificial Intelligence and Data Science\n",
            "\n",
            "\n",
            "\n",
            "Jan 2022 - Jul 2025\n",
            "\n",
            "GPA: 7/10\n",
            "\n",
            "Coursework: Data Science, Data Analytics, Machine Learning, Deep Learning and ANN , Statistics, Linear algebra.\n",
            "1. Nahid Kawsar is an aspiring machine learning engineer with a strong foundation in applied mathematics, specializing in NLP, deep learning, and generative AI. He is highly skilled in leveraging machine learning frameworks and data science tools to solve complex problems.\n",
            "\n",
            "2. Nahid Kawsar matches the query as he has experience with PyTorch for deep learning, including working with CNN, RNN, LSTM, Transformers, and Attention Mechanism. He also has projects involving transfer learning with VGG16 and generative AI using frameworks like Huggingface.\n",
            "\n",
            "3. Key strengths relevant to the query include Nahid's experience with deep learning frameworks like PyTorch, his ability to explain model training and evaluation trade-offs through his project work, and his strong foundation in applied mathematics which is essential for understanding the theoretical aspects of machine learning models.\n",
            "1. The candidate is a future data scientist with a strong background in deep learning, machine learning, and data analytics. They have experience in creating predictive models and user-friendly online apps to solve real-world issues.\n",
            "\n",
            "2. This candidate matches the query as they have experience in deep learning and have successfully created predictive models using machine learning. They have also worked on projects involving AI chatbots, disease prediction using machine learning models, and integrating AI into practical applications.\n",
            "\n",
            "3. Key strengths relevant to the query include the candidate's experience in deep learning, machine learning, and data analytics. They have a strong technical expertise in Python, Numpy, Pandas, and Scikitlearn, which are essential for working with PyTorch for deep learning. Additionally, their experience in developing AI chatbots, disease prediction models, and integrating AI into practical applications demonstrates their ability to explain model training and evaluation trade-offs.\n",
            "1. Zinadine Zidan Alsyahana is a Robotics and AI student with a strong academic background and practical experience in machine learning, deep learning, and computer vision. They have completed relevant courses, internships, and projects in these areas, showcasing a passion for AI technologies.\n",
            "\n",
            "2. Zinadine Zidan Alsyahana is a suitable candidate for the query as they have experience with PyTorch, deep learning, and model training and evaluation trade-offs. They have worked on projects involving machine learning models, Large Language Models (LLMs), and computer vision, demonstrating their proficiency in these areas.\n",
            "\n",
            "3. Key strengths relevant to the query include proficiency in PyTorch and other tools/frameworks like Tensorflow, OpenCV, and Keras. Zinadine's experience in developing and fine-tuning LLMs, collaborating on machine learning projects, and integrating AI solutions into platforms highlight their ability to explain model training and evaluation trade-offs effectively. Additionally, their academic background in Robotics and AI, along with relevant certifications in machine learning, further support their expertise in deep learning technologies.\n",
            "1. Aziz Bayu Pratama is an Informatics student with a strong foundation in Data Science and Machine Learning, showcasing a deep interest in AI development. He has hands-on experience in computer vision through an internship and has actively participated in various projects and programs related to data science.\n",
            "\n",
            "2. Aziz Bayu Pratama matches the query as he has experience in machine learning and AI development, specifically in computer vision. He has worked on creating datasets, training models, and implementing APIs for computer vision projects, demonstrating his ability to work with deep learning frameworks like TensorFlow.\n",
            "\n",
            "3. Key strengths relevant to the query include Aziz's hands-on experience in computer vision projects, his knowledge of machine learning tools such as Scikit-Learn and TensorFlow, and his ability to explain model training and evaluation trade-offs through his project experiences and coursework in AI technology.\n",
            "1. The candidate is a Bachelor of Technology in Artificial Intelligence and Data Science with a GPA of 7/10. They have experience in developing machine learning models, data preprocessing, and model optimization.\n",
            "\n",
            "2. This candidate matches the query as they are comfortable with PyTorch for deep learning and have experience in explaining model training and evaluation trade-offs.\n",
            "\n",
            "3. Key strengths relevant to the query include proficiency in AI/ML frameworks like PyTorch, experience in model optimization to improve accuracy, and the ability to explain model validation tests effectively.\n"
          ]
        }
      ],
      "source": [
        "# Usage\n",
        "query = \"Find people comfortable with PyTorch for deep learning and who can explain model training and evaluation trade-offs.\"\n",
        "summaries = summarize_resumes_with_llm(query, reranked, all_chunks, top_n=5)\n",
        "\n",
        "for i, s in enumerate(summaries, 1):\n",
        "    # print(f\"\\n{'='*60}\")\n",
        "    # print(f\"RANK {i} | Resume ID: {s['resume_id']} | RRF Score: {s['rrf_score']:.5f}\")\n",
        "    # print(f\"{'='*60}\")\n",
        "\n",
        "    print(s['summary'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "007972da55ac40bfbfa1488fc544cd19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0458f99cbec54b7fb1d5d22f4597a740": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04ef7e88c9fc4bbe8ca9ddf70836e25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e6066eb8d6645e08a781418af8dc67c",
              "IPY_MODEL_b8ed57669e6a4e92822b7a792863c4bf",
              "IPY_MODEL_cc8ce45a4cf24af7b6166dd479a03f60"
            ],
            "layout": "IPY_MODEL_865c93e33f294e569289a2931324996c"
          }
        },
        "05c8c23052434950b937da29282bca5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0777e207188d4bb78dd9072e04f3f624": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09e7891ff62b4d0785f338f291e31583": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a011db83bdf4ffebf7721ffa52c8907",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45fbdef435f04531b1aa2f4a987d52cf",
            "value": 1
          }
        },
        "0b87c7c198c747dea1218b7faad04063": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88d57f6d25c84231853789bc817487a2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db6d5d517d1a46178056a0262619b9ff",
            "value": 1
          }
        },
        "0df7618577504ead85d1e03ec77f1f80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15cf8b226aba469bb34da98d385fbb11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17ffa0d91a3142c4b3b1d5bc9fa52976": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aeda559506a4c80907a9579ede8043e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20a9053f3bcc4be29730db68e83444b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2123908e271c45cb9c90eb6832221f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24ea647e61ed48ddb7161cb67f825513": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85a536750c764af4afe5b0240dcd10cf",
            "placeholder": "​",
            "style": "IPY_MODEL_b5de395182db4de99322fd85b78ac133",
            "value": " 3.67k/? [00:00&lt;00:00, 118kB/s]"
          }
        },
        "2b4449afe82d46368db8d6f83d83ccb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e38710927044637a41624f102c45846": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efce9a9252fe4989a5662d0215626949",
            "placeholder": "​",
            "style": "IPY_MODEL_9d663af70fed4b25a34d11d0c0a14a07",
            "value": "config.json: 100%"
          }
        },
        "2e6066eb8d6645e08a781418af8dc67c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_659ee9100e27451b9ddead349df3f28c",
            "placeholder": "​",
            "style": "IPY_MODEL_f99a80150ea8425797a69d64fc219b52",
            "value": "model.safetensors: 100%"
          }
        },
        "32f185755ed04846af11426139879a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "375d4973c0ae4386aacad1182b7d335f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40711fae641541ac80155eb6275e224d",
            "placeholder": "​",
            "style": "IPY_MODEL_dcac28bf011c4bf8bb11ce55209e35e5",
            "value": " 132/132 [00:00&lt;00:00, 4.02kB/s]"
          }
        },
        "3e86221798784c8b8aa502d226eef936": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40711fae641541ac80155eb6275e224d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40bed0975bab4661a0233f1364791017": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44fe6c843e764eb49816e6d4bc38020a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "456f472c01aa4ef3bf8b2e1a9bc52fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45fbdef435f04531b1aa2f4a987d52cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46c189f7f01344bab03a2fc2259ed23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44fe6c843e764eb49816e6d4bc38020a",
            "max": 794,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0777e207188d4bb78dd9072e04f3f624",
            "value": 794
          }
        },
        "4982718b96154578ac681a6ee223cda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_456f472c01aa4ef3bf8b2e1a9bc52fa5",
            "placeholder": "​",
            "style": "IPY_MODEL_05c8c23052434950b937da29282bca5f",
            "value": "vocab.txt: "
          }
        },
        "4afd5a6623b7427bbf49b63871143fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bcdf9241b164e35a8a175b5e98fa88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e38710927044637a41624f102c45846",
              "IPY_MODEL_46c189f7f01344bab03a2fc2259ed23d",
              "IPY_MODEL_5b0a5a55e9c54cbaaff4ee7c1c8f4b40"
            ],
            "layout": "IPY_MODEL_3e86221798784c8b8aa502d226eef936"
          }
        },
        "50adfb3aaa3c411ca8113b928394e8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_887cf8b176584e3292c2b33b68e0e308",
            "placeholder": "​",
            "style": "IPY_MODEL_86705d87935a4b739c62eaa90fa069c3",
            "value": " 232k/? [00:00&lt;00:00, 3.02MB/s]"
          }
        },
        "55d0b6883e94411889bf1e822f68686d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b0a5a55e9c54cbaaff4ee7c1c8f4b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007972da55ac40bfbfa1488fc544cd19",
            "placeholder": "​",
            "style": "IPY_MODEL_b910b19e692140ec89e3e10389ed7431",
            "value": " 794/794 [00:00&lt;00:00, 30.5kB/s]"
          }
        },
        "600b07e436c64a0daf9c11d55fb4c20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "659ee9100e27451b9ddead349df3f28c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a011db83bdf4ffebf7721ffa52c8907": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "71c20f8a79fa45aea3d22337b559b582": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9b024ec8f3f47f28e9eb73fdfc55f8b",
              "IPY_MODEL_75c0baf0931d45bdb97889e95b895c27",
              "IPY_MODEL_ae5d1fc442684262a5c4c20ac794dd2f"
            ],
            "layout": "IPY_MODEL_17ffa0d91a3142c4b3b1d5bc9fa52976"
          }
        },
        "75c0baf0931d45bdb97889e95b895c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad7bdfa98d0d4df9b83daa086d6f2002",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4afd5a6623b7427bbf49b63871143fd9",
            "value": 1
          }
        },
        "76bbcfdf95dc4bb6aa6310642367dfe8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ea3317af214f5d8766c3c42d494b76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "85a536750c764af4afe5b0240dcd10cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "865c93e33f294e569289a2931324996c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86705d87935a4b739c62eaa90fa069c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "880af25ceccb4775a464ece1fb187080": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4982718b96154578ac681a6ee223cda8",
              "IPY_MODEL_0b87c7c198c747dea1218b7faad04063",
              "IPY_MODEL_50adfb3aaa3c411ca8113b928394e8d9"
            ],
            "layout": "IPY_MODEL_b4865e9e1fd0412596b36a253d7175fa"
          }
        },
        "8840544ce48347c5ac528b49c0b0ca3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "887cf8b176584e3292c2b33b68e0e308": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d57f6d25c84231853789bc817487a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8f3f3c9763a64a75ba8e294715ccd903": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9389601b26ca46b29f69240bb51fb2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ee23b33b2a24262855ef8ea97200ac9",
              "IPY_MODEL_d560750488e44619ac596f65122cb1b9",
              "IPY_MODEL_9b651a6800d94be8bf4801215e3475ea"
            ],
            "layout": "IPY_MODEL_40bed0975bab4661a0233f1364791017"
          }
        },
        "9b651a6800d94be8bf4801215e3475ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76bbcfdf95dc4bb6aa6310642367dfe8",
            "placeholder": "​",
            "style": "IPY_MODEL_d2f9494035e84674935795bfbb1c89f3",
            "value": " 711k/? [00:00&lt;00:00, 14.1MB/s]"
          }
        },
        "9c62a4cbe6a54a0a8d3041c95d83ff95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cecf061316cf4fdeb2f7fd87102a623e",
              "IPY_MODEL_ed85514bf8a34c7d96ffd0890d70f7a3",
              "IPY_MODEL_375d4973c0ae4386aacad1182b7d335f"
            ],
            "layout": "IPY_MODEL_0458f99cbec54b7fb1d5d22f4597a740"
          }
        },
        "9c844fd4446e42c692a0b02b6821ed2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b72b00737d384e94ac0815cc7b0bd7be",
            "placeholder": "​",
            "style": "IPY_MODEL_1aeda559506a4c80907a9579ede8043e",
            "value": "README.md: "
          }
        },
        "9d663af70fed4b25a34d11d0c0a14a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ee23b33b2a24262855ef8ea97200ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20a9053f3bcc4be29730db68e83444b3",
            "placeholder": "​",
            "style": "IPY_MODEL_fb5f120be85e4ff5aa527263300bd4fd",
            "value": "tokenizer.json: "
          }
        },
        "9fd3a841ae71425c84c45dea71a53a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a67b6106e6e34c2e9d29167b3ebcd3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9b024ec8f3f47f28e9eb73fdfc55f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f3f3c9763a64a75ba8e294715ccd903",
            "placeholder": "​",
            "style": "IPY_MODEL_e664571dea16457999ff57c3935b52b8",
            "value": "tokenizer_config.json: "
          }
        },
        "ad7bdfa98d0d4df9b83daa086d6f2002": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ae14078afba740dc934bb618aaa63a6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae5d1fc442684262a5c4c20ac794dd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae14078afba740dc934bb618aaa63a6e",
            "placeholder": "​",
            "style": "IPY_MODEL_2b4449afe82d46368db8d6f83d83ccb1",
            "value": " 1.33k/? [00:00&lt;00:00, 20.6kB/s]"
          }
        },
        "b4865e9e1fd0412596b36a253d7175fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5de395182db4de99322fd85b78ac133": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b72b00737d384e94ac0815cc7b0bd7be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8ed57669e6a4e92822b7a792863c4bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb1fdb3700734d5d8a4a65bcf7b0fca2",
            "max": 90870598,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32f185755ed04846af11426139879a89",
            "value": 90870598
          }
        },
        "b910b19e692140ec89e3e10389ed7431": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc8ce45a4cf24af7b6166dd479a03f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2123908e271c45cb9c90eb6832221f4e",
            "placeholder": "​",
            "style": "IPY_MODEL_9fd3a841ae71425c84c45dea71a53a39",
            "value": " 90.9M/90.9M [00:02&lt;00:00, 35.2MB/s]"
          }
        },
        "cecf061316cf4fdeb2f7fd87102a623e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8840544ce48347c5ac528b49c0b0ca3c",
            "placeholder": "​",
            "style": "IPY_MODEL_600b07e436c64a0daf9c11d55fb4c20e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d2f9494035e84674935795bfbb1c89f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d560750488e44619ac596f65122cb1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ea3317af214f5d8766c3c42d494b76",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15cf8b226aba469bb34da98d385fbb11",
            "value": 1
          }
        },
        "db6d5d517d1a46178056a0262619b9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcac28bf011c4bf8bb11ce55209e35e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e206205a27234365af121b84667d6025": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c844fd4446e42c692a0b02b6821ed2b",
              "IPY_MODEL_09e7891ff62b4d0785f338f291e31583",
              "IPY_MODEL_24ea647e61ed48ddb7161cb67f825513"
            ],
            "layout": "IPY_MODEL_0df7618577504ead85d1e03ec77f1f80"
          }
        },
        "e664571dea16457999ff57c3935b52b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed85514bf8a34c7d96ffd0890d70f7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55d0b6883e94411889bf1e822f68686d",
            "max": 132,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a67b6106e6e34c2e9d29167b3ebcd3a4",
            "value": 132
          }
        },
        "efce9a9252fe4989a5662d0215626949": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f99a80150ea8425797a69d64fc219b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb1fdb3700734d5d8a4a65bcf7b0fca2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb5f120be85e4ff5aa527263300bd4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
